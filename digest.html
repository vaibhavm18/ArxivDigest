Title: <a href="https://arxiv.org/abs/">Title:
          Pre-Trained Vision-Language Models as Partial Annotators</a><br>Authors: Qian-Wei Wang, Yuqiu Xie, Letian Zhang, Zimo Liu, Shu-Tao Xia<br>Score: 9<br>Reason: The paper investigates the use of pre-trained vision-language models as partial annotators, which is relevant to large language model pretraining and finetuning as it explores methods for leveraging unlabeled data in downstream tasks.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Shedding Light on Large Generative Networks: Estimating Epistemic Uncertainty in Diffusion Models</a><br>Authors: Lucas Berry, Axel Brando, David Meger<br>Score: 9<br>Reason: The paper introduces a framework for estimating uncertainty in large generative diffusion models, which is relevant to large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Nomic Embed Vision: Expanding the Latent Space</a><br>Authors: Zach Nussbaum, Brandon Duderstadt, Andriy Mulyar<br>Score: 9<br>Reason: The paper describes a model that expands the latent space for image embeddings, which is relevant to multimodal machine learning and may have applications in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Towards Large Language Model Aided Program Refinement</a><br>Authors: Yufan Cai, Zhe Hou, Xiaokun Luan, David Miguel Sanan Baena, Yun Lin, Jun Sun, Jin Song Dong<br>Score: 9<br>Reason: The paper introduces a tool that combines formal program refinement techniques with large language models, which is directly related to large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of LLMs</a><br>Authors: Xin Lai, Zhuotao Tian, Yukang Chen, Senqiao Yang, Xiangru Peng, Jiaya Jia<br>Score: 9<br>Reason: The paper presents a method for improving long-chain reasoning in large language models, which is directly related to large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          RouteLLM: Learning to Route LLMs with Preference Data</a><br>Authors: Isaac Ong, Amjad Almahairi, Vincent Wu, Wei-Lin Chiang, Tianhao Wu, Joseph E. Gonzalez, M Waleed Kadous, Ion Stoica<br>Score: 9<br>Reason: The paper introduces router models for dynamically selecting between different language models, which is relevant to large language model pretraining and finetuning and multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Understand What LLM Needs: Dual Preference Alignment for Retrieval-Augmented Generation</a><br>Authors: Guanting Dong, Yutao Zhu, Chenghao Zhang, Zechen Wang, Zhicheng Dou, Ji-Rong Wen<br>Score: 9<br>Reason: This paper proposes a framework for aligning diverse knowledge preferences within retrieval-augmented generation (RAG) systems, which is relevant to large language model pretraining and fine-tuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          MUMU: Bootstrapping Multimodal Image Generation from Text-to-Image Data</a><br>Authors: William Berman, Alexander Peysakhovich<br>Score: 9<br>Reason: The paper presents a model for generating images from multimodal prompts, which aligns with your interest in multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Two-Pronged Human Evaluation of ChatGPT Self-Correction in Radiology Report Simplification</a><br>Authors: Ziyu Yang, Santhosh Cherian, Slobodan Vucetic<br>Score: 9<br>Reason: This paper explores the use of large language models in automatically generating simplified radiology reports, which is relevant to your interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis</a><br>Authors: Wenbin Li, Di Yao, Ruibo Zhao, Wenjie Chen, Zijie Xu, Chengxue Luo, Chang Gong, Quanliang Jing, Haining Tan, Jingping Bi<br>Score: 9<br>Reason: The paper evaluates the spatio-temporal understanding capability of large language models, aligning with research interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Fairness and Bias in Multimodal AI: A Survey</a><br>Authors: Tosin Adewumi, Lama Alkhaled, Namrata Gurung, Goya van Boven, Irene Pagliai<br>Score: 9<br>Reason: The paper surveys fairness and bias in multimodal AI, aligning with research interest in multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation</a><br>Authors: Zijun Yao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Weichuan Liu, Lei Hou, Juanzi Li<br>Score: 9<br>Reason: This paper introduces a self-aware knowledge retrieval model for adaptive retrieval augmented generation, which is highly relevant to large language model pretraining and fine-tuning and multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts</a><br>Authors: Shubhankar Singh, Purvi Chaurasia, Yerram Varun, Pranshu Pandya, Vatsal Gupta, Vivek Gupta, Dan Roth<br>Score: 9<br>Reason: This paper presents a benchmark for assessing visual question-answering multimodal language models in reasoning with flowcharts, which is highly relevant to multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment</a><br>Authors: Hao Fei, Shengqiong Wu, Meishan Zhang, Min Zhang, Tat-Seng Chua, Shuicheng Yan<br>Score: 9<br>Reason: The paper focuses on enhancing video-language representations, which is related to multimodal machine learning. It also mentions the use of large-scale video-language models.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          VERISCORE: Evaluating the factuality of verifiable claims in long-form text generation</a><br>Authors: Yixiao Song, Yekyung Kim, Mohit Iyyer<br>Score: 9<br>Reason: The paper introduces a metric for evaluating the factuality of verifiable claims in long-form text generation, which is relevant to large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Reliable Interval Prediction of Minimum Operating Voltage Based on On-chip Monitors via Conformalized Quantile Regression</a><br>Authors: Yuxuan Yin, Xiaoxiao Wang, Rebecca Chen, Chen He, Peng Li<br>Score: 8<br>Reason: The paper proposes a novel methodology for interval estimation of minimum operating voltage in chips, which is relevant to large language model pretraining and finetuning as it addresses uncertainty and prediction intervals.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Flexible ViG: Learning the Self-Saliency for Flexible Object Recognition</a><br>Authors: Lin Zuo, Kunshan Yang, Xianlong Tian, Kunbin He, Yongqi Ding, Mengmeng Jing<br>Score: 8<br>Reason: The paper addresses the recognition of flexible objects, which is relevant to multimodal machine learning and may have applications in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Composition Vision-Language Understanding via Segment and Depth Anything Model</a><br>Authors: Mingxiao Huo, Pengliang Ji, Haotian Lin, Junchen Liu, Yixiao Wang, Yijun Chen<br>Score: 8<br>Reason: The paper presents a library that enhances vision-language understanding, which is relevant to multimodal machine learning and may have applications in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Improving Hyperparameter Optimization with Checkpointed Model Weights</a><br>Authors: Nikhil Mehta, Jonathan Lorraine, Steve Masson, Ramanathan Arunachalam, Zaid Pervaiz Bhat, James Lucas, Arun George Zachariah<br>Score: 8<br>Reason: The paper proposes a method for improving hyperparameter optimization using checkpointed model weights, which is relevant to large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Human-AI Collaborative Taxonomy Construction: A Case Study in Profession-Specific Writing Assistants</a><br>Authors: Minhwa Lee, Zae Myung Kim, Vivek A. Khetan, Dongyeop Kang<br>Score: 8<br>Reason: The paper proposes a methodology for developing domain-specific writing assistants, which is relevant to large language model pretraining and finetuning and may have applications in multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Few-shot Personalization of LLMs with Mis-aligned Responses</a><br>Authors: Jaehyung Kim, Yiming Yang<br>Score: 8<br>Reason: This paper introduces a few-shot personalization approach for large language models (LLMs) using mis-aligned responses, which is relevant to large language model pretraining and fine-tuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          WV-Net: A foundation model for SAR WV-mode satellite imagery trained using contrastive self-supervised learning on 10 million images</a><br>Authors: Yannik Glaser, Justin E. Stopa, Linnea M. Wolniewicz, Ralph Foster, Doug Vandemark, Alexis Mouche, Bertrand Chapron, Peter Sadowski<br>Score: 8<br>Reason: The paper explores the use of large language models for analyzing SAR satellite imagery, which aligns with your interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Infinite Width Models That Work: Why Feature Learning Doesn't Matter as Much as You Think</a><br>Authors: Luke Sernau<br>Score: 8<br>Reason: The paper challenges the notion that feature learning is crucial for infinite-width models, which aligns with your interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          OutlierTune: Efficient Channel-Wise Quantization for Large Language Models</a><br>Authors: Jinguang Wang, Yuexi Yin, Haifeng Sun, Qi Qi, Jingyu Wang, Zirui Zhuang, Tingting Yang, Jianxin Liao<br>Score: 8<br>Reason: The paper proposes an efficient channel-wise quantization method for large language models, which aligns with your interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          LICO: Large Language Models for In-Context Molecular Optimization</a><br>Authors: Tung Nguyen, Aditya Grover<br>Score: 8<br>Reason: The paper introduces a model for in-context molecular optimization using large language models, which aligns with your interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Efficacy of Language Model Self-Play in Non-Zero-Sum Games</a><br>Authors: Austen Liao, Nicholas Tomlin, Dan Klein<br>Score: 8<br>Reason: This paper investigates the effectiveness of self-play in improving language models in a negotiation game setting, which is relevant to your interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets</a><br>Authors: Melanie Walsh, Anna Preus, Maria Antoniak<br>Score: 8<br>Reason: This paper explores how well large language models recognize poetic form, which is relevant to your interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          UniGen: A Unified Framework for Textual Dataset Generation Using Large Language Models</a><br>Authors: Siyuan Wu, Yue Huang, Chujie Gao, Dongping Chen, Qihui Zhang, Yao Wan, Tianyi Zhou, Xiangliang Zhang, Jianfeng Gao, Chaowei Xiao, Lichao Sun<br>Score: 8<br>Reason: The paper proposes a unified framework for textual dataset generation using large language models, which aligns with your interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          A look under the hood of the Interactive Deep Learning Enterprise (No-IDLE)</a><br>Authors: Daniel Sonntag, Michael Barz, Thiago Gouvêa<br>Score: 8<br>Reason: The paper discusses interactive machine learning combined with multimodal interaction, which aligns with research interest in multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Statements: Universal Information Extraction from Tables with Large Language Models for ESG KPIs</a><br>Authors: Lokesh Mishra, Sohayl Dhibi, Yusik Kim, Cesar Berrospi Ramis, Shubham Gupta, Michele Dolfi, Peter Staar<br>Score: 8<br>Reason: The paper focuses on information extraction from tables using large language models, which aligns with research interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Resolving Discrepancies in Compute-Optimal Scaling of Language Models</a><br>Authors: Tomer Porian, Mitchell Wortsman, Jenia Jitsev, Ludwig Schmidt, Yair Carmon<br>Score: 8<br>Reason: The paper examines compute-optimal scaling of language models, which aligns with research interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          RAVEN: Multitask Retrieval Augmented Vision-Language Learning</a><br>Authors: Varun Nagaraj Rao, Siddharth Choudhary, Aditya Deshpande, Ravi Kumar Satzoda, Srikar Appalaraju<br>Score: 8<br>Reason: The paper introduces a multitask retrieval augmented vision-language learning framework, aligning with research interest in multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Annotation Errors and NER: A Study with OntoNotes 5.0</a><br>Authors: Gabriel Bernier-Colborne, Sowmya Vajjala<br>Score: 8<br>Reason: This paper addresses the issue of annotation errors in NER datasets, which is relevant to large language model pretraining and fine-tuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings</a><br>Authors: Björn Deiseroth, Manuel Brack, Patrick Schramowski, Kristian Kersting, Samuel Weinbach<br>Score: 8<br>Reason: This paper presents a tokenizer-free approach for generative LLMs, which is highly relevant to large language model pretraining and fine-tuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Aligning Teacher with Student Preferences for Tailored Training Data Generation</a><br>Authors: Yantao Liu, Zhao Zhang, Zijun Yao, Shulin Cao, Lei Hou, Juanzi Li<br>Score: 8<br>Reason: This paper introduces a framework for aligning teacher with student preferences for tailored training data generation, which is highly relevant to large language model pretraining and fine-tuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Human-Aware Vision-and-Language Navigation: Bridging Simulation to Reality with Dynamic Human Interactions</a><br>Authors: Minghan Li, Heng Li, Zhi-Qi Cheng, Yifei Dong, Yuxuan Zhou, Jun-Yan He, Qi Dai, Teruko Mitamura, Alexander G. Hauptmann<br>Score: 8<br>Reason: This paper introduces a human-aware vision-and-language navigation framework, which is highly relevant to multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Revealing Fine-Grained Values and Opinions in Large Language Models</a><br>Authors: Dustin Wright, Arnav Arora, Nadav Borenstein, Srishti Yadav, Serge Belongie, Isabelle Augenstein<br>Score: 8<br>Reason: This paper explores the detection of fine-grained values and opinions in large language models, which is highly relevant to large language model pretraining and fine-tuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation</a><br>Authors: Jia Fu, Xiaoting Qin, Fangkai Yang, Lu Wang, Jue Zhang, Qingwei Lin, Yubo Chen, Dongmei Zhang, Saravan Rajmohan, Qi Zhang<br>Score: 8<br>Reason: The paper proposes a framework for automatic hyper-parameter tuning in retrieval-augmented generation, which is relevant to large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale</a><br>Authors: Junying Chen, Ruyi Ouyang, Anningzhe Gao, Shunian Chen, Guiming Hardy Chen, Xidong Wang, Ruifei Zhang, Zhenyang Cai, Ke Ji, Guangjun Yu, Xiang Wan, Benyou Wang<br>Score: 8<br>Reason: The paper focuses on injecting medical visual knowledge into multimodal LLMs, which is relevant to multimodal machine learning and may involve large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Jump Starting Bandits with LLM-Generated Prior Knowledge</a><br>Authors: Parand A. Alamdari, Yanshuai Cao, Kevin H. Wilson<br>Score: 8<br>Reason: The paper discusses the benefits of integrating LLMs with a contextual multi-armed bandit framework, which is relevant to large language model pretraining and may involve multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions</a><br>Authors: Nigel Fernandez, Alexander Scarlatos, Simon Woodhead, Andrew Lan<br>Score: 8<br>Reason: This paper introduces a novel approach, DiVERT, for generating distractors in math multiple-choice questions using large language models, which aligns with your interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          AddBiomechanics Dataset: Capturing the Physics of Human Motion at Scale</a><br>Authors: Keenon Werling, Janelle Kaneda, Alan Tan, Rishi Agarwal, Six Skov, Tom Van Wouwe, Scott Uhlrich, Nicholas Bianco, Carmichael Ong, Antoine Falisse, Shardul Sapkota, Aidan Chandra, Joshua Carter, Ezio Preatoni, Benjamin Fregly, Jennifer Hicks, Scott Delp, C. Karen Liu<br>Score: 7<br>Reason: The paper presents a dataset capturing the physics of human motion, which is relevant to multimodal machine learning as it provides data for analyzing human movement using different modalities.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Application of Multimodal Fusion Deep Learning Model in Disease Recognition</a><br>Authors: Xiaoyi Liu, Hongjie Qiu, Muqing Li, Zhou Yu, Yutian Yang, Yafeng Yan<br>Score: 7<br>Reason: The paper applies a multimodal fusion deep learning model to disease recognition, which is relevant to multimodal machine learning as it explores the advantages of combining different modalities for improved recognition.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Pseudo-label Based Domain Adaptation for Zero-Shot Text Steganalysis</a><br>Authors: Yufei Luo, Zhen Yang, Ru Zhang, Jianyi Liu<br>Score: 7<br>Reason: The paper presents a pseudo-label based domain adaptation method for zero-shot text steganalysis, which is relevant to large language model pretraining and finetuning as it addresses the challenges of limited labeled data and model generalization.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          FLOW: Fusing and Shuffling Global and Local Views for Cross-User Human Activity Recognition with IMUs</a><br>Authors: Qi Qiu, Tao Zhu, Furong Duan, Kevin I-Kai Wang, Liming Chen, Mingxing Nie, Mingxing Nie<br>Score: 7<br>Reason: The paper presents an unsupervised few-shot continual learning approach for remote sensing image scene classification, which is relevant to large language model pretraining and finetuning as it addresses the challenges of limited labeled samples.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Unsupervised Few-Shot Continual Learning for Remote Sensing Image Scene Classification</a><br>Authors: Muhammad Anwar Ma'sum, Mahardhika Pratama, Ramasamy Savitha, Lin Liu, Habibullah, Ryszard Kowalczyk<br>Score: 7<br>Reason: The paper proposes an unsupervised few-shot continual learning approach for remote sensing image scene classification, which is relevant to large language model pretraining and finetuning as it addresses the challenges of limited labeled samples.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Negative Prototypes Guided Contrastive Learning for WSOD</a><br>Authors: Yu Zhang, Chuang Zhu, Guoqing Yang, Siqi Chen<br>Score: 7<br>Reason: The paper introduces a negative prototypes guided contrastive learning approach for weakly supervised object detection, which is relevant to multimodal machine learning as it focuses on improving the representation of instances with similar characteristics.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Documentation Practices of Artificial Intelligence</a><br>Authors: Stefan Arnold, Dilara Yesilbas, Rene Gröbner, Dominik Riedelbauch, Maik Horn, Sven Weinzierl<br>Score: 7<br>Reason: The paper examines documentation practices in artificial intelligence, which is not directly related to large language model pretraining and finetuning or multimodal machine learning, but may provide insights into best practices for model development and deployment.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Towards Deep Active Learning in Avian Bioacoustics</a><br>Authors: Lukas Rauch, Denis Huseljic, Moritz Wirth, Jens Decke, Bernhard Sick, Christoph Scholz<br>Score: 7<br>Reason: The paper discusses the use of active learning in avian bioacoustics, which is not directly related to large language model pretraining and finetuning or multimodal machine learning, but may provide insights into active learning techniques that can be applied in other domains.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Automatic Prediction of Amyotrophic Lateral Sclerosis Progression using Longitudinal Speech Transformer</a><br>Authors: Liming Wang, Yuan Gong, Nauman Dawalatabad, Marco Vilela, Katerina Placek, Brian Tracey, Yishu Gong, Alan Premasiri, Fernando Vieira, James Glass<br>Score: 7<br>Reason: The paper proposes a model for predicting disease progression using longitudinal speech recordings, which is not directly related to large language model pretraining and finetuning or multimodal machine learning, but may provide insights into predictive modeling techniques.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Evaluating Copyright Takedown Methods for Language Models</a><br>Authors: Boyi Wei, Weijia Shi, Yangsibo Huang, Noah A. Smith, Chiyuan Zhang, Luke Zettlemoyer, Kai Li, Peter Henderson<br>Score: 7<br>Reason: The paper evaluates copyright takedown methods for language models, which is not directly related to large language model pretraining and finetuning or multimodal machine learning, but may provide insights into ethical considerations and responsible use of language models.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Learning to Correct for QA Reasoning with Black-box LLMs</a><br>Authors: Jaehyung Kim, Dongyoung Kim, Yiming Yang<br>Score: 7<br>Reason: This paper addresses the challenge of improving reasoning capability in black-box large language models (LLMs), which is relevant to large language model pretraining and fine-tuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Learn it or Leave it: Module Composition and Pruning for Continual Learning</a><br>Authors: Mingyang Wang, Heike Adel, Lukas Lange, Jannik Strötgen, Hinrich Schütze<br>Score: 7<br>Reason: This paper proposes a continual learning method for pretrained language models, which is relevant to large language model pretraining and fine-tuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Re-Ranking Step by Step: Investigating Pre-Filtering for Re-Ranking with Large Language Models</a><br>Authors: Baharan Nouriinanloo, Maxime Lamothe<br>Score: 7<br>Reason: This paper investigates the use of pre-filtering for re-ranking with large language models, which is relevant to large language model pretraining and fine-tuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Psychological Profiling in Cybersecurity: A Look at LLMs and Psycholinguistic Features</a><br>Authors: Jean Marie Tshimula, D'Jeff K. Nkashama, Jean Tshibangu Muabila, René Manassé Galekwa, Hugues Kanda, Maximilien V. Dialufuma, Mbuyi Mukendi Didier, Kalala Kalonji, Serge Mundele, Patience Kinshie Lenye, Tighana Wenge Basele, Aristarque Ilunga, Christian N. Mayemba, Nathanaël M. Kasoro, Selain K. Kasereka, Hardy Mikese, Pierre-Martin Tardif, Marc Frappier, Froduald Kabanza, Belkacem Chikhaoui, Shengrui Wang, Ali Mulenda Sumbu, Xavier Ndona, Raoul Kienge-Kienge Intudi<br>Score: 7<br>Reason: The paper discusses the potential of using large language models and psycholinguistic features for psychological profiling in cybersecurity, which aligns with your interest in large language model pretraining and finetuning as well as your interest in cybersecurity.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          All Random Features Representations are Equivalent</a><br>Authors: Luke Sernau, Silvano Bonacina, Rif A. Saurous<br>Score: 7<br>Reason: The paper discusses the equivalence of different random features representations, which is not directly related to your research interests in large language model pretraining and finetuning or multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Navigating LLM Ethics: Advancements, Challenges, and Future Directions</a><br>Authors: Junfeng Jiao, Saleh Afroogh, Yiming Xu, Connor Phillips<br>Score: 7<br>Reason: The paper discusses the ethical challenges posed by large language models, which aligns with your interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          The global landscape of academic guidelines for generative AI and Large Language Models</a><br>Authors: Junfeng Jiao, Saleh Afroogh, Kevin Chen, David Atkinson, Amit Dhurandhar<br>Score: 7<br>Reason: The paper explores the global landscape of academic guidelines for generative AI and large language models, which aligns with your interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Learning Retrieval Augmentation for Personalized Dialogue Generation</a><br>Authors: Qiushi Huang, Shuai Fu, Xubo Liu, Wenwu Wang, Tom Ko, Yu Zhang, Lilian Tang<br>Score: 7<br>Reason: The paper proposes a method for personalized dialogue generation, which aligns with your interest in multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          FFN: a Fine-grained Chinese-English Financial Domain Parallel Corpus</a><br>Authors: Yuxin Fu, Shijing Si, Leyi Mai, Xi-ang Li<br>Score: 7<br>Reason: The paper presents a fine-grained Chinese-English parallel corpus in the financial domain, which aligns with your interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models</a><br>Authors: Vipul Rathore, Aniruddha Deb, Ankish Chandresh, Parag Singla, Mausam<br>Score: 7<br>Reason: This paper explores the effectiveness of self-supervised prompting for cross-lingual transfer to low-resource languages using large language models, which is relevant to your interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Factor-Conditioned Speaking-Style Captioning</a><br>Authors: Atsushi Ando, Takafumi Moriya, Shota Horiguchi, Ryo Masumura<br>Score: 7<br>Reason: This paper presents a novel speaking-style captioning method, which is relevant to your interest in multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          TrustUQA: A Trustful Framework for Unified Structured Data Question Answering</a><br>Authors: Wen Zhang, Long Jin, Yushan Zhu, Jiaoyan Chen, Zhiwei Huang, Junjie Wang, Yin Hua, Lei Liang, Huajun Chen<br>Score: 7<br>Reason: This paper proposes a trustful framework for unified structured data question answering, which is relevant to your interest in multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data</a><br>Authors: Yiting Ran, Xintao Wang, Rui Xu, Xinfeng Yuan, Jiaqing Liang, Yanghua Xiao, Deqing Yang<br>Score: 7<br>Reason: This paper enhances role-playing language models with personality-indicative data, which is relevant to your interest in multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Enhanced ASR Robustness to Packet Loss with a Front-End Adaptation Network</a><br>Authors: Yehoshua Dissen, Shiry Yonash, Israel Cohen, Joseph Keshet<br>Score: 7<br>Reason: The paper proposes a method for enhancing ASR models in noisy environments, which aligns with your interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Improving Weak-to-Strong Generalization with Reliability-Aware Alignment</a><br>Authors: Yue Guo, Yi Yang<br>Score: 7<br>Reason: The paper proposes a method for improving weak-to-strong generalization in large language models, which aligns with your interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning</a><br>Authors: Alexander Herzog, Robbie Southam, Ioannis Mavromatis, Aftab Khan<br>Score: 7<br>Reason: The paper proposes a method for communication-efficient federated learning, which aligns with your interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO</a><br>Authors: Fuseini Mumuni, Alhassan Mumuni<br>Score: 7<br>Reason: The paper addresses the limitations of using language descriptions for object detection and image segmentation, which is relevant to research interest in multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          AMBROSIA: A Benchmark for Parsing Ambiguous Questions into Database Queries</a><br>Authors: Irina Saparina, Mirella Lapata<br>Score: 7<br>Reason: The paper introduces a benchmark dataset for parsing ambiguous questions into database queries, which is relevant to research interest in information extraction and language understanding.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          YZS-model: A Predictive Model for Organic Drug Solubility Based on Graph Convolutional Networks and Transformer-Attention</a><br>Authors: Chenxu Wang, Haowei Ming, Jian He, Yao Lu<br>Score: 7<br>Reason: The paper proposes a predictive model for organic drug solubility using graph convolutional networks and transformers, which aligns with research interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          The Illusion of Competence: Evaluating the Effect of Explanations on Users' Mental Models of Visual Question Answering Systems</a><br>Authors: Judith Sieker, Simeon Junker, Ronja Utescher, Nazia Attari, Heiko Wersing, Hendrik Buschmeier, Sina Zarrieß<br>Score: 7<br>Reason: The paper investigates the effect of explanations on users' mental models of visual question answering systems, which aligns with research interest in multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          BISeizuRe: BERT-Inspired Seizure Data Representation to Improve Epilepsy Monitoring</a><br>Authors: Luca Benfenati, Thorir Mar Ingolfsson, Andrea Cossettini, Daniele Jahier Pagliari, Alessio Burrello, Luca Benini<br>Score: 7<br>Reason: This paper presents a novel approach for EEG-based seizure detection using a BERT-based model, which falls under the category of multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Think Step by Step: Chain-of-Gesture Prompting for Error Detection in Robotic Surgical Videos</a><br>Authors: Zhimin Shao, Jialang Xu, Danail Stoyanov, Evangelos B. Mazomenos, Yueming Jin<br>Score: 7<br>Reason: This paper proposes a chain-of-gesture prompting framework for error detection in robotic surgical videos, which falls under the category of multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Simulating Classroom Education with LLM-Empowered Agents</a><br>Authors: Zheyuan Zhang, Daniel Zhang-Li, Jifan Yu, Linlu Gong, Jinchang Zhou, Zhiyuan Liu, Lei Hou, Juanzi Li<br>Score: 7<br>Reason: This paper proposes a multi-agent classroom simulation framework using LLMs, which falls under the category of multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs</a><br>Authors: Ekaterina Taktasheva, Maxim Bazhukov, Kirill Koncha, Alena Fenogenova, Ekaterina Artemova<br>Score: 7<br>Reason: This paper introduces a benchmark for evaluating grammatical knowledge of language models in the context of minimal pairs, which falls under the category of large language model pretraining and fine-tuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation</a><br>Authors: Yuying Li, Gaoyang Liu, Yang Yang, Chen Wang<br>Score: 7<br>Reason: This paper investigates membership inference attacks against retrieval augmented generation models, which falls under the category of large language model pretraining and fine-tuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI</a><br>Authors: Kaveen Hiniduma, Suren Byna, Jean Luca Bez, Ravi Madduri<br>Score: 7<br>Reason: The paper introduces a framework for quantitative assessment of data readiness for AI, which is relevant to large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding</a><br>Authors: Yue Fan, Lei Ding, Ching-Chen Kuo, Shan Jiang, Yang Zhao, Xinze Guan, Jie Yang, Yi Zhang, Xin Eric Wang<br>Score: 7<br>Reason: The paper proposes a method for layout-aware GUI screen reading, which involves multimodal machine learning and may be relevant to large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data</a><br>Authors: Zheyang Xiong, Vasilis Papageorgiou, Kangwook Lee, Dimitris Papailiopoulos<br>Score: 7<br>Reason: The paper proposes a finetuning approach using synthetic data to improve retrieval capabilities in LLMs, which is relevant to large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          LiveBench: A Challenging, Contamination-Free LLM Benchmark</a><br>Authors: Colin White, Samuel Dooley, Manley Roberts, Arka Pal, Ben Feuer, Siddhartha Jain, Ravid Shwartz-Ziv, Neel Jain, Khalid Saifullah, Siddartha Naidu, Chinmay Hegde, Yann LeCun, Tom Goldstein, Willie Neiswanger, Micah Goldblum<br>Score: 7<br>Reason: The paper introduces a challenging and contamination-free LLM benchmark, which may be relevant to large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language</a><br>Authors: Lucky Susanto, Musa Izzanardi Wijanarko, Prasetia Anugrah Pratama, Traci Hong, Ika Idris, Alham Fikri Aji, Derry Wijaya<br>Score: 7<br>Reason: The paper introduces a dataset of hate speech and toxicity types for Indonesian language, which is not directly related to the research interests of large language model pretraining and multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          The Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models</a><br>Authors: Xiliang Zhu, Shayna Gardiner, Tere Roldán, David Rossouw<br>Score: 7<br>Reason: This paper compares the cross-lingual sentiment analysis capabilities of different language models, including large language models, which relates to your interest in multimodal machine learning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Suri: Multi-constraint Instruction Following for Long-form Text Generation</a><br>Authors: Chau Minh Pham, Simeng Sun, Mohit Iyyer<br>Score: 7<br>Reason: This paper focuses on multi-constraint instruction following for long-form text generation, which aligns with your interest in large language model pretraining and finetuning.<br><br>Title: <a href="https://arxiv.org/abs/">Title:
          Taming Data and Transformers for Audio Generation</a><br>Authors: Moayed Haji-Ali, Willi Menapace, Aliaksandr Siarohin, Guha Balakrishnan, Sergey Tulyakov, Vicente Ordonez<br>Score: 7<br>Reason: This paper introduces new models for audio generation, including a scalable transformer-based architecture, which aligns with your interest in multimodal machine learning.