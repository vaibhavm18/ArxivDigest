{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Reliable Interval Prediction of Minimum Operating Voltage Based on On-chip Monitors via Conformalized Quantile Regression", "authors": "Yuxuan Yin, Xiaoxiao Wang, Rebecca Chen, Chen He, Peng Li", "subjects": "Subjects:\nSystems and Control (eess.SY); Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)", "abstract": "Predicting the minimum operating voltage ($V_{min}$) of chips is one of the important techniques for improving the manufacturing testing flow, as well as ensuring the long-term reliability and safety of in-field systems. Current $V_{min}$ prediction methods often provide only point estimates, necessitating additional techniques for constructing prediction confidence intervals to cover uncertainties caused by different sources of variations. While some existing techniques offer region predictions, but they rely on certain distributional assumptions and/or provide no coverage guarantees. In response to these limitations, we propose a novel distribution-free $V_{min}$ interval estimation methodology possessing a theoretical guarantee of coverage. Our approach leverages conformalized quantile regression and on-chip monitors to generate reliable prediction intervals. We demonstrate the effectiveness of the proposed method on an industrial 5nm automotive chip dataset. Moreover, we show that the use of on-chip monitors can reduce the interval length significantly for $V_{min}$ prediction."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AddBiomechanics Dataset: Capturing the Physics of Human Motion at Scale", "authors": "Keenon Werling, Janelle Kaneda, Alan Tan, Rishi Agarwal, Six Skov, Tom Van Wouwe, Scott Uhlrich, Nicholas Bianco, Carmichael Ong, Antoine Falisse, Shardul Sapkota, Aidan Chandra, Joshua Carter, Ezio Preatoni, Benjamin Fregly, Jennifer Hicks, Scott Delp, C. Karen Liu", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Graphics (cs.GR); Robotics (cs.RO)", "abstract": "While reconstructing human poses in 3D from inexpensive sensors has advanced significantly in recent years, quantifying the dynamics of human motion, including the muscle-generated joint torques and external forces, remains a challenge. Prior attempts to estimate physics from reconstructed human poses have been hampered by a lack of datasets with high-quality pose and force data for a variety of movements. We present the AddBiomechanics Dataset 1.0, which includes physically accurate human dynamics of 273 human subjects, over 70 hours of motion and force plate data, totaling more than 24 million frames. To construct this dataset, novel analytical methods were required, which are also reported here. We propose a benchmark for estimating human dynamics from motion using this dataset, and present several baseline results. The AddBiomechanics Dataset is publicly available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          VideoQA-SC: Adaptive Semantic Communication for Video Question Answering", "authors": "Jiangyuan Guo, Wei Chen, Yuxuan Sun, Jialong Xu, Bo Ai", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)", "abstract": "Although semantic communication (SC) has shown its potential in efficiently transmitting multi-modal data such as text, speeches and images, SC for videos has focused primarily on pixel-level reconstruction. However, these SC systems may be suboptimal for downstream intelligent tasks. Moreover, SC systems without pixel-level video reconstruction present advantages by achieving higher bandwidth efficiency and real-time performance of various intelligent tasks. The difficulty in such system design lies in the extraction of task-related compact semantic representations and their accurate delivery over noisy channels. In this paper, we propose an end-to-end SC system for video question answering (VideoQA) tasks called VideoQA-SC. Our goal is to accomplish VideoQA tasks directly based on video semantics over noisy or fading wireless channels, bypassing the need for video reconstruction at the receiver. To this end, we develop a spatiotemporal semantic encoder for effective video semantic extraction, and a learning-based bandwidth-adaptive deep joint source-channel coding (DJSCC) scheme for efficient and robust video semantic transmission. Experiments demonstrate that VideoQA-SC outperforms traditional and advanced DJSCC-based SC systems that rely on video reconstruction at the receiver under a wide range of channel conditions and bandwidth constraints. In particular, when the signal-to-noise ratio is low, VideoQA-SC can improve the answer accuracy by 5.17% while saving almost 99.5% of the bandwidth at the same time, compared with the advanced DJSCC-based SC system. Our results show the great potential of task-oriented SC system design for video applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          TexPainter: Generative Mesh Texturing with Multi-view Consistency", "authors": "Hongkun Zhang, Zherong Pan, Congyi Zhang, Lifeng Zhu, Xifeng Gao", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)", "abstract": "The recent success of pre-trained diffusion models unlocks the possibility of the automatic generation of textures for arbitrary 3D meshes in the wild. However, these models are trained in the screen space, while converting them to a multi-view consistent texture image poses a major obstacle to the output quality. In this paper, we propose a novel method to enforce multi-view consistency. Our method is based on the observation that latent space in a pre-trained diffusion model is noised separately for each camera view, making it difficult to achieve multi-view consistency by directly manipulating the latent codes. Based on the celebrated Denoising Diffusion Implicit Models (DDIM) scheme, we propose to use an optimization-based color-fusion to enforce consistency and indirectly modify the latent codes by gradient back-propagation. Our method further relaxes the sequential dependency assumption among the camera views. By evaluating on a series of general 3D models, we find our simple approach improves consistency and overall quality of the generated textures as compared to competing state-of-the-arts. Our implementation is available at: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fully Exploiting Every Real Sample: SuperPixel Sample Gradient Model Stealing", "authors": "Yunlong Zhao, Xiaoheng Deng, Yijing Liu, Xinjun Pei, Jiazhi Xia, Wei Chen", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Cryptography and Security (cs.CR)", "abstract": "Model stealing (MS) involves querying and observing the output of a machine learning model to steal its capabilities. The quality of queried data is crucial, yet obtaining a large amount of real data for MS is often challenging. Recent works have reduced reliance on real data by using generative models. However, when high-dimensional query data is required, these methods are impractical due to the high costs of querying and the risk of model collapse. In this work, we propose using sample gradients (SG) to enhance the utility of each real sample, as SG provides crucial guidance on the decision boundaries of the victim model. However, utilizing SG in the model stealing scenario faces two challenges: 1. Pixel-level gradient estimation requires extensive query volume and is susceptible to defenses. 2. The estimation of sample gradients has a significant variance. This paper proposes Superpixel Sample Gradient stealing (SPSG) for model stealing under the constraint of limited real samples. With the basic idea of imitating the victim model's low-variance patch-level gradients instead of pixel-level gradients, SPSG achieves efficient sample gradient estimation through two steps. First, we perform patch-wise perturbations on query images to estimate the average gradient in different regions of the image. Then, we filter the gradients through a threshold strategy to reduce variance. Exhaustive experiments demonstrate that, with the same number of real samples, SPSG achieves accuracy, agreements, and adversarial success rate significantly surpassing the current state-of-the-art MS methods. Codes are available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Refining 3D Point Cloud Normal Estimation via Sample Selection", "authors": "Jun Zhou, Yaoshun Li, Hongchen Tan, Mingjie Wang, Nannan Li, Xiuping Liu", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)", "abstract": "In recent years, point cloud normal estimation, as a classical and foundational algorithm, has garnered extensive attention in the field of 3D geometric processing. Despite the remarkable performance achieved by current Neural Network-based methods, their robustness is still influenced by the quality of training data and the models' performance. In this study, we designed a fundamental framework for normal estimation, enhancing existing model through the incorporation of global information and various constraint mechanisms. Additionally, we employed a confidence-based strategy to select the reasonable samples for fair and robust network training. The introduced sample confidence can be integrated into the loss function to balance the influence of different samples on model training. Finally, we utilized existing orientation methods to correct estimated non-oriented normals, achieving state-of-the-art performance in both oriented and non-oriented tasks. Extensive experimental results demonstrate that our method works well on the widely used benchmarks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Generative AI Empowered LiDAR Point Cloud Generation with Multimodal Transformer", "authors": "Mohammad Farzanullah, Han Zhang, Akram Bin Sediq, Ali Afana, Melike Erol-Kantarci", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP)", "abstract": "Integrated sensing and communications is a key enabler for the 6G wireless communication systems. The multiple sensing modalities will allow the base station to have a more accurate representation of the environment, leading to context-aware communications. Some widely equipped sensors such as cameras and RADAR sensors can provide some environmental perceptions. However, they are not enough to generate precise environmental representations, especially in adverse weather conditions. On the other hand, the LiDAR sensors provide more accurate representations, however, their widespread adoption is hindered by their high cost. This paper proposes a novel approach to enhance the wireless communication systems by synthesizing LiDAR point clouds from images and RADAR data. Specifically, it uses a multimodal transformer architecture and pre-trained encoding models to enable an accurate LiDAR generation. The proposed framework is evaluated on the DeepSense 6G dataset, which is a real-world dataset curated for context-aware wireless applications. Our results demonstrate the efficacy of the proposed approach in accurately generating LiDAR point clouds. We achieve a modified mean squared error of 10.3931. Visual examination of the images indicates that our model can successfully capture the majority of structures present in the LiDAR point cloud for diverse environments. This will enable the base stations to achieve more precise environmental sensing. By integrating LiDAR synthesis with existing sensing modalities, our method can enhance the performance of various wireless applications, including beam and blockage prediction."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Set-based Approach for Feature Extraction of 3D CAD Models", "authors": "Peng Xu, Qi Gao, Ying-Jie Wu", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Feature extraction is a critical technology to realize the automatic transmission of feature information throughout product life cycles. As CAD models primarily capture the 3D geometry of products, feature extraction heavily relies on geometric information. However, existing feature extraction methods often yield inaccurate outcomes due to the diverse interpretations of geometric information. This report presents a set-based feature extraction approach to address this uncertainty issue. Unlike existing methods that seek accurate feature results, our approach aims to transform the uncertainty of geometric information into a set of feature subgraphs. First, we define the convexity of basic geometric entities and introduce the concept of two-level attributed adjacency graphs. Second, a feature extraction workflow is designed to determine feature boundaries and identify feature subgraphs from CAD models. This set of feature subgraphs can be used for further feature recognition. A feature extraction system is programmed using C++ and UG/Open to demonstrate the feasibility of our proposed approach."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          GS-ROR: 3D Gaussian Splatting for Reflective Object Relighting via SDF Priors", "authors": "Zuo-Liang Zhu, Beibei Wang, Jian Yang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)", "abstract": "3D Gaussian Splatting (3DGS) has shown a powerful capability for novel view synthesis due to its detailed expressive ability and highly efficient rendering speed. Unfortunately, creating relightable 3D assets with 3DGS is still problematic, particularly for reflective objects, as its discontinuous representation raises difficulties in constraining geometries. Inspired by previous works, the signed distance field (SDF) can serve as an effective way for geometry regularization. However, a direct incorporation between Gaussians and SDF significantly slows training. To this end, we propose GS-ROR for reflective objects relighting with 3DGS aided by SDF priors. At the core of our method is the mutual supervision of the depth and normal between deferred Gaussians and SDF, which avoids the expensive volume rendering of SDF. Thanks to this mutual supervision, the learned deferred Gaussians are well-constrained with a minimal time cost. As the Gaussians are rendered in a deferred shading mode, while the alpha-blended Gaussians are smooth, individual Gaussians may still be outliers, yielding floater artifacts. Therefore, we further introduce an SDF-aware pruning strategy to remove Gaussian outliers, which are located distant from the surface defined by SDF, avoiding the floater issue. Consequently, our method outperforms the existing Gaussian-based inverse rendering methods in terms of relighting quality. Our method also exhibits competitive relighting quality compared to NeRF-based methods with at most 25% of training time and allows rendering at 200+ frames per second on an RTX4090."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Visual Analysis of Prediction Uncertainty in Neural Networks for Deep Image Synthesis", "authors": "Soumya Dutta, Faheem Nizar, Ahmad Amaan, Ayan Acharya", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Ubiquitous applications of Deep neural networks (DNNs) in different artificial intelligence systems have led to their adoption in solving challenging visualization problems in recent years. While sophisticated DNNs offer an impressive generalization, it is imperative to comprehend the quality, confidence, robustness, and uncertainty associated with their prediction. A thorough understanding of these quantities produces actionable insights that help application scientists make informed decisions. Unfortunately, the intrinsic design principles of the DNNs cannot beget prediction uncertainty, necessitating separate formulations for robust uncertainty-aware models for diverse visualization applications. To that end, this contribution demonstrates how the prediction uncertainty and sensitivity of DNNs can be estimated efficiently using various methods and then interactively compared and contrasted for deep image synthesis tasks. Our inspection suggests that uncertainty-aware deep visualization models generate illustrations of informative and superior quality and diversity. Furthermore, prediction uncertainty improves the robustness and interpretability of deep visualization models, making them practical and convenient for various scientific domains that thrive on visual analyses."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Application of Multimodal Fusion Deep Learning Model in Disease Recognition", "authors": "Xiaoyi Liu, Hongjie Qiu, Muqing Li, Zhou Yu, Yutian Yang, Yafeng Yan", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "This paper introduces an innovative multi-modal fusion deep learning approach to overcome the drawbacks of traditional single-modal recognition techniques. These drawbacks include incomplete information and limited diagnostic accuracy. During the feature extraction stage, cutting-edge deep learning models including convolutional neural networks (CNN), recurrent neural networks (RNN), and transformers are applied to distill advanced features from image-based, temporal, and structured data sources. The fusion strategy component seeks to determine the optimal fusion mode tailored to the specific disease recognition task. In the experimental section, a comparison is made between the performance of the proposed multi-mode fusion model and existing single-mode recognition methods. The findings demonstrate significant advantages of the multimodal fusion model across multiple evaluation metrics."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Pre-Trained Vision-Language Models as Partial Annotators", "authors": "Qian-Wei Wang, Yuqiu Xie, Letian Zhang, Zimo Liu, Shu-Tao Xia", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Pre-trained vision-language models learn massive data to model unified representations of images and natural languages, which can be widely applied to downstream machine learning tasks. In addition to zero-shot inference, in order to better adapt pre-trained models to the requirements of downstream tasks, people usually use methods such as few-shot or parameter-efficient fine-tuning and knowledge distillation. However, annotating samples is laborious, while a large number of unlabeled samples can be easily obtained. In this paper, we investigate a novel \"pre-trained annotating - weakly-supervised learning\" paradigm for pre-trained model application and experiment on image classification tasks. Specifically, based on CLIP, we annotate image samples with multiple prompt templates to obtain multiple candidate labels to form the noisy partial label dataset, and design a collaborative consistency regularization algorithm to solve this problem. Our method simultaneously trains two neural networks, which collaboratively purify training labels for each other and obtain pseudo-labels for self-training, while adopting prototypical similarity alignment and noisy supervised contrastive learning to optimize model representation. In experiments, our method achieves performances far beyond zero-shot inference without introducing additional label information, and outperforms other weakly supervised learning and few-shot fine-tuning methods, and obtains smaller deployed models. Our code is available at: \\url{https://anonymous.4open.science/r/Co-Reg-8CF9}."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          GFFE: G-buffer Free Frame Extrapolation for Low-latency Real-time Rendering", "authors": "Songyin Wu, Deepak Vembar, Anton Sochenov, Selvakumar Panneer, Sungye Kim, Anton Kaplanyan, Ling-Qi Yan", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)", "abstract": "Real-time rendering has been embracing ever-demanding effects, such as ray tracing. However, rendering such effects in high resolution and high frame rate remains challenging. Frame extrapolation methods, which don't introduce additional latency as opposed to frame interpolation methods such as DLSS 3 and FSR 3, boost the frame rate by generating future frames based on previous frames. However, it is a more challenging task because of the lack of information in the disocclusion regions, and recent methods also have a high engine integration cost due to requiring G-buffers as input. We propose a \\emph{G-buffer free} frame extrapolation, GFFE, with a novel heuristic framework and an efficient neural network, to plausibly generate new frames in real-time without introducing additional latency. We analyze the motion of dynamic fragments and different types of disocclusions, and design the corresponding modules of the extrapolation block to handle them. After filling disocclusions, a light-weight shading correction network is used to correct shading and improve overall quality. GFFE achieves comparable or better results compared to previous interpolation as well as G-buffer-dependent extrapolation methods, with more efficient performance and easier game integration."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery", "authors": "Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "In medical imaging, particularly in early disease detection and prognosis tasks, discerning the rationale behind an AI model's predictions is crucial for evaluating the reliability of its decisions. Conventional explanation methods face challenges in identifying discernible decisive features in medical image classifications, where discriminative features are subtle or not immediately apparent. To bridge this gap, we propose an explainable model that is equipped with both decision reasoning and feature identification capabilities. Our approach not only detects influential image patterns but also uncovers the decisive features that drive the model's final predictions. By implementing our method, we can efficiently identify and visualise class-specific features leveraged by the data-driven model, providing insights into the decision-making processes of deep learning models. We validated our model in the demanding realm of medical prognosis task, demonstrating its efficacy and potential in enhancing the reliability of AI in healthcare and in discovering new knowledge in diseases where prognostic understanding is limited."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A PST Algorithm for FPs Suppression in Two-stage CNN Detection Methods", "authors": "Qiang Guo", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Pedestrian detection has been a hot spot in computer vision over the past decades due to the wide spectrum of promising applications, the major challenge of which is False Positives (FPs) that occur during pedestrian detection. The emergence various Convolutional Neural Network-based detection strategies substantially enhance the pedestrian detection accuracy but still not well solve this problem. This paper deeply analysis the detection framework of the two-stage CNN detection methods and find out false positives in detection results is due to its training strategy miss classify some false proposals, thus weakens the classification capability of following subnetwork and hardly to suppress false ones. To solve this problem, This paper proposes a pedestrian-sensitive training algorithm to effectively help two-stage CNN detection methods learn to distinguish the pedestrian and non-pedestrian samples and suppress the false positives in final detection results. The core of the proposed training algorithm is to redesign the training proposal generating pipeline of the two-stage CNN detection methods, which can avoid a certain number of false ones that mislead its training process. With the help of the proposed algorithm, the detection accuracy of the MetroNext, an smaller and accurate metro passenger detector, is further improved, which further decreases false ones in its metro passengers detection results. Based on various challenging benchmark datasets, experiment results have demonstrated that feasibility of the proposed algorithm to improve pedestrian detection accuracy by removing the false positives. Compared with the competitors, MetroNext-PST demonstrates better overall prediction performance in accuracy, total number of parameters, and inference time, thus it can become a practical solution for hunting pedestrian tailored for mobile and edge devices."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Planted: a dataset for planted forest identification from multi-satellite time series", "authors": "Luis Miguel Pazos-Out\u00f3n, Cristina Nader Vasconcelos, Anton Raichuk, Anurag Arnab, Dan Morris, Maxim Neumann", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Protecting and restoring forest ecosystems is critical for biodiversity conservation and carbon sequestration. Forest monitoring on a global scale is essential for prioritizing and assessing conservation efforts. Satellite-based remote sensing is the only viable solution for providing global coverage, but to date, large-scale forest monitoring is limited to single modalities and single time points. In this paper, we present a dataset consisting of data from five public satellites for recognizing forest plantations and planted tree species across the globe. Each satellite modality consists of a multi-year time series. The dataset, named \\PlantD, includes over 2M examples of 64 tree label classes (46 genera and 40 species), distributed among 41 countries. This dataset is released to foster research in forest monitoring using multimodal, multi-scale, multi-temporal data sources. Additionally, we present initial baseline results and evaluate modality fusion and data augmentation approaches for this dataset."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Experimental Evaluation of Road-Crossing Decisions by Autonomous Wheelchairs against Environmental Factors", "authors": "Franca Corradini, Carlo Grigioni, Alessandro Antonucci, J\u00e9r\u00f4me Guzzi, Francesco Flammini", "subjects": "Subjects:\nRobotics (cs.RO); Artificial Intelligence (cs.AI)", "abstract": "Safe road crossing by autonomous wheelchairs can be affected by several environmental factors such as adverse weather conditions influencing the accuracy of artificial vision. Previous studies have addressed experimental evaluation of multi-sensor information fusion to support road-crossing decisions in autonomous wheelchairs. In this study, we focus on the fine-tuning of tracking performance and on its experimental evaluation against outdoor environmental factors such as fog, rain, darkness, etc. It is rather intuitive that those factors can negatively affect the tracking performance; therefore our aim is to provide an approach to quantify their effects in the reference scenario, in order to detect conditions of unacceptable accuracy. In those cases, warnings can be issued and system can be possibly reconfigured to reduce the reputation of less accurate sensors, and thus improve overall safety. Critical situations can be detected by the main sensors or by additional sensors, e.g., light sensors, rain sensors, etc. Results have been achieved by using an available laboratory dataset and by applying appropriate software filters; they show that the approach can be adopted to evaluate video tracking and event detection robustness against outdoor environmental factors in relevant operational scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          BAISeg: Boundary Assisted Weakly Supervised Instance Segmentation", "authors": "Tengbo Wang, Yu Bai", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)", "abstract": "How to extract instance-level masks without instance-level supervision is the main challenge of weakly supervised instance segmentation (WSIS). Popular WSIS methods estimate a displacement field (DF) via learning inter-pixel relations and perform clustering to identify instances. However, the resulting instance centroids are inherently unstable and vary significantly across different clustering algorithms. In this paper, we propose Boundary-Assisted Instance Segmentation (BAISeg), which is a novel paradigm for WSIS that realizes instance segmentation with pixel-level annotations. BAISeg comprises an instance-aware boundary detection (IABD) branch and a semantic segmentation branch. The IABD branch identifies instances by predicting class-agnostic instance boundaries rather than instance centroids, therefore, it is different from previous DF-based approaches. In particular, we proposed the Cascade Fusion Module (CFM) and the Deep Mutual Attention (DMA) in the IABD branch to obtain rich contextual information and capture instance boundaries with weak responses. During the training phase, we employed Pixel-to-Pixel Contrast to enhance the discriminative capacity of the IABD branch. This further strengthens the continuity and closedness of the instance boundaries. Extensive experiments on PASCAL VOC 2012 and MS COCO demonstrate the effectiveness of our approach, and we achieve considerable performance with only pixel-level annotations. The code will be available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Revision Matters: Generative Design Guided by Revision Edits", "authors": "Tao Li, Chin-Yi Cheng, Amber Xie, Gang Li, Yang Li", "subjects": "Subjects:\nHuman-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Layout design, such as user interface or graphical layout in general, is fundamentally an iterative revision process. Through revising a design repeatedly, the designer converges on an ideal layout. In this paper, we investigate how revision edits from human designer can benefit a multimodal generative model. To do so, we curate an expert dataset that traces how human designers iteratively edit and improve a layout generation with a prompted language goal. Based on such data, we explore various supervised fine-tuning task setups on top of a Gemini multimodal backbone, a large multimodal model. Our results show that human revision plays a critical role in iterative layout refinement. While being noisy, expert revision edits lead our model to a surprisingly strong design FID score ~10 which is close to human performance (~6). In contrast, self-revisions that fully rely on model's own judgement, lead to an echo chamber that prevents iterative improvement, and sometimes leads to generative degradation. Fortunately, we found that providing human guidance plays at early stage plays a critical role in final generation. In such human-in-the-loop scenario, our work paves the way for iterative design revision based on pre-trained large multimodal models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SelMatch: Effectively Scaling Up Dataset Distillation via Selection-Based Initialization and Partial Updates by Trajectory Matching", "authors": "Yongmin Lee, Hye Won Chung", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Dataset distillation aims to synthesize a small number of images per class (IPC) from a large dataset to approximate full dataset training with minimal performance loss. While effective in very small IPC ranges, many distillation methods become less effective, even underperforming random sample selection, as IPC increases. Our examination of state-of-the-art trajectory-matching based distillation methods across various IPC scales reveals that these methods struggle to incorporate the complex, rare features of harder samples into the synthetic dataset even with the increased IPC, resulting in a persistent coverage gap between easy and hard test samples. Motivated by such observations, we introduce SelMatch, a novel distillation method that effectively scales with IPC. SelMatch uses selection-based initialization and partial updates through trajectory matching to manage the synthetic dataset's desired difficulty level tailored to IPC scales. When tested on CIFAR-10/100 and TinyImageNet, SelMatch consistently outperforms leading selection-only and distillation-only methods across subset ratios from 5% to 30%."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Views Can Be Deceiving: Improved SSL Through Feature Space Augmentation", "authors": "Kimia Hamidieh, Haoran Zhang, Swami Sankaranarayanan, Marzyeh Ghassemi", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Supervised learning methods have been found to exhibit inductive biases favoring simpler features. When such features are spuriously correlated with the label, this can result in suboptimal performance on minority subgroups. Despite the growing popularity of methods which learn from unlabeled data, the extent to which these representations rely on spurious features for prediction is unclear. In this work, we explore the impact of spurious features on Self-Supervised Learning (SSL) for visual representation learning. We first empirically show that commonly used augmentations in SSL can cause undesired invariances in the image space, and illustrate this with a simple example. We further show that classical approaches in combating spurious correlations, such as dataset re-sampling during SSL, do not consistently lead to invariant representations. Motivated by these findings, we propose LateTVG to remove spurious information from these representations during pre-training, by regularizing later layers of the encoder via pruning. We find that our method produces representations which outperform the baselines on several benchmarks, without the need for group or label information during SSL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Interdisciplinary Expertise to Advance Equitable Explainable AI", "authors": "Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles", "subjects": "Subjects:\nComputers and Society (cs.CY); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "The field of artificial intelligence (AI) is rapidly influencing health and healthcare, but bias and poor performance persists for populations who face widespread structural oppression. Previous work has clearly outlined the need for more rigorous attention to data representativeness and model performance to advance equity and reduce bias. However, there is an opportunity to also improve the explainability of AI by leveraging best practices of social epidemiology and health equity to help us develop hypotheses for associations found. In this paper, we focus on explainable AI (XAI) and describe a framework for interdisciplinary expert panel review to discuss and critically assess AI model explanations from multiple perspectives and identify areas of bias and directions for future research. We emphasize the importance of the interdisciplinary expert panel to produce more accurate, equitable interpretations which are historically and contextually informed. Interdisciplinary panel discussions can help reduce bias, identify potential confounders, and identify opportunities for additional research where there are gaps in the literature. In turn, these insights can suggest opportunities for AI model improvement."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Rotation Averaging: A Primal-Dual Method and Closed-Forms in Cycle Graphs", "authors": "Gabriel Moreira, Manuel Marques, Jo\u00e3o Paulo Costeira", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "abstract": "A cornerstone of geometric reconstruction, rotation averaging seeks the set of absolute rotations that optimally explains a set of measured relative orientations between them. In addition to being an integral part of bundle adjustment and structure-from-motion, the problem of synchronizing rotations also finds applications in visual simultaneous localization and mapping, where it is used as an initialization for iterative solvers, and camera network calibration. Nevertheless, this optimization problem is both non-convex and high-dimensional. In this paper, we address it from a maximum likelihood estimation standpoint and make a twofold contribution. Firstly, we set forth a novel primal-dual method, motivated by the widely accepted spectral initialization. Further, we characterize stationary points of rotation averaging in cycle graphs topologies and contextualize this result within spectral graph theory. We benchmark the proposed method in multiple settings and certify our solution via duality theory, achieving a significant gain in precision and performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Pseudo-label Based Domain Adaptation for Zero-Shot Text Steganalysis", "authors": "Yufei Luo, Zhen Yang, Ru Zhang, Jianyi Liu", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Currently, most methods for text steganalysis are based on deep neural networks (DNNs). However, in real-life scenarios, obtaining a sufficient amount of labeled stego-text for correctly training networks using a large number of parameters is often challenging and costly. Additionally, due to a phenomenon known as dataset bias or domain shift, recognition models trained on a large dataset exhibit poor generalization performance on novel datasets and tasks. Therefore, to address the issues of missing labeled data and inadequate model generalization in text steganalysis, this paper proposes a cross-domain stego-text analysis method (PDTS) based on pseudo-labeling and domain adaptation (unsupervised learning). Specifically, we propose a model architecture combining pre-trained BERT with a single-layer Bi-LSTM to learn and extract generic features across tasks and generate task-specific representations. Considering the differential contributions of different features to steganalysis, we further design a feature filtering mechanism to achieve selective feature propagation, thereby enhancing classification performance. We train the model using labeled source domain data and adapt it to target domain data distribution using pseudo-labels for unlabeled target domain data through self-training. In the label estimation step, instead of using a static sampling strategy, we propose a progressive sampling strategy to gradually increase the number of selected pseudo-label candidates. Experimental results demonstrate that our method performs well in zero-shot text steganalysis tasks, achieving high detection accuracy even in the absence of labeled data in the target domain, and outperforms current zero-shot text steganalysis methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Memorized Images in Diffusion Models share a Subspace that can be Located and Deleted", "authors": "Ruchika Chavhan, Ondrej Bohdal, Yongshuo Zong, Da Li, Timothy Hospedales", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Large-scale text-to-image diffusion models excel in generating high-quality images from textual inputs, yet concerns arise as research indicates their tendency to memorize and replicate training data, raising We also addressed the issue of memorization in diffusion models, where models tend to replicate exact training samples raising copyright infringement and privacy issues. Efforts within the text-to-image community to address memorization explore causes such as data duplication, replicated captions, or trigger tokens, proposing per-prompt inference-time or training-time mitigation strategies. In this paper, we focus on the feed-forward layers and begin by contrasting neuron activations of a set of memorized and non-memorized prompts. Experiments reveal a surprising finding: many different sets of memorized prompts significantly activate a common subspace in the model, demonstrating, for the first time, that memorization in the diffusion models lies in a special subspace. Subsequently, we introduce a novel post-hoc method for editing pre-trained models, whereby memorization is mitigated through the straightforward pruning of weights in specialized subspaces, avoiding the need to disrupt the training or inference process as seen in prior research. Finally, we demonstrate the robustness of the pruned model against training data extraction attacks, thereby unveiling new avenues for a practical and one-for-all solution to memorization."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Research on Image Processing and Vectorization Storage Based on Garage Electronic Maps", "authors": "Nan Dou, Qi Shi, Zhigang Lian", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Databases (cs.DB)", "abstract": "For the purpose of achieving a more precise definition and data analysis of images, this study conducted a research on vectorization and rasterization storage of electronic maps, focusing on a large underground parking garage map. During the research, image processing, vectorization and rasterization storage were performed. The paper proposed a method for the vectorization classification storage of indoor two-dimensional map raster data. This method involves converting raster data into vector data and classifying elements such as parking spaces, pathways, and obstacles based on their coordinate positions with the grid indexing method, thereby facilitating efficient storage and rapid querying of indoor maps. Additionally, interpolation algorithms were employed to extract vector data and convert it into raster data. Navigation testing was conducted to validate the accuracy and reliability of the map model under this method, providing effective technical support for the digital storage and navigation of garage maps."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Diagnostic Model for Acute Lymphoblastic Leukemia Using Metaheuristics and Deep Learning Methods", "authors": "M. Hosseinzadeh, P. Khoshaght, S. Sadeghi, P. Asghari, Z. Arabi, J. Lansky, P. Budinsky, A. Masoud Rahmani, S. W. Lee", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Acute lymphoblastic leukemia (ALL) severity is determined by the presence and ratios of blast cells (abnormal white blood cells) in both bone marrow and peripheral blood. Manual diagnosis of this disease is a tedious and time-consuming operation, making it difficult for professionals to accurately examine blast cell characteristics. To address this difficulty, researchers use deep learning and machine learning. In this paper, a ResNet-based feature extractor is utilized to detect ALL, along with a variety of feature selectors and classifiers. To get the best results, a variety of transfer learning models, including the Resnet, VGG, EfficientNet, and DensNet families, are used as deep feature extractors. Following extraction, different feature selectors are used, including Genetic algorithm, PCA, ANOVA, Random Forest, Univariate, Mutual information, Lasso, XGB, Variance, and Binary ant colony. After feature qualification, a variety of classifiers are used, with MLP outperforming the others. The recommended technique is used to categorize ALL and HEM in the selected dataset which is C-NMC 2019. This technique got an impressive 90.71% accuracy and 95.76% sensitivity for the relevant classifications, and its metrics on this dataset outperformed others."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FLOW: Fusing and Shuffling Global and Local Views for Cross-User Human Activity Recognition with IMUs", "authors": "Qi Qiu, Tao Zhu, Furong Duan, Kevin I-Kai Wang, Liming Chen, Mingxing Nie, Mingxing Nie", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Inertial Measurement Unit (IMU) sensors are widely employed for Human Activity Recognition (HAR) due to their portability, energy efficiency, and growing research interest. However, a significant challenge for IMU-HAR models is achieving robust generalization performance across diverse users. This limitation stems from substantial variations in data distribution among individual users. One primary reason for this distribution disparity lies in the representation of IMU sensor data in the local coordinate system, which is susceptible to subtle user variations during IMU wearing. To address this issue, we propose a novel approach that extracts a global view representation based on the characteristics of IMU data, effectively alleviating the data distribution discrepancies induced by wearing styles. To validate the efficacy of the global view representation, we fed both global and local view data into model for experiments. The results demonstrate that global view data significantly outperforms local view data in cross-user experiments. Furthermore, we propose a Multi-view Supervised Network (MVFNet) based on Shuffling to effectively fuse local view and global view data. It supervises the feature extraction of each view through view division and view shuffling, so as to avoid the model ignoring important features as much as possible. Extensive experiments conducted on OPPORTUNITY and PAMAP2 datasets demonstrate that the proposed algorithm outperforms the current state-of-the-art methods in cross-user HAR."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          It's a Feature, Not a Bug: Measuring Creative Fluidity in Image Generators", "authors": "Aditi Ramaswamy, Melane Navaratnarajah, Hana Chockler", "subjects": "Subjects:\nHuman-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "With the rise of freely available image generators, AI-generated art has become the centre of a series of heated debates, one of which concerns the concept of human creativity. Can an image generation AI exhibit ``creativity'' of the same type that artists do, and if so, how does that manifest? Our paper attempts to define and empirically measure one facet of creative behavior in AI, by conducting an experiment to quantify the \"fluidity of prompt interpretation\", or just \"fluidity\", in a series of selected popular image generators. To study fluidity, we (1) introduce a clear definition for it, (2) create chains of auto-generated prompts and images seeded with an initial \"ground-truth: image, (3) measure these chains' breakage points using preexisting visual and semantic metrics, and (4) use both statistical tests and visual explanations to study these chains and determine whether the image generators used to produce them exhibit significant fluidity."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          UltraCortex: Submillimeter Ultra-High Field 9.4 T1 Brain MR Image Collection and Manual Cortical Segmentations", "authors": "Lucas Mahler, Julius Steiglechner, Benjamin Bender, Tobias Lindig, Dana Ramadan, Jonas Bause, Florian Birk, Rahel Heule, Edyta Charyasz, Michael Erb, Vinod Jangir Kumar, Gisela E Hagberg, Pascal Martin, Gabriele Lohmann, Klaus Scheffler", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "The UltraCortex repository (this https URL) houses magnetic resonance imaging data of the human brain obtained at an ultra-high field strength of 9.4 T. It contains 86 structural MR images with spatial resolutions ranging from 0.6 to 0.8 mm. Additionally, the repository includes segmentations of 12 brains into gray and white matter compartments. These segmentations have been independently validated by two expert neuroradiologists, thus establishing them as a reliable gold standard. This resource provides researchers with access to high-quality brain imaging data and validated segmentations, facilitating neuroimaging studies and advancing our understanding of brain structure and function. Existing repositories do not accommodate field strengths beyond 7 T, nor do they offer validated segmentations, underscoring the significance of this new resource."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          GeoReasoner: Geo-localization with Reasoning in Street Views using a Large Vision-Language Model", "authors": "Ling Li, Yu Ye, Bingchuan Jiang, Wei Zeng", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "This work tackles the problem of geo-localization with a new paradigm using a large vision-language model (LVLM) augmented with human inference knowledge. A primary challenge here is the scarcity of data for training the LVLM - existing street-view datasets often contain numerous low-quality images lacking visual clues, and lack any reasoning inference. To address the data-quality issue, we devise a CLIP-based network to quantify the degree of street-view images being locatable, leading to the creation of a new dataset comprising highly locatable street views. To enhance reasoning inference, we integrate external knowledge obtained from real geo-localization games, tapping into valuable human inference capabilities. The data are utilized to train GeoReasoner, which undergoes fine-tuning through dedicated reasoning and location-tuning stages. Qualitative and quantitative evaluations illustrate that GeoReasoner outperforms counterpart LVLMs by more than 25% at country-level and 38% at city-level geo-localization tasks, and surpasses StreetCLIP performance while requiring fewer training resources. The data and code are available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Generating grid maps via the snake model", "authors": "Zhiwei Wei, Nai Yang, Wenjia Xu, Su Ding", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY); Graphics (cs.GR)", "abstract": "The grid map, often referred to as the tile map, stands as a vital tool in geospatial visualization, possessing unique attributes that differentiate it from more commonly known techniques such as choropleths and cartograms. It transforms geographic regions into grids, which requires the displacement of both region centroids and boundary nodes to establish a coherent grid arrangement. However, existing approaches typically displace region centroids and boundary nodes separately, potentially resulting in self-intersected boundaries and compromised relative orientation relations between regions. In this paper, we introduce a novel approach that leverages the Snake displacement algorithm from cartographic generalization to concurrently displace region centroids and boundary nodes. The revised Constrained Delaunay triangulation (CDT) is employed to represent the relations between regions and serves as a structural foundation for the Snake algorithm. Forces for displacing the region centroids into a grid-like pattern are then computed. These forces are iteratively applied within the Snake model until a satisfactory new boundary is achieved. Subsequently, the grid map is created by aligning the grids with the newly generated boundary, utilizing a one-to-one match algorithm to assign each region to a specific grid. Experimental results demonstrate that the proposed approach excels in maintaining the relative orientation and global shape of regions, albeit with a potential increase in local location deviations. We also present two strategies aligned with existing approaches to generate diverse grid maps for user preferences. Further details and resources are available on our project website: this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Unsupervised Few-Shot Continual Learning for Remote Sensing Image Scene Classification", "authors": "Muhammad Anwar Ma'sum, Mahardhika Pratama, Ramasamy Savitha, Lin Liu, Habibullah, Ryszard Kowalczyk", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "A continual learning (CL) model is desired for remote sensing image analysis because of varying camera parameters, spectral ranges, resolutions, etc. There exist some recent initiatives to develop CL techniques in this domain but they still depend on massive labelled samples which do not fully fit remote sensing applications because ground truths are often obtained via field-based surveys. This paper addresses this problem with a proposal of unsupervised flat-wide learning approach (UNISA) for unsupervised few-shot continual learning approaches of remote sensing image scene classifications which do not depend on any labelled samples for its model updates. UNISA is developed from the idea of prototype scattering and positive sampling for learning representations while the catastrophic forgetting problem is tackled with the flat-wide learning approach combined with a ball generator to address the data scarcity problem. Our numerical study with remote sensing image scene datasets and a hyperspectral dataset confirms the advantages of our solution. Source codes of UNISA are shared publicly in \\url{this https URL} to allow convenient future studies and reproductions of our numerical results."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Research on Driver Facial Fatigue Detection Based on Yolov8 Model", "authors": "Chang Zhou, Yang Zhao, Shaobo Liu, Yi Zhao, Xingchen Li, Chiyu Cheng", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "In a society where traffic accidents frequently occur, fatigue driving has emerged as a grave issue. Fatigue driving detection technology, especially those based on the YOLOv8 deep learning model, has seen extensive research and application as an effective preventive measure. This paper discusses in depth the methods and technologies utilized in the YOLOv8 model to detect driver fatigue, elaborates on the current research status both domestically and internationally, and systematically introduces the processing methods and algorithm principles for various datasets. This study aims to provide a robust technical solution for preventing and detecting fatigue driving, thereby contributing significantly to reducing traffic accidents and safeguarding lives."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Negative Prototypes Guided Contrastive Learning for WSOD", "authors": "Yu Zhang, Chuang Zhu, Guoqing Yang, Siqi Chen", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Weakly Supervised Object Detection (WSOD) with only image-level annotation has recently attracted wide attention. Many existing methods ignore the inter-image relationship of instances which share similar characteristics while can certainly be determined not to belong to the same category. Therefore, in order to make full use of the weak label, we propose the Negative Prototypes Guided Contrastive learning (NPGC) architecture. Firstly, we define Negative Prototype as the proposal with the highest confidence score misclassified for the category that does not appear in the label. Unlike other methods that only utilize category positive feature, we construct an online updated global feature bank to store both positive prototypes and negative prototypes. Meanwhile, we propose a pseudo label sampling module to mine reliable instances and discard the easily misclassified instances based on the feature similarity with corresponding prototypes in global feature bank. Finally, we follow the contrastive learning paradigm to optimize the proposal's feature representation by attracting same class samples closer and pushing different class samples away in the embedding space. Extensive experiments have been conducted on VOC07, VOC12 datasets, which shows that our proposed method achieves the state-of-the-art performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Hire: Hybrid-modal Interaction with Multiple Relational Enhancements for Image-Text Matching", "authors": "Xuri Ge, Fuhai Chen, Songpei Xu, Fuxiang Tao, Jie Wang, Joemon M. Jose", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR)", "abstract": "Image-text matching (ITM) is a fundamental problem in computer vision. The key issue lies in jointly learning the visual and textual representation to estimate their similarity accurately. Most existing methods focus on feature enhancement within modality or feature interaction across modalities, which, however, neglects the contextual information of the object representation based on the inter-object relationships that match the corresponding sentences with rich contextual semantics. In this paper, we propose a Hybrid-modal Interaction with multiple Relational Enhancements (termed \\textit{Hire}) for image-text matching, which correlates the intra- and inter-modal semantics between objects and words with implicit and explicit relationship modelling. In particular, the explicit intra-modal spatial-semantic graph-based reasoning network is designed to improve the contextual representation of visual objects with salient spatial and semantic relational connectivities, guided by the explicit relationships of the objects' spatial positions and their scene graph. We use implicit relationship modelling for potential relationship interactions before explicit modelling to improve the fault tolerance of explicit relationship detection. Then the visual and textual semantic representations are refined jointly via inter-modal interactive attention and cross-modal alignment. To correlate the context of objects with the textual context, we further refine the visual semantic representation via cross-level object-sentence and word-image-based interactive attention. Extensive experiments validate that the proposed hybrid-modal interaction with implicit and explicit modelling is more beneficial for image-text matching. And the proposed \\textit{Hire} obtains new state-of-the-art results on MS-COCO and Flickr30K benchmarks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Shedding Light on Large Generative Networks: Estimating Epistemic Uncertainty in Diffusion Models", "authors": "Lucas Berry, Axel Brando, David Meger", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Generative diffusion models, notable for their large parameter count (exceeding 100 million) and operation within high-dimensional image spaces, pose significant challenges for traditional uncertainty estimation methods due to computational demands. In this work, we introduce an innovative framework, Diffusion Ensembles for Capturing Uncertainty (DECU), designed for estimating epistemic uncertainty for diffusion models. The DECU framework introduces a novel method that efficiently trains ensembles of conditional diffusion models by incorporating a static set of pre-trained parameters, drastically reducing the computational burden and the number of parameters that require training. Additionally, DECU employs Pairwise-Distance Estimators (PaiDEs) to accurately measure epistemic uncertainty by evaluating the mutual information between model outputs and weights in high-dimensional spaces. The effectiveness of this framework is demonstrated through experiments on the ImageNet dataset, highlighting its capability to capture epistemic uncertainty, specifically in under-sampled image classes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Dream-in-Style: Text-to-3D Generation using Stylized Score Distillation", "authors": "Hubert Kompanowski, Binh-Son Hua", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)", "abstract": "We present a method to generate 3D objects in styles. Our method takes a text prompt and a style reference image as input and reconstructs a neural radiance field to synthesize a 3D model with the content aligning with the text prompt and the style following the reference image. To simultaneously generate the 3D object and perform style transfer in one go, we propose a stylized score distillation loss to guide a text-to-3D optimization process to output visually plausible geometry and appearance. Our stylized score distillation is based on a combination of an original pretrained text-to-image model and its modified sibling with the key and value features of self-attention layers manipulated to inject styles from the reference image. Comparisons with state-of-the-art methods demonstrated the strong visual performance of our method, further supported by the quantitative results from our user study."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Canonical Consolidation Fields: Reconstructing Dynamic Shapes from Point Clouds", "authors": "Miaowei Wang, Changjian Li, Amir Vaxman", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)", "abstract": "We present Canonical Consolidation Fields (CanFields): a method for reconstructing a time series of independently-sampled point clouds into a single deforming coherent shape. Such input often comes from motion capture. Existing methods either couple the geometry and the deformation, where by doing so they smooth fine details and lose the ability to track moving points, or they track the deformation explicitly, but introduce topological and geometric artifacts. Our novelty lies in the consolidation of the point clouds into a single canonical shape in a way that reduces the effect of noise and outliers, and enables us to overcome missing regions. We simultaneously reconstruct the velocity fields that guide the deformation. This consolidation allows us to retain the high-frequency details of the geometry, while faithfully reproducing the low-frequency deformation. Our architecture comprises simple components, and fits any single input shape without using datasets. We demonstrate the robustness and accuracy of our methods on a diverse benchmark of dynamic point clouds, including missing regions, sparse frames, and noise."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Lumina-Next: Making Lumina-T2X Stronger and Faster with Next-DiT", "authors": "Le Zhuo, Ruoyi Du, Han Xiao, Yangguang Li, Dongyang Liu, Rongjie Huang, Wenze Liu, Lirui Zhao, Fu-Yun Wang, Zhanyu Ma, Xu Luo, Zehan Wang, Kaipeng Zhang, Xiangyang Zhu, Si Liu, Xiangyu Yue, Dingning Liu, Wanli Ouyang, Ziwei Liu, Yu Qiao, Hongsheng Li, Peng Gao", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Lumina-T2X is a nascent family of Flow-based Large Diffusion Transformers that establishes a unified framework for transforming noise into various modalities, such as images and videos, conditioned on text instructions. Despite its promising capabilities, Lumina-T2X still encounters challenges including training instability, slow inference, and extrapolation artifacts. In this paper, we present Lumina-Next, an improved version of Lumina-T2X, showcasing stronger generation performance with increased training and inference efficiency. We begin with a comprehensive analysis of the Flag-DiT architecture and identify several suboptimal components, which we address by introducing the Next-DiT architecture with 3D RoPE and sandwich normalizations. To enable better resolution extrapolation, we thoroughly compare different context extrapolation methods applied to text-to-image generation with 3D RoPE, and propose Frequency- and Time-Aware Scaled RoPE tailored for diffusion transformers. Additionally, we introduced a sigmoid time discretization schedule to reduce sampling steps in solving the Flow ODE and the Context Drop method to merge redundant visual tokens for faster network evaluation, effectively boosting the overall sampling speed. Thanks to these improvements, Lumina-Next not only improves the quality and efficiency of basic text-to-image generation but also demonstrates superior resolution extrapolation capabilities and multilingual generation using decoder-based LLMs as the text encoder, all in a zero-shot manner. To further validate Lumina-Next as a versatile generative framework, we instantiate it on diverse tasks including visual recognition, multi-view, audio, music, and point cloud generation, showcasing strong performance across these domains. By releasing all codes and model weights, we aim to advance the development of next-generation generative AI capable of universal modeling."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Assessment of Sentinel-2 spatial and temporal coverage based on the scene classification layer", "authors": "Cristhian Sanchez, Francisco Mena, Marcela Charfuelan, Marlon Nuske, Andreas Dengel", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Since the launch of the Sentinel-2 (S2) satellites, many ML models have used the data for diverse applications. The scene classification layer (SCL) inside the S2 product provides rich information for training, such as filtering images with high cloud coverage. However, there is more potential in this. We propose a technique to assess the clean optical coverage of a region, expressed by a SITS and calculated with the S2-based SCL data. With a manual threshold and specific labels in the SCL, the proposed technique assigns a percentage of spatial and temporal coverage across the time series and a high/low assessment. By evaluating the AI4EO challenge for Enhanced Agriculture, we show that the assessment is correlated to the predictive results of ML models. The classification results in a region with low spatial and temporal coverage is worse than in a region with high coverage. Finally, we applied the technique across all continents of the global dataset LandCoverNet."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Flexible ViG: Learning the Self-Saliency for Flexible Object Recognition", "authors": "Lin Zuo, Kunshan Yang, Xianlong Tian, Kunbin He, Yongqi Ding, Mengmeng Jing", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Existing computer vision methods mainly focus on the recognition of rigid objects, whereas the recognition of flexible objects remains unexplored. Recognizing flexible objects poses significant challenges due to their inherently diverse shapes and sizes, translucent attributes, ambiguous boundaries, and subtle inter-class differences. In this paper, we claim that these problems primarily arise from the lack of object saliency. To this end, we propose the Flexible Vision Graph Neural Network (FViG) to optimize the self-saliency and thereby improve the discrimination of the representations for flexible objects. Specifically, on one hand, we propose to maximize the channel-aware saliency by extracting the weight of neighboring nodes, which adapts to the shape and size variations in flexible objects. On the other hand, we maximize the spatial-aware saliency based on clustering to aggregate neighborhood information for the centroid nodes, which introduces local context information for the representation learning. To verify the performance of flexible objects recognition thoroughly, for the first time we propose the Flexible Dataset (FDA), which consists of various images of flexible objects collected from real-world scenarios or online. Extensive experiments evaluated on our Flexible Dataset demonstrate the effectiveness of our method on enhancing the discrimination of flexible objects."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cut-and-Paste with Precision: a Content and Perspective-aware Data Augmentation for Road Damage Detection", "authors": "Punnawat Siripathitti, Florent Forest, Olga Fink", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)", "abstract": "Damage to road pavement can develop into cracks, potholes, spallings, and other issues posing significant challenges to the integrity, safety, and durability of the road structure. Detecting and monitoring the evolution of these damages is crucial for maintaining the condition and structural health of road infrastructure. In recent years, researchers have explored various data-driven methods for image-based damage detection in road monitoring applications. The field gained attention with the introduction of the Road Damage Detection Challenge (RDDC2018), encouraging competition in developing object detectors on street-view images from various countries. Leading teams have demonstrated the effectiveness of ensemble models, mostly based on the YOLO and Faster R-CNN series. Data augmentations have also shown benefits in object detection within the computer vision field, including transformations such as random flipping, cropping, cutting out patches, as well as cut-and-pasting object instances. Applying cut-and-paste augmentation to road damages appears to be a promising approach to increase data diversity. However, the standard cut-and-paste technique, which involves sampling an object instance from a random image and pasting it at a random location onto the target image, has demonstrated limited effectiveness for road damage detection. This method overlooks the location of the road and disregards the difference in perspective between the sampled damage and the target image, resulting in unrealistic augmented images. In this work, we propose an improved Cut-and-Paste augmentation technique that is both content-aware (i.e. considers the true location of the road in the image) and perspective-aware (i.e. takes into account the difference in perspective between the injected damage and the target image)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Nomic Embed Vision: Expanding the Latent Space", "authors": "Zach Nussbaum, Brandon Duderstadt, Andriy Mulyar", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "This technical report describes the training of nomic-embed-vision, a highly performant, open-code, open-weights image embedding model that shares the same latent space as nomic-embed-text. Together, nomic-embed-vision and nomic-embed-text form the first unified latent space to achieve high performance across vision, language, and multimodal tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Varying Manifolds in Diffusion: From Time-varying Geometries to Visual Saliency", "authors": "Junhao Chen, Manyi Li, Zherong Pan, Xifeng Gao, Changhe Tu", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Deep generative models learn the data distribution, which is concentrated on a low-dimensional manifold. The geometric analysis of distribution transformation provides a better understanding of data structure and enables a variety of applications. In this paper, we study the geometric properties of the diffusion model, whose forward diffusion process and reverse generation process construct a series of distributions on manifolds which vary over time. Our key contribution is the introduction of generation rate, which corresponds to the local deformation of manifold over time around an image component. We show that the generation rate is highly correlated with intuitive visual properties, such as visual saliency, of the image component. Further, we propose an efficient and differentiable scheme to estimate the generation rate for a given image component over time, giving rise to a generation curve. The differentiable nature of our scheme allows us to control the shape of the generation curve via optimization. Using different loss functions, our generation curve matching algorithm provides a unified framework for a range of image manipulation tasks, including semantic transfer, object removal, saliency manipulation, image blending, etc. We conduct comprehensive analytical evaluations to support our findings and evaluate our framework on various manipulation tasks. The results show that our method consistently leads to better manipulation results, compared to recent baselines."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Text-Guided Alternative Image Clustering", "authors": "Andreas Stephan, Lukas Miklautz, Collin Leiber, Pedro Henrique Luz de Araujo, Dominik R\u00e9p\u00e1s, Claudia Plant, Benjamin Roth", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Traditional image clustering techniques only find a single grouping within visual data. In particular, they do not provide a possibility to explicitly define multiple types of clustering. This work explores the potential of large vision-language models to facilitate alternative image clustering. We propose Text-Guided Alternative Image Consensus Clustering (TGAICC), a novel approach that leverages user-specified interests via prompts to guide the discovery of diverse clusterings. To achieve this, it generates a clustering for each prompt, groups them using hierarchical clustering, and then aggregates them using consensus clustering. TGAICC outperforms image- and text-based baselines on four alternative image clustering benchmark datasets. Furthermore, using count-based word statistics, we are able to obtain text-based explanations of the alternative clusterings. In conclusion, our research illustrates how contemporary large vision-language models can transform explanatory data analysis, enabling the generation of insightful, customizable, and diverse image clusterings."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Composition Vision-Language Understanding via Segment and Depth Anything Model", "authors": "Mingxiao Huo, Pengliang Ji, Haotian Lin, Junchen Liu, Yixiao Wang, Yijun Chen", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "We introduce a pioneering unified library that leverages depth anything, segment anything models to augment neural comprehension in language-vision model zero-shot understanding. This library synergizes the capabilities of the Depth Anything Model (DAM), Segment Anything Model (SAM), and GPT-4V, enhancing multimodal tasks such as vision-question-answering (VQA) and composition reasoning. Through the fusion of segmentation and depth analysis at the symbolic instance level, our library provides nuanced inputs for language models, significantly advancing image interpretation. Validated across a spectrum of in-the-wild real-world images, our findings showcase progress in vision-language models through neural-symbolic integration. This novel approach melds visual and language analysis in an unprecedented manner. Overall, our library opens new directions for future research aimed at decoding the complexities of the real world through advanced multimodal technologies and our code is available at \\url{this https URL}."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Neural Appearance Modeling From Single Images", "authors": "Jay Idema, Pieter Peers", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)", "abstract": "We propose a material appearance modeling neural network for visualizing plausible, spatially-varying materials under diverse view and lighting conditions, utilizing only a single photograph of a material under co-located light and view as input for appearance estimation. Our neural architecture is composed of two network stages: a network that infers learned per-pixel neural parameters of a material from a single input photograph, and a network that renders the material utilizing these neural parameters, similar to a BRDF. We train our model on a set of 312,165 synthetic spatially-varying exemplars. Since our method infers learned neural parameters rather than analytical BRDF parameters, our method is capable of encoding anisotropic and global illumination (inter-pixel interaction) information into individual pixel parameters. We demonstrate our model's performance compared to prior work and demonstrate the feasibility of the render network as a BRDF by implementing it into the Mitsuba3 rendering engine. Finally, we briefly discuss the capability of neural parameters to encode global illumination information."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Realtime Dynamic Gaze Target Tracking and Depth-Level Estimation", "authors": "Esmaeil Seraj, Harsh Bhate, Walter Talamonti", "subjects": "Subjects:\nHuman-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "The integration of Transparent Displays (TD) in various applications, such as Heads-Up Displays (HUDs) in vehicles, is a burgeoning field, poised to revolutionize user experiences. However, this innovation brings forth significant challenges in realtime human-device interaction, particularly in accurately identifying and tracking a user's gaze on dynamically changing TDs. In this paper, we present a two-fold robust and efficient systematic solution for realtime gaze monitoring, comprised of: (1) a tree-based algorithm for identifying and dynamically tracking gaze targets (i.e., moving, size-changing, and overlapping 2D content) projected on a transparent display, in realtime; (2) a multi-stream self-attention architecture to estimate the depth-level of human gaze from eye tracking data, to account for the display's transparency and preventing undesired interactions with the TD. We collected a real-world eye-tracking dataset to train and test our gaze monitoring system. We present extensive results and ablation studies, including inference experiments on System on Chip (SoC) evaluation boards, demonstrating our model's scalability, precision, and realtime feasibility in both static and dynamic contexts. Our solution marks a significant stride in enhancing next-generation user-device interaction and experience, setting a new benchmark for algorithmic gaze monitoring technology in dynamic transparent displays."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Vox-UDA: Voxel-wise Unsupervised Domain Adaptation for Cryo-Electron Subtomogram Segmentation with Denoised Pseudo Labeling", "authors": "Haoran Li, Xingjian Li, Jiahua Shi, Huaming Chen, Bo Du, Daisuke Kihara, Johan Barthelemy, Jun Shen, Min Xu", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Cryo-Electron Tomography (cryo-ET) is a 3D imaging technology facilitating the study of macromolecular structures at near-atomic resolution. Recent volumetric segmentation approaches on cryo-ET images have drawn widespread interest in biological sector. However, existing methods heavily rely on manually labeled data, which requires highly professional skills, thereby hindering the adoption of fully-supervised approaches for cryo-ET images. Some unsupervised domain adaptation (UDA) approaches have been designed to enhance the segmentation network performance using unlabeled data. However, applying these methods directly to cryo-ET images segmentation tasks remains challenging due to two main issues: 1) the source data, usually obtained through simulation, contain a certain level of noise, while the target data, directly collected from raw-data from real-world scenario, have unpredictable noise levels. 2) the source data used for training typically consists of known macromoleculars, while the target domain data are often unknown, causing the model's segmenter to be biased towards these known macromolecules, leading to a domain shift problem. To address these challenges, in this work, we introduce the first voxel-wise unsupervised domain adaptation approach, termed Vox-UDA, specifically for cryo-ET subtomogram segmentation. Vox-UDA incorporates a noise generation module to simulate target-like noises in the source dataset for cross-noise level adaptation. Additionally, we propose a denoised pseudo-labeling strategy based on improved Bilateral Filter to alleviate the domain shift problem. Experimental results on both simulated and real cryo-ET subtomogram datasets demonstrate the superiority of our proposed approach compared to state-of-the-art UDA methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Translation of Nagumo's Foundational Work on Barrier Functions: On the Location of Integral Curves of Ordinary Differential Equations", "authors": "Marcel Menner, Eugene Lavretsky", "subjects": "Subjects:\nSystems and Control (eess.SY)", "abstract": "In 1942, Prof. Mitio Nagumo published his seminal paper on the location of integral curves of ordinary differential equations. Nagumo's paper provides the foundation of the set invariance of ordinary differential equations and barrier functions, which have recently gained popularity for the control design of safety critical dynamical systems. This translation shall serve the community with an easily accessible version of the original 1942 paper in English. A copy of Nagumo's paper in German is also attached as a reference. That copy was created by the Boeing Company, Germany, in an attempt to improve pdf format readability of the original paper."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Improving Execution Concurrency in Partial-Order Plans via Block-Substitution", "authors": "Sabah Binte Noor, Fazlul Hasan Siddiqui", "subjects": "Subjects:\nArtificial Intelligence (cs.AI)", "abstract": "Partial-order plans in AI planning facilitate execution flexibility and several other tasks, such as plan reuse, modification, and decomposition, due to their less constrained nature. A Partial-Order Plan (POP) allows two actions with no ordering between them, thus providing the flexibility of executing actions in different sequences. This flexibility can be further extended by enabling parallel execution of actions in a POP to reduce its overall execution time. While extensive studies exist on improving the flexibility of a POP by optimizing its action orderings through plan deordering and reordering, there has been limited focus on the flexibility of executing actions concurrently in a plan. Execution concurrency in a POP can be achieved by incorporating action non-concurrency constraints, specifying which actions can not be executed in parallel. This work formalizes the conditions for non-concurrency constraints to transform a POP into a parallel plan. We also introduce an algorithm to enhance the plan's concurrency by optimizing resource utilization through substitutions of its subplans with respect to the corresponding planning task. Our algorithm employs block deordering that eliminates orderings in a POP by encapsulating coherent actions in blocks, and then exploits blocks as candidate subplans for substitutions. Experiments over the benchmark problems from International Planning Competitions (IPC) exhibit significant improvement in plan concurrency, specifically, with improvement in 25% of the plans, and an overall increase of 2.1% in concurrency."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Large Language Model Aided Program Refinement", "authors": "Yufan Cai, Zhe Hou, Xiaokun Luan, David Miguel Sanan Baena, Yun Lin, Jun Sun, Jin Song Dong", "subjects": "Subjects:\nSoftware Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Program refinement involves correctness-preserving transformations from formal high-level specification statements into executable programs. Traditional verification tool support for program refinement is highly interactive and lacks automation. On the other hand, the emergence of large language models (LLMs) enables automatic code generations from informal natural language specifications. However, code generated by LLMs is often unreliable. Moreover, the opaque procedure from specification to code provided by LLM is an uncontrolled black box. We propose LLM4PR, a tool that combines formal program refinement techniques with informal LLM-based methods to (1) transform the specification to preconditions and postconditions, (2) automatically build prompts based on refinement calculus, (3) interact with LLM to generate code, and finally, (4) verify that the generated code satisfies the conditions of refinement calculus, thus guaranteeing the correctness of the code. We have implemented our tool using GPT4, Coq, and Coqhammer, and evaluated it on the HumanEval and EvalPlus datasets."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Documentation Practices of Artificial Intelligence", "authors": "Stefan Arnold, Dilara Yesilbas, Rene Gr\u00f6bner, Dominik Riedelbauch, Maik Horn, Sven Weinzierl", "subjects": "Subjects:\nDigital Libraries (cs.DL); Artificial Intelligence (cs.AI)", "abstract": "Artificial Intelligence (AI) faces persistent challenges in terms of transparency and accountability, which requires rigorous documentation. Through a literature review on documentation practices, we provide an overview of prevailing trends, persistent issues, and the multifaceted interplay of factors influencing the documentation. Our examination of key characteristics such as scope, target audiences, support for multimodality, and level of automation, highlights a dynamic evolution in documentation practices, underscored by a shift towards a more holistic, engaging, and automated documentation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Deep Active Learning in Avian Bioacoustics", "authors": "Lukas Rauch, Denis Huseljic, Moritz Wirth, Jens Decke, Bernhard Sick, Christoph Scholz", "subjects": "Subjects:\nSound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)", "abstract": "Passive acoustic monitoring (PAM) in avian bioacoustics enables cost-effective and extensive data collection with minimal disruption to natural habitats. Despite advancements in computational avian bioacoustics, deep learning models continue to encounter challenges in adapting to diverse environments in practical PAM scenarios. This is primarily due to the scarcity of annotations, which requires labor-intensive efforts from human experts. Active learning (AL) reduces annotation cost and speed ups adaption to diverse scenarios by querying the most informative instances for labeling. This paper outlines a deep AL approach, introduces key challenges, and conducts a small-scale pilot study."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Automatic Prediction of Amyotrophic Lateral Sclerosis Progression using Longitudinal Speech Transformer", "authors": "Liming Wang, Yuan Gong, Nauman Dawalatabad, Marco Vilela, Katerina Placek, Brian Tracey, Yishu Gong, Alan Premasiri, Fernando Vieira, James Glass", "subjects": "Subjects:\nSound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)", "abstract": "Automatic prediction of amyotrophic lateral sclerosis (ALS) disease progression provides a more efficient and objective alternative than manual approaches. We propose ALS longitudinal speech transformer (ALST), a neural network-based automatic predictor of ALS disease progression from longitudinal speech recordings of ALS patients. By taking advantage of high-quality pretrained speech features and longitudinal information in the recordings, our best model achieves 91.0\\% AUC, improving upon the previous best model by 5.6\\% relative on the ALS TDI dataset. Careful analysis reveals that ALST is capable of fine-grained and interpretable predictions of ALS progression, especially for distinguishing between rarer and more severe cases. Code is publicly available."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AssertionBench: A Benchmark to Evaluate Large-Language Models for Assertion Generation", "authors": "Vaishnavi Pulavarthi, Deeksha Nandal, Soham Dan, Debjit Pal", "subjects": "Subjects:\nSoftware Engineering (cs.SE); Machine Learning (cs.LG)", "abstract": "Assertions have been the de facto collateral for simulation-based and formal verification of hardware designs for over a decade. The quality of hardware verification, \\ie, detection and diagnosis of corner-case design bugs, is critically dependent on the quality of the assertions. There has been a considerable amount of research leveraging a blend of data-driven statistical analysis and static analysis to generate high-quality assertions from hardware design source code and design execution trace data. Despite such concerted effort, all prior research struggles to scale to industrial-scale large designs, generates too many low-quality assertions, often fails to capture subtle and non-trivial design functionality, and does not produce any easy-to-comprehend explanations of the generated assertions to understand assertions' suitability to different downstream validation tasks. Recently, with the advent of Large-Language Models (LLMs), there has been a widespread effort to leverage prompt engineering to generate assertions. However, there is little effort to quantitatively establish the effectiveness and suitability of various LLMs for assertion generation. In this paper, we present AssertionBench, a novel benchmark to evaluate LLMs' effectiveness for assertion generation quantitatively. AssertioBench contains 100 curated Verilog hardware designs from OpenCores and formally verified assertions for each design generated from GoldMine and HARM. We use AssertionBench to compare state-of-the-art LLMs to assess their effectiveness in inferring functionally correct assertions for hardware designs. Our experiments demonstrate how LLMs perform relative to each other, the benefits of using more in-context exemplars in generating a higher fraction of functionally correct assertions, and the significant room for improvement for LLM-based assertion generators."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          IDA-UIE: An Iterative Framework for Deep Network-based Degradation Aware Underwater Image Enhancement", "authors": "Pranjali Singh, Prithwijit Guha", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)", "abstract": "Underwater image quality is affected by fluorescence, low illumination, absorption, and scattering. Recent works in underwater image enhancement have proposed different deep network architectures to handle these problems. Most of these works have proposed a single network to handle all the challenges. We believe that deep networks trained for specific conditions deliver better performance than a single network learned from all degradation cases. Accordingly, the first contribution of this work lies in the proposal of an iterative framework where a single dominant degradation condition is identified and resolved. This proposal considers the following eight degradation conditions -- low illumination, low contrast, haziness, blurred image, presence of noise and color imbalance in three different channels. A deep network is designed to identify the dominant degradation condition. Accordingly, an appropriate deep network is selected for degradation condition-specific enhancement. The second contribution of this work is the construction of degradation condition specific datasets from good quality images of two standard datasets (UIEB and EUVP). This dataset is used to learn the condition specific enhancement networks. The proposed approach is found to outperform nine baseline methods on UIEB and EUVP datasets."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of LLMs", "authors": "Xin Lai, Zhuotao Tian, Yukang Chen, Senqiao Yang, Xiangru Peng, Jiaya Jia", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Mathematical reasoning presents a significant challenge for Large Language Models (LLMs) due to the extensive and precise chain of reasoning required for accuracy. Ensuring the correctness of each reasoning step is critical. To address this, we aim to enhance the robustness and factuality of LLMs by learning from human feedback. However, Direct Preference Optimization (DPO) has shown limited benefits for long-chain mathematical reasoning, as models employing DPO struggle to identify detailed errors in incorrect answers. This limitation stems from a lack of fine-grained process supervision. We propose a simple, effective, and data-efficient method called Step-DPO, which treats individual reasoning steps as units for preference optimization rather than evaluating answers holistically. Additionally, we have developed a data construction pipeline for Step-DPO, enabling the creation of a high-quality dataset containing 10K step-wise preference pairs. We also observe that in DPO, self-generated data is more effective than data generated by humans or GPT-4, due to the latter's out-of-distribution nature. Our findings demonstrate that as few as 10K preference data pairs and fewer than 500 Step-DPO training steps can yield a nearly 3% gain in accuracy on MATH for models with over 70B parameters. Notably, Step-DPO, when applied to Qwen2-72B-Instruct, achieves scores of 70.8% and 94.0% on the test sets of MATH and GSM8K, respectively, surpassing a series of closed-source models, including GPT-4-1106, Claude-3-Opus, and Gemini-1.5-Pro. Our code, data, and models are available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Improving Hyperparameter Optimization with Checkpointed Model Weights", "authors": "Nikhil Mehta, Jonathan Lorraine, Steve Masson, Ramanathan Arunachalam, Zaid Pervaiz Bhat, James Lucas, Arun George Zachariah", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "abstract": "When training deep learning models, the performance depends largely on the selected hyperparameters. However, hyperparameter optimization (HPO) is often one of the most expensive parts of model design. Classical HPO methods treat this as a black-box optimization problem. However, gray-box HPO methods, which incorporate more information about the setup, have emerged as a promising direction for more efficient optimization. For example, using intermediate loss evaluations to terminate bad selections. In this work, we propose an HPO method for neural networks using logged checkpoints of the trained weights to guide future hyperparameter selections. Our method, Forecasting Model Search (FMS), embeds weights into a Gaussian process deep kernel surrogate model, using a permutation-invariant graph metanetwork to be data-efficient with the logged network weights. To facilitate reproducibility and further research, we open-source our code at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Evaluating Copyright Takedown Methods for Language Models", "authors": "Boyi Wei, Weijia Shi, Yangsibo Huang, Noah A. Smith, Chiyuan Zhang, Luke Zettlemoyer, Kai Li, Peter Henderson", "subjects": "Subjects:\nComputation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Language models (LMs) derive their capabilities from extensive training on diverse data, including potentially copyrighted material. These models can memorize and generate content similar to their training data, posing potential concerns. Therefore, model creators are motivated to develop mitigation methods that prevent generating protected content. We term this procedure as copyright takedowns for LMs, noting the conceptual similarity to (but legal distinction from) the DMCA takedown This paper introduces the first evaluation of the feasibility and side effects of copyright takedowns for LMs. We propose CoTaEval, an evaluation framework to assess the effectiveness of copyright takedown methods, the impact on the model's ability to retain uncopyrightable factual knowledge from the training data whose recitation is embargoed, and how well the model maintains its general utility and efficiency. We examine several strategies, including adding system prompts, decoding-time filtering interventions, and unlearning approaches. Our findings indicate that no tested method excels across all metrics, showing significant room for research in this unique problem setting and indicating potential unresolved challenges for live policy proposals."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RouteLLM: Learning to Route LLMs with Preference Data", "authors": "Isaac Ong, Amjad Almahairi, Vincent Wu, Wei-Lin Chiang, Tianhao Wu, Joseph E. Gonzalez, M Waleed Kadous, Ion Stoica", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Large language models (LLMs) exhibit impressive capabilities across a wide range of tasks, yet the choice of which model to use often involves a trade-off between performance and cost. More powerful models, though effective, come with higher expenses, while less capable models are more cost-effective. To address this dilemma, we propose several efficient router models that dynamically select between a stronger and a weaker LLM during inference, aiming to optimize the balance between cost and response quality. We develop a training framework for these routers leveraging human preference data and data augmentation techniques to enhance performance. Our evaluation on widely-recognized benchmarks shows that our approach significantly reduces costs-by over 2 times in certain cases-without compromising the quality of responses. Interestingly, our router models also demonstrate significant transfer learning capabilities, maintaining their performance even when the strong and weak models are changed at test time. This highlights the potential of these routers to provide a cost-effective yet high-performance solution for deploying LLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Generalized Cuts and Grothendieck Covers: a Primal-Dual Approximation Framework Extending the Goemans--Williamson Algorithm", "authors": "Nathan Benedetto Proen\u00e7a, Marcel K. de Carli Silva, Cristiane M. Sato, Levent Tun\u00e7el", "subjects": "Subjects:\nData Structures and Algorithms (cs.DS); Discrete Mathematics (cs.DM); Optimization and Control (math.OC)", "abstract": "We provide a primal-dual framework for randomized approximation algorithms utilizing semidefinite programming (SDP) relaxations. Our framework pairs a continuum of APX-complete problems including MaxCut, Max2Sat, MaxDicut, and more generally, Max-Boolean Constraint Satisfaction and MaxQ (maximization of a positive semidefinite quadratic form over the hypercube) with new APX-complete problems which are stated as convex optimization problems with exponentially many variables. These new dual counterparts, based on what we call Grothendieck covers, range from fractional cut covering problems (for MaxCut) to tensor sign covering problems (for MaxQ). For each of these problem pairs, our framework transforms the randomized approximation algorithms with the best known approximation factors for the primal problems to randomized approximation algorithms for their dual counterparts with reciprocal approximation factors which are tight with respect to the Unique Games Conjecture. For each APX-complete pair, our algorithms solve a single SDP relaxation and generate feasible solutions for both problems which also provide approximate optimality certificates for each other. Our work utilizes techniques from areas of randomized approximation algorithms, convex optimization, spectral sparsification, as well as Chernoff-type concentration results for random matrices."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Zero Auxiliary Knowledge Membership Inference Attack on Aggregate Location Data", "authors": "Vincent Guan, Florent Gu\u00e9pin, Ana-Maria Cretu, Yves-Alexandre de Montjoye", "subjects": "Subjects:\nCryptography and Security (cs.CR); Machine Learning (cs.LG)", "abstract": "Location data is frequently collected from populations and shared in aggregate form to guide policy and decision making. However, the prevalence of aggregated data also raises the privacy concern of membership inference attacks (MIAs). MIAs infer whether an individual's data contributed to the aggregate release. Although effective MIAs have been developed for aggregate location data, these require access to an extensive auxiliary dataset of individual traces over the same locations, which are collected from a similar population. This assumption is often impractical given common privacy practices surrounding location data. To measure the risk of an MIA performed by a realistic adversary, we develop the first Zero Auxiliary Knowledge (ZK) MIA on aggregate location data, which eliminates the need for an auxiliary dataset of real individual traces. Instead, we develop a novel synthetic approach, such that suitable synthetic traces are generated from the released aggregate. We also develop methods to correct for bias and noise, to show that our synthetic-based attack is still applicable when privacy mechanisms are applied prior to release. Using two large-scale location datasets, we demonstrate that our ZK MIA matches the state-of-the-art Knock-Knock (KK) MIA across a wide range of settings, including popular implementations of differential privacy (DP) and suppression of small counts. Furthermore, we show that ZK MIA remains highly effective even when the adversary only knows a small fraction (10%) of their target's location history. This demonstrates that effective MIAs can be performed by realistic adversaries, highlighting the need for strong DP protection."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Human-AI Collaborative Taxonomy Construction: A Case Study in Profession-Specific Writing Assistants", "authors": "Minhwa Lee, Zae Myung Kim, Vivek A. Khetan, Dongyeop Kang", "subjects": "Subjects:\nHuman-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Large Language Models (LLMs) have assisted humans in several writing tasks, including text revision and story generation. However, their effectiveness in supporting domain-specific writing, particularly in business contexts, is relatively less explored. Our formative study with industry professionals revealed the limitations in current LLMs' understanding of the nuances in such domain-specific writing. To address this gap, we propose an approach of human-AI collaborative taxonomy development to perform as a guideline for domain-specific writing assistants. This method integrates iterative feedback from domain experts and multiple interactions between these experts and LLMs to refine the taxonomy. Through larger-scale experiments, we aim to validate this methodology and thus improve LLM-powered writing assistance, tailoring it to meet the unique requirements of different stakeholder needs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Understand What LLM Needs: Dual Preference Alignment for Retrieval-Augmented Generation", "authors": "Guanting Dong, Yutao Zhu, Chenghao Zhang, Zechen Wang, Zhicheng Dou, Ji-Rong Wen", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Retrieval-augmented generation (RAG) has demonstrated effectiveness in mitigating the hallucination problem of large language models (LLMs). However, the difficulty of aligning the retriever with the diverse LLMs' knowledge preferences inevitably poses an inevitable challenge in developing a reliable RAG system. To address this issue, we propose DPA-RAG, a universal framework designed to align diverse knowledge preferences within RAG systems. Specifically, we initially introduce a preference knowledge construction pipline and incorporate five novel query augmentation strategies to alleviate preference data scarcity. Based on preference data, DPA-RAG accomplishes both external and internal preference alignment: 1) It jointly integrate pair-wise, point-wise, and contrastive preference alignment abilities into the reranker, achieving external preference alignment among RAG components. 2) It further introduces a pre-aligned stage before vanilla Supervised Fine-tuning (SFT), enabling LLMs to implicitly capture knowledge aligned with their reasoning preferences, achieving LLMs' internal alignment. Experimental results across four knowledge-intensive QA datasets demonstrate that DPA-RAG outperforms all baselines and seamlessly integrates both black-box and open-sourced LLM readers. Further qualitative analysis and discussions also provide empirical guidance for achieving reliable RAG systems. Our code is publicly available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Few-shot Personalization of LLMs with Mis-aligned Responses", "authors": "Jaehyung Kim, Yiming Yang", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "As the diversity of users increases, the capability of providing personalized responses by large language models (LLMs) has become increasingly important. Existing approaches have only limited successes in LLM personalization, due to the absence of personalized learning or the reliance on shared personal data. This paper proposes a new approach for a few-shot personalization of LLMs with their mis-aligned responses (Fermi). Our key idea is to learn a set of personalized prompts for each user by progressively improving the prompts using LLMs, based on user profile (e.g., demographic information) and a few examples of previous opinions. During an iterative process of prompt improvement, we incorporate the contexts of mis-aligned responses by LLMs, which are especially crucial for the effective personalization of LLMs. In addition, we develop an effective inference method to further leverage the context of the test query and the personalized prompts. Our experimental results demonstrate that Fermi significantly improves performance across various benchmarks, compared to the best-performing baselines."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Multilingual Alignment Prism: Aligning Global and Local Preferences to Reduce Harm", "authors": "Aakanksha, Arash Ahmadian, Beyza Ermis, Seraphina Goldfarb-Tarrant, Julia Kreutzer, Marzieh Fadaee, Sara Hooker", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "A key concern with the concept of \"alignment\" is the implicit question of \"alignment to what?\". AI systems are increasingly used across the world, yet safety alignment is often focused on homogeneous monolingual settings. Additionally, preference training and safety measures often overfit to harms common in Western-centric datasets. Here, we explore the viability of different alignment approaches when balancing dual objectives: addressing and optimizing for a non-homogeneous set of languages and cultural preferences while minimizing both global and local harms. We collect the first set of human annotated red-teaming prompts in different languages distinguishing between global and local harm, which serve as a laboratory for understanding the reliability of alignment techniques when faced with preference distributions that are non-stationary across geographies and languages. While this setting is seldom covered by the literature to date, which primarily centers on English harm mitigation, it captures real-world interactions with AI systems around the world. We establish a new precedent for state-of-the-art alignment techniques across 6 languages with minimal degradation in general performance. Our work provides important insights into cross-lingual transfer and novel optimization approaches to safeguard AI systems designed to serve global populations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CSI4Free: GAN-Augmented mmWave CSI for Improved Pose Classification", "authors": "Nabeel Nisar Bhat, Rafael Berkvens Jeroen Famaey", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "In recent years, Joint Communication and Sensing (JC&S), has demonstrated significant success, particularly in utilizing sub-6 GHz frequencies with commercial-off-the-shelf (COTS) Wi-Fi devices for applications such as localization, gesture recognition, and pose classification. Deep learning and the existence of large public datasets has been pivotal in achieving such results. However, at mmWave frequencies (30-300 GHz), which has shown potential for more accurate sensing performance, there is a noticeable lack of research in the domain of COTS Wi-Fi sensing. Challenges such as limited research hardware, the absence of large datasets, limited functionality in COTS hardware, and the complexities of data collection present obstacles to a comprehensive exploration of this field. In this work, we aim to address these challenges by developing a method that can generate synthetic mmWave channel state information (CSI) samples. In particular, we use a generative adversarial network (GAN) on an existing dataset, to generate 30,000 additional CSI samples. The augmented samples exhibit a remarkable degree of consistency with the original data, as indicated by the notably high GAN-train and GAN-test scores. Furthermore, we integrate the augmented samples in training a pose classification model. We observe that the augmented samples complement the real data and improve the generalization of the classification model."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Petal-X: Human-Centered Visual Explanations to Improve Cardiovascular Risk Communication", "authors": "Diego Rojo, Houda Lamqaddam, Lucija Gosak, Katrien Verbert", "subjects": "Subjects:\nHuman-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Cardiovascular diseases (CVDs), the leading cause of death worldwide, can be prevented in most cases through behavioral interventions. Therefore, effective communication of CVD risk and projected risk reduction by risk factor modification plays a crucial role in reducing CVD risk at the individual level. However, despite interest in refining risk estimation with improved prediction models such as SCORE2, the guidelines for presenting these risk estimations in clinical practice remained essentially unchanged in the last few years, with graphical score charts (GSCs) continuing to be one of the prevalent systems. This work describes the design and implementation of Petal-X, a novel tool to support clinician-patient shared decision-making by explaining the CVD risk contributions of different factors and facilitating what-if analysis. Petal-X relies on a novel visualization, Petal Product Plots, and a tailor-made global surrogate model of SCORE2, whose fidelity is comparable to that of the GSCs used in clinical practice. We evaluated Petal-X compared to GSCs in a controlled experiment with 88 healthcare students, all but one with experience with chronic patients. The results show that Petal-X outperforms GSC in critical tasks, such as comparing the contribution to the patient's 10-year CVD risk of each modifiable risk factor, without a significant loss of perceived transparency, trust, or intent to use. Our study provides an innovative approach to the visualization and explanation of risk in clinical practice that, due to its model-agnostic nature, could continue to support next-generation artificial intelligence risk assessment models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Geometric Features Enhanced Human-Object Interaction Detection", "authors": "Manli Zhu, Edmond S. L. Ho, Shuang Chen, Longzhi Yang, Hubert P. H. Shum", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Cameras are essential vision instruments to capture images for pattern detection and measurement. Human-object interaction (HOI) detection is one of the most popular pattern detection approaches for captured human-centric visual scenes. Recently, Transformer-based models have become the dominant approach for HOI detection due to their advanced network architectures and thus promising results. However, most of them follow the one-stage design of vanilla Transformer, leaving rich geometric priors under-exploited and leading to compromised performance especially when occlusion occurs. Given that geometric features tend to outperform visual ones in occluded scenarios and offer information that complements visual cues, we propose a novel end-to-end Transformer-style HOI detection model, i.e., geometric features enhanced HOI detector (GeoHOI). One key part of the model is a new unified self-supervised keypoint learning method named UniPointNet that bridges the gap of consistent keypoint representation across diverse object categories, including humans. GeoHOI effectively upgrades a Transformer-based HOI detector benefiting from the keypoints similarities measuring the likelihood of human-object interactions as well as local keypoint patches to enhance interaction query representation, so as to boost HOI predictions. Extensive experiments show that the proposed method outperforms the state-of-the-art models on V-COCO and achieves competitive performance on HICO-DET. Case study results on the post-disaster rescue with vision-based instruments showcase the applicability of the proposed GeoHOI in real-world applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Learning to Correct for QA Reasoning with Black-box LLMs", "authors": "Jaehyung Kim, Dongyoung Kim, Yiming Yang", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "An open challenge in recent machine learning is about how to improve the reasoning capability of large language models (LLMs) in a black-box setting, i.e., without access to detailed information such as output token probabilities. Existing approaches either rely on accessibility (which is often unrealistic) or involve significantly increased train- and inference-time costs. This paper addresses those limitations or shortcomings by proposing a novel approach, namely CoBB (Correct for improving QA reasoning of Black-Box LLMs). It uses a trained adaptation model to perform a seq2seq mapping from the often-imperfect reasonings of the original black-box LLM to the correct or improved reasonings. Specifically, the adaptation model is initialized with a relatively small open-source LLM and adapted over a collection of sub-sampled training pairs. To select the representative pairs of correct and incorrect reasonings, we formulated the dataset construction as an optimization problem that minimizes the statistical divergence between the sampled subset and the entire collection, and solved it via a genetic algorithm. We then train the adaptation model over the sampled pairs by contrasting the likelihoods of correct and incorrect reasonings. Our experimental results demonstrate that CoBB significantly improves reasoning accuracy across various QA benchmarks, compared to the best-performing adaptation baselines."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Sequence Graph Network for Online Debate Analysis", "authors": "Quan Mai, Susan Gauch, Douglas Adams, Miaoqing Huang", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Online debates involve a dynamic exchange of ideas over time, where participants need to actively consider their opponents' arguments, respond with counterarguments, reinforce their own points, and introduce more compelling arguments as the discussion unfolds. Modeling such a complex process is not a simple task, as it necessitates the incorporation of both sequential characteristics and the capability to capture interactions effectively. To address this challenge, we employ a sequence-graph approach. Building the conversation as a graph allows us to effectively model interactions between participants through directed edges. Simultaneously, the propagation of information along these edges in a sequential manner enables us to capture a more comprehensive representation of context. We also introduce a Sequence Graph Attention layer to illustrate the proposed information update scheme. The experimental results show that sequence graph networks achieve superior results to existing methods in online debates."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          From Pixels to Torques with Linear Feedback", "authors": "Jeong Hun Lee, Sam Schoedel, Aditya Bhardwaj, Zachary Manchester", "subjects": "Subjects:\nRobotics (cs.RO)", "abstract": "We demonstrate the effectiveness of simple observer-based linear feedback policies for \"pixels-to-torques\" control of robotic systems using only a robot-facing camera. Specifically, we show that the matrices of an image-based Luenberger observer (linear state estimator) for a \"student\" output-feedback policy can be learned from demonstration data provided by a \"teacher\" state-feedback policy via simple linear-least-squares regression. The resulting linear output-feedback controller maps directly from high-dimensional raw images to torques while being amenable to the rich set of analytical tools from linear systems theory, alowing us to enforce closed-loop stability constraints in the learning problem. We also investigate a nonlinear extension of the method via the Koopman embedding. Finally, we demonstrate the surprising effectiveness of linear pixels-to-torques policies on a cartpole system, both in simulation and on real-world hardware. The policy successfully executes both stabilizing and swing-up trajectory tracking tasks using only camera feedback while subject to model mismatch, process and sensor noise, perturbations, and occlusions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On Fourier analysis of sparse Boolean functions over certain Abelian groups", "authors": "Sourav Chakraborty, Swarnalipa Datta, Pranjal Dutta, Arijit Ghosh, Swagato Sanyal", "subjects": "Subjects:\nComputational Complexity (cs.CC)", "abstract": "Given an Abelian group G, a Boolean-valued function f: G -> {-1,+1}, is said to be s-sparse, if it has at most s-many non-zero Fourier coefficients over the domain G. In a seminal paper, Gopalan et al. proved \"Granularity\" for Fourier coefficients of Boolean valued functions over Z_2^n, that have found many diverse applications in theoretical computer science and combinatorics. They also studied structural results for Boolean functions over Z_2^n which are approximately Fourier-sparse. In this work, we obtain structural results for approximately Fourier-sparse Boolean valued functions over Abelian groups G of the form,G:= Z_{p_1}^{n_1} \\times ... \\times Z_{p_t}^{n_t}, for distinct primes p_i. We also obtain a lower bound of the form 1/(m^{2}s)^ceiling(phi(m)/2), on the absolute value of the smallest non-zero Fourier coefficient of an s-sparse function, where m=p_1 ... p_t, and phi(m)=(p_1-1) ... (p_t-1). We carefully apply probabilistic techniques from Gopalan et al., to obtain our structural results, and use some non-trivial results from algebraic number theory to get the lower bound. We construct a family of at most s-sparse Boolean functions over Z_p^n, where p > 2, for arbitrarily large enough s, where the minimum non-zero Fourier coefficient is 1/omega(n). The \"Granularity\" result of Gopalan et al. implies that the absolute values of non-zero Fourier coefficients of any s-sparse Boolean valued function over Z_2^n are 1/O(s). So, our result shows that one cannot expect such a lower bound for general Abelian groups. Using our new structural results on the Fourier coefficients of sparse functions, we design an efficient testing algorithm for Fourier-sparse Boolean functions, thata requires poly((ms)^phi(m),1/epsilon)-many queries. Further, we prove an Omega(sqrt{s}) lower bound on the query complexity of any adaptive sparsity testing algorithm."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fast Optimizer Benchmark", "authors": "Simon Blauth, Tobias B\u00fcrger, Zacharias H\u00e4ringer, J\u00f6rg Franke, Frank Hutter", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "In this paper, we present the Fast Optimizer Benchmark (FOB), a tool designed for evaluating deep learning optimizers during their development. The benchmark supports tasks from multiple domains such as computer vision, natural language processing, and graph learning. The focus is on convenient usage, featuring human-readable YAML configurations, SLURM integration, and plotting utilities. FOB can be used together with existing hyperparameter optimization (HPO) tools as it handles training and resuming of runs. The modular design enables integration into custom pipelines, using it simply as a collection of tasks. We showcase an optimizer comparison as a usage example of our tool. FOB can be found on GitHub: this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Simulating The U.S. Senate: An LLM-Driven Agent Approach to Modeling Legislative Behavior and Bipartisanship", "authors": "Zachary R. Baker, Zarif L. Azher", "subjects": "Subjects:\nHuman-Computer Interaction (cs.HC); Computation and Language (cs.CL)", "abstract": "This study introduces a novel approach to simulating legislative processes using LLM-driven virtual agents, focusing on the U.S. Senate Intelligence Committee. We developed agents representing individual senators and placed them in simulated committee discussions. The agents demonstrated the ability to engage in realistic debate, provide thoughtful reflections, and find bipartisan solutions under certain conditions. Notably, the simulation also showed promise in modeling shifts towards bipartisanship in response to external perturbations. Our results indicate that this LLM-driven approach could become a valuable tool for understanding and potentially improving legislative processes, supporting a broader pattern of findings highlighting how LLM-based agents can usefully model real-world phenomena. Future works will focus on enhancing agent complexity, expanding the simulation scope, and exploring applications in policy testing and negotiation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Learn it or Leave it: Module Composition and Pruning for Continual Learning", "authors": "Mingyang Wang, Heike Adel, Lukas Lange, Jannik Str\u00f6tgen, Hinrich Sch\u00fctze", "subjects": "Subjects:\nMachine Learning (cs.LG); Computation and Language (cs.CL)", "abstract": "In real-world environments, continual learning is essential for machine learning models, as they need to acquire new knowledge incrementally without forgetting what they have already learned. While pretrained language models have shown impressive capabilities on various static tasks, applying them to continual learning poses significant challenges, including avoiding catastrophic forgetting, facilitating knowledge transfer, and maintaining parameter efficiency. In this paper, we introduce MoCL-P, a novel lightweight continual learning method that addresses these challenges simultaneously. Unlike traditional approaches that continuously expand parameters for newly arriving tasks, MoCL-P integrates task representation-guided module composition with adaptive pruning, effectively balancing knowledge integration and computational overhead. Our evaluation across three continual learning benchmarks with up to 176 tasks shows that MoCL-P achieves state-of-the-art performance and improves parameter efficiency by up to three times, demonstrating its potential for practical applications where resource requirements are constrained."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SpY: A Context-Based Approach to Spacecraft Component Detection", "authors": "Trupti Mahendrakar, Ryan T. White, Madhur Tiwari", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "This paper focuses on autonomously characterizing components such as solar panels, body panels, antennas, and thrusters of an unknown resident space object (RSO) using camera feed to aid autonomous on-orbit servicing (OOS) and active debris removal. Significant research has been conducted in this area using convolutional neural networks (CNNs). While CNNs are powerful at learning patterns and performing object detection, they struggle with missed detections and misclassifications in environments different from the training data, making them unreliable for safety in high-stakes missions like OOS. Additionally, failures exhibited by CNNs are often easily rectifiable by humans using commonsense reasoning and contextual knowledge. Embedding such reasoning in an object detector could improve detection accuracy. To validate this hypothesis, this paper presents an end-to-end object detector called SpaceYOLOv2 (SpY), which leverages the generalizability of CNNs while incorporating contextual knowledge using traditional computer vision techniques. SpY consists of two main components: a shape detector and the SpaceYOLO classifier (SYC). The shape detector uses CNNs to detect primitive shapes of RSOs and SYC associates these shapes with contextual knowledge, such as color and texture, to classify them as spacecraft components or \"unknown\" if the detected shape is uncertain. SpY's modular architecture allows customizable usage of contextual knowledge to improve detection performance, or SYC as a secondary fail-safe classifier with an existing spacecraft component detector. Performance evaluations on hardware-in-the-loop images of a mock-up spacecraft demonstrate that SpY is accurate and an ensemble of SpY with YOLOv5 trained for satellite component detection improved the performance by 23.4% in recall, demonstrating enhanced safety for vision-based navigation tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Dynamic Gaussian Marbles for Novel View Synthesis of Casual Monocular Videos", "authors": "Colton Stearns, Adam Harley, Mikaela Uy, Florian Dubost, Federico Tombari, Gordon Wetzstein, Leonidas Guibas", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Gaussian splatting has become a popular representation for novel-view synthesis, exhibiting clear strengths in efficiency, photometric quality, and compositional edibility. Following its success, many works have extended Gaussians to 4D, showing that dynamic Gaussians maintain these benefits while also tracking scene geometry far better than alternative representations. Yet, these methods assume dense multi-view videos as supervision, constraining their use to controlled capture settings. In this work, we extend the capability of Gaussian scene representations to casually captured monocular videos. We show that existing 4D Gaussian methods dramatically fail in this setup because the monocular setting is underconstrained. Building off this finding, we propose Dynamic Gaussian Marbles (DGMarbles), consisting of three core modifications that target the difficulties of the monocular setting. First, DGMarbles uses isotropic Gaussian \"marbles\", reducing the degrees of freedom of each Gaussian, and constraining the optimization to focus on motion and appearance over local shape. Second, DGMarbles employs a hierarchical divide-and-conquer learning strategy to guide the optimization towards solutions with coherent motion. Finally, DGMarbles adds image-level and geometry-level priors into the optimization, including a tracking loss that takes advantage of recent progress in point tracking. By constraining the optimization in these ways, DGMarbles learns Gaussian trajectories that enable novel-view rendering and accurately capture the 3D motion of the scene elements. We evaluate on the (monocular) Nvidia Dynamic Scenes dataset and the Dycheck iPhone dataset, and show that DGMarbles significantly outperforms other Gaussian baselines in quality, and is on-par with non-Gaussian representations, all while maintaining the efficiency, compositionality, editability, and tracking benefits of Gaussians."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          State-Based Automation for Time-Restricted Eating Adherence", "authors": "Samuel E. Armstrong, Aaron D. Mullen, J. Matthew Thomas, Dorothy D. Sears, Julie S. Pendergast, Jeffrey Talbert, Cody Bumgardner", "subjects": "Subjects:\nHuman-Computer Interaction (cs.HC); Systems and Control (eess.SY)", "abstract": "Developing and enforcing study protocols is a foundational component of medical research. As study complexity for participant interactions increases, translating study protocols to supporting application code becomes challenging. A collaboration exists between the University of Kentucky and Arizona State University to determine the efficacy of time-restricted eating in improving metabolic risk among postmenopausal women. This study utilizes a graph-based approach to monitor and support adherence to a designated schedule, enabling the validation and step-wise audit of participants' statuses to derive dependable conclusions. A texting service, driven by a participant graph, automatically manages interactions and collects data. Participant data is then accessible to the research study team via a website, which enables viewing, management, and exportation. This paper presents a system for automatically managing participants in a time-restricted eating study that eliminates time-consuming interactions with participants."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Open-World Grasping with Large Vision-Language Models", "authors": "Georgios Tziafas, Hamidreza Kasaei", "subjects": "Subjects:\nRobotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The ability to grasp objects in-the-wild from open-ended language instructions constitutes a fundamental challenge in robotics. An open-world grasping system should be able to combine high-level contextual with low-level physical-geometric reasoning in order to be applicable in arbitrary scenarios. Recent works exploit the web-scale knowledge inherent in large language models (LLMs) to plan and reason in robotic context, but rely on external vision and action models to ground such knowledge into the environment and parameterize actuation. This setup suffers from two major bottlenecks: a) the LLM's reasoning capacity is constrained by the quality of visual grounding, and b) LLMs do not contain low-level spatial understanding of the world, which is essential for grasping in contact-rich scenarios. In this work we demonstrate that modern vision-language models (VLMs) are capable of tackling such limitations, as they are implicitly grounded and can jointly reason about semantics and geometry. We propose OWG, an open-world grasping pipeline that combines VLMs with segmentation and grasp synthesis models to unlock grounded world understanding in three stages: open-ended referring segmentation, grounded grasp planning and grasp ranking via contact reasoning, all of which can be applied zero-shot via suitable visual prompting mechanisms. We conduct extensive evaluation in cluttered indoor scene datasets to showcase OWG's robustness in grounding from open-ended language, as well as open-world robotic grasping experiments in both simulation and hardware that demonstrate superior performance compared to previous supervised and zero-shot LLM-based methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Jailbreaking LLMs with Arabic Transliteration and Arabizi", "authors": "Mansour Al Ghanim, Saleh Almohaimeed, Mengxin Zheng, Yan Solihin, Qian Lou", "subjects": "Subjects:\nMachine Learning (cs.LG); Computation and Language (cs.CL)", "abstract": "This study identifies the potential vulnerabilities of Large Language Models (LLMs) to 'jailbreak' attacks, specifically focusing on the Arabic language and its various forms. While most research has concentrated on English-based prompt manipulation, our investigation broadens the scope to investigate the Arabic language. We initially tested the AdvBench benchmark in Standardized Arabic, finding that even with prompt manipulation techniques like prefix injection, it was insufficient to provoke LLMs into generating unsafe content. However, when using Arabic transliteration and chatspeak (or arabizi), we found that unsafe content could be produced on platforms like OpenAI GPT-4 and Anthropic Claude 3 Sonnet. Our findings suggest that using Arabic and its various forms could expose information that might remain hidden, potentially increasing the risk of jailbreak attacks. We hypothesize that this exposure could be due to the model's learned connection to specific words, highlighting the need for more comprehensive safety training across all language forms."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Data-driven identification of port-Hamiltonian DAE systems by Gaussian processes", "authors": "Peter Zaspel, Michael G\u00fcnther", "subjects": "Subjects:\nSystems and Control (eess.SY); Machine Learning (cs.LG); Numerical Analysis (math.NA)", "abstract": "Port-Hamiltonian systems (pHS) allow for a structure-preserving modeling of dynamical systems. Coupling pHS via linear relations between input and output defines an overall pHS, which is structure preserving. However, in multiphysics applications, some subsystems do not allow for a physical pHS description, as (a) this is not available or (b) too expensive. Here, data-driven approaches can be used to deliver a pHS for such subsystems, which can then be coupled to the other subsystems in a structure-preserving way. In this work, we derive a data-driven identification approach for port-Hamiltonian differential algebraic equation (DAE) systems. The approach uses input and state space data to estimate nonlinear effort functions of pH-DAEs. As underlying technique, we us (multi-task) Gaussian processes. This work thereby extends over the current state of the art, in which only port-Hamiltonian ordinary differential equation systems could be identified via Gaussian processes. We apply this approach successfully to two applications from network design and constrained multibody system dynamics, based on pH-DAE system of index one and three, respectively."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Demonic variance and a non-determinism score for Markov decision processes", "authors": "Jakob Piribauer", "subjects": "Subjects:\nLogic in Computer Science (cs.LO)", "abstract": "This paper studies the influence of probabilism and non-determinism on some quantitative aspect X of the execution of a system modeled as a Markov decision process (MDP). To this end, the novel notion of demonic variance is introduced: For a random variable X in an MDP M, it is defined as 1/2 times the maximal expected squared distance of the values of X in two independent execution of M in which also the non-deterministic choices are resolved independently by two distinct schedulers. It is shown that the demonic variance is between 1 and 2 times as large as the maximal variance of X in M that can be achieved by a single scheduler. This allows defining a non-determinism score for M and X measuring how strongly the difference of X in two executions of M can be influenced by the non-deterministic choices. Properties of MDPs M with extremal values of the non-determinism score are established. Further, the algorithmic problems of computing the maximal variance and the demonic variance are investigated for two random variables, namely weighted reachability and accumulated rewards. In the process, also the structure of schedulers maximizing the variance and of scheduler pairs realizing the demonic variance is analyzed."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RetroGFN: Diverse and Feasible Retrosynthesis using GFlowNets", "authors": "Piotr Gai\u0144ski, Micha\u0142 Koziarski, Krzysztof Maziarz, Marwin Segler, Jacek Tabor, Marek \u015amieja", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Single-step retrosynthesis aims to predict a set of reactions that lead to the creation of a target molecule, which is a crucial task in molecular discovery. Although a target molecule can often be synthesized with multiple different reactions, it is not clear how to verify the feasibility of a reaction, because the available datasets cover only a tiny fraction of the possible solutions. Consequently, the existing models are not encouraged to explore the space of possible reactions sufficiently. In this paper, we propose a novel single-step retrosynthesis model, RetroGFN, that can explore outside the limited dataset and return a diverse set of feasible reactions by leveraging a feasibility proxy model during the training. We show that RetroGFN achieves competitive results on standard top-k accuracy while outperforming existing methods on round-trip accuracy. Moreover, we provide empirical arguments in favor of using round-trip accuracy which expands the notion of feasibility with respect to the standard top-k accuracy metric."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Re-Ranking Step by Step: Investigating Pre-Filtering for Re-Ranking with Large Language Models", "authors": "Baharan Nouriinanloo, Maxime Lamothe", "subjects": "Subjects:\nComputation and Language (cs.CL); Information Retrieval (cs.IR)", "abstract": "Large Language Models (LLMs) have been revolutionizing a myriad of natural language processing tasks with their diverse zero-shot capabilities. Indeed, existing work has shown that LLMs can be used to great effect for many tasks, such as information retrieval (IR), and passage ranking. However, current state-of-the-art results heavily lean on the capabilities of the LLM being used. Currently, proprietary, and very large LLMs such as GPT-4 are the highest performing passage re-rankers. Hence, users without the resources to leverage top of the line LLMs, or ones that are closed source, are at a disadvantage. In this paper, we investigate the use of a pre-filtering step before passage re-ranking in IR. Our experiments show that by using a small number of human generated relevance scores, coupled with LLM relevance scoring, it is effectively possible to filter out irrelevant passages before re-ranking. Our experiments also show that this pre-filtering then allows the LLM to perform significantly better at the re-ranking task. Indeed, our results show that smaller models such as Mixtral can become competitive with much larger proprietary models (e.g., ChatGPT and GPT-4)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Decentralized Semantic Traffic Control in AVs Using RL and DQN for Dynamic Roadblocks", "authors": "Emanuel Figetakis, Yahuza Bello, Ahmed Refaey, Abdallah Shami", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)", "abstract": "Autonomous Vehicles (AVs), furnished with sensors capable of capturing essential vehicle dynamics such as speed, acceleration, and precise location, possess the capacity to execute intelligent maneuvers, including lane changes, in anticipation of approaching roadblocks. Nevertheless, the sheer volume of sensory data and the processing necessary to derive informed decisions can often overwhelm the vehicles, rendering them unable to handle the task independently. Consequently, a common approach in traffic scenarios involves transmitting the data to servers for processing, a practice that introduces challenges, particularly in situations demanding real-time processing. In response to this challenge, we present a novel DL-based semantic traffic control system that entrusts semantic encoding responsibilities to the vehicles themselves. This system processes driving decisions obtained from a Reinforcement Learning (RL) agent, streamlining the decision-making process. Specifically, our framework envisions scenarios where abrupt roadblocks materialize due to factors such as road maintenance, accidents, or vehicle repairs, necessitating vehicles to make determinations concerning lane-keeping or lane-changing actions to navigate past these obstacles. To formulate this scenario mathematically, we employ a Markov Decision Process (MDP) and harness the Deep Q Learning (DQN) algorithm to unearth viable solutions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          3D Feature Distillation with Object-Centric Priors", "authors": "Georgios Tziafas, Yucheng Xu, Zhibin Li, Hamidreza Kasaei", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "abstract": "Grounding natural language to the physical world is a ubiquitous topic with a wide range of applications in computer vision and robotics. Recently, 2D vision-language models such as CLIP have been widely popularized, due to their impressive capabilities for open-vocabulary grounding in 2D images. Recent works aim to elevate 2D CLIP features to 3D via feature distillation, but either learn neural fields that are scene-specific and hence lack generalization, or focus on indoor room scan data that require access to multiple camera views, which is not practical in robot manipulation scenarios. Additionally, related methods typically fuse features at pixel-level and assume that all camera views are equally informative. In this work, we show that this approach leads to sub-optimal 3D features, both in terms of grounding accuracy, as well as segmentation crispness. To alleviate this, we propose a multi-view feature fusion strategy that employs object-centric priors to eliminate uninformative views based on semantic information, and fuse features at object-level via instance segmentation masks. To distill our object-centric 3D features, we generate a large-scale synthetic multi-view dataset of cluttered tabletop scenes, spawning 15k scenes from over 3300 unique object instances, which we make publicly available. We show that our method reconstructs 3D CLIP features with improved grounding capacity and spatial consistency, while doing so from single-view RGB-D, thus departing from the assumption of multiple camera views at test time. Finally, we show that our approach can generalize to novel tabletop domains and be re-purposed for 3D instance segmentation without fine-tuning, and demonstrate its utility for language-guided robotic grasping in clutter"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          QBI: Quantile-based Bias Initialization for Efficient Private Data Reconstruction in Federated Learning", "authors": "Micha V. Nowak, Tim P. Bott, David Khachaturov, Frank Puppe, Adrian Krenzer, Amar Hekalo", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Federated learning enables the training of machine learning models on distributed data without compromising user privacy, as data remains on personal devices and only model updates, such as gradients, are shared with a central coordinator. However, recent research has shown that the central entity can perfectly reconstruct private data from shared model updates by maliciously initializing the model's parameters. In this paper, we propose QBI, a novel bias initialization method that significantly enhances reconstruction capabilities. This is accomplished by directly solving for bias values yielding sparse activation patterns. Further, we propose PAIRS, an algorithm that builds on QBI. PAIRS can be deployed when a separate dataset from the target domain is available to further increase the percentage of data that can be fully recovered. Measured by the percentage of samples that can be perfectly reconstructed from batches of various sizes, our approach achieves significant improvements over previous methods with gains of up to 50% on ImageNet and up to 60% on the IMDB sentiment analysis text dataset. Furthermore, we establish theoretical limits for attacks leveraging stochastic gradient sparsity, providing a foundation for understanding the fundamental constraints of these attacks. We empirically assess these limits using synthetic datasets. Finally, we propose and evaluate AGGP, a defensive framework designed to prevent gradient sparsity attacks, contributing to the development of more secure and private federated learning systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Lifelong Robot Library Learning: Bootstrapping Composable and Generalizable Skills for Embodied Control with Language Models", "authors": "Georgios Tziafas, Hamidreza Kasaei", "subjects": "Subjects:\nRobotics (cs.RO)", "abstract": "Large Language Models (LLMs) have emerged as a new paradigm for embodied reasoning and control, most recently by generating robot policy code that utilizes a custom library of vision and control primitive skills. However, prior arts fix their skills library and steer the LLM with carefully hand-crafted prompt engineering, limiting the agent to a stationary range of addressable tasks. In this work, we introduce LRLL, an LLM-based lifelong learning agent that continuously grows the robot skill library to tackle manipulation tasks of ever-growing complexity. LRLL achieves this with four novel contributions: 1) a soft memory module that allows dynamic storage and retrieval of past experiences to serve as context, 2) a self-guided exploration policy that proposes new tasks in simulation, 3) a skill abstractor that distills recent experiences into new library skills, and 4) a lifelong learning algorithm for enabling human users to bootstrap new skills with minimal online interaction. LRLL continuously transfers knowledge from the memory to the library, building composable, general and interpretable policies, while bypassing gradient-based optimization, thus relieving the learner from catastrophic forgetting. Empirical evaluation in a simulated tabletop environment shows that LRLL outperforms end-to-end and vanilla LLM approaches in the lifelong setup while learning skills that are transferable to the real world. Project material will become available at the webpage this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Stem-Agnostic Single-Decoder System for Music Source Separation Beyond Four Stems", "authors": "Karn N. Watcharasupat, Alexander Lerch", "subjects": "Subjects:\nSound (cs.SD); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)", "abstract": "Despite significant recent progress across multiple subtasks of audio source separation, few music source separation systems support separation beyond the four-stem vocals, drums, bass, and other (VDBO) setup. Of the very few current systems that support source separation beyond this setup, most continue to rely on an inflexible decoder setup that can only support a fixed pre-defined set of stems. Increasing stem support in these inflexible systems correspondingly requires increasing computational complexity, rendering extensions of these systems computationally infeasible for long-tail instruments. In this work, we propose Banquet, a system that allows source separation of multiple stems using just one decoder. A bandsplit source separation model is extended to work in a query-based setup in tandem with a music instrument recognition PaSST model. On the MoisesDB dataset, Banquet, at only 24.9 M trainable parameters, approached the performance level of the significantly more complex 6-stem Hybrid Transformer Demucs on VDBO stems and outperformed it on guitar and piano. The query-based setup allows for the separation of narrow instrument classes such as clean acoustic guitars, and can be successfully applied to the extraction of less common stems such as reeds and organs. Implementation is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Competitive Algorithms for Online Knapsack with Succinct Predictions", "authors": "Mohammadreza Daneshvaramoli, Helia Karisani, Adam Lechowicz, Bo Sun, Cameron Musco, Mohammad Hajiesmaili", "subjects": "Subjects:\nMachine Learning (cs.LG); Computer Science and Game Theory (cs.GT)", "abstract": "In the online knapsack problem, the goal is to pack items arriving online with different values and weights into a capacity-limited knapsack to maximize the total value of the accepted items. We study \\textit{learning-augmented} algorithms for this problem, which aim to use machine-learned predictions to move beyond pessimistic worst-case guarantees. Existing learning-augmented algorithms for online knapsack consider relatively complicated prediction models that give an algorithm substantial information about the input, such as the total weight of items at each value. In practice, such predictions can be error-sensitive and difficult to learn. Motivated by this limitation, we introduce a family of learning-augmented algorithms for online knapsack that use \\emph{succinct predictions}. In particular, the machine-learned prediction given to the algorithm is just a single value or interval that estimates the minimum value of any item accepted by an offline optimal solution. By leveraging a relaxation to online \\emph{fractional} knapsack, we design algorithms that can leverage such succinct predictions in both the trusted setting (i.e., with perfect prediction) and the untrusted setting, where we prove that a simple meta-algorithm achieves a nearly optimal consistency-robustness trade-off. Empirically, we show that our algorithms significantly outperform baselines that do not use predictions and often outperform algorithms based on more complex prediction models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Impact of Feature Representation on the Accuracy of Photonic Neural Networks", "authors": "Mauricio Gomes de Queiroz, Paul Jimenez, Raphael Cardoso, Mateus Vidaletti da Costa, Mohab Abdalla, Ian O'Connor, Alberto Bosio, Fabio Pavanello", "subjects": "Subjects:\nEmerging Technologies (cs.ET); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Photonic Neural Networks (PNNs) are gaining significant interest in the research community due to their potential for high parallelization, low latency, and energy efficiency. PNNs compute using light, which leads to several differences in implementation when compared to electronics, such as the need to represent input features in the photonic domain before feeding them into the network. In this encoding process, it is common to combine multiple features into a single input to reduce the number of inputs and associated devices, leading to smaller and more energy-efficient PNNs. Although this alters the network's handling of input data, its impact on PNNs remains understudied. This paper addresses this open question, investigating the effect of commonly used encoding strategies that combine features on the performance and learning capabilities of PNNs. Here, using the concept of feature importance, we develop a mathematical framework for analyzing feature combination. Through this framework, we demonstrate that encoding multiple features together in a single input determines their relative importance, thus limiting the network's ability to learn from the data. Given some prior knowledge of the data, however, this can also be leveraged for higher accuracy. By selecting an optimal encoding method, we achieve up to a 12.3\\% improvement in accuracy of PNNs trained on the Iris dataset compared to other encoding techniques, surpassing the performance of networks where features are not combined. These findings highlight the importance of carefully choosing the encoding to the accuracy and decision-making strategies of PNNs, particularly in size or power constrained applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Categorical Syllogisms Revisited: A Review of the Logical Reasoning Abilities of LLMs for Analyzing Categorical Syllogism", "authors": "Shi Zong, Jimmy Lin", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "There have been a huge number of benchmarks proposed to evaluate how large language models (LLMs) behave for logic inference tasks. However, it remains an open question how to properly evaluate this ability. In this paper, we provide a systematic overview of prior works on the logical reasoning ability of LLMs for analyzing categorical syllogisms. We first investigate all the possible variations for the categorical syllogisms from a purely logical perspective and then examine the underlying configurations (i.e., mood and figure) tested by the existing datasets. Our results indicate that compared to template-based synthetic datasets, crowdsourcing approaches normally sacrifice the coverage of configurations (i.e., mood and figure) of categorical syllogisms for more language variations, thus bringing challenges to fully testing LLMs under different situations. We then proceed to summarize the findings and observations for the performances of LLMs to infer the validity of syllogisms from the current literature. The error rate breakdown analyses suggest that the interpretation of the quantifiers seems to be the current bottleneck that limits the performances of the LLMs and is thus worth more attention. Finally, we discuss several points that might be worth considering when researchers plan on the future release of categorical syllogism datasets. We hope our work will not only provide a timely review of the current literature regarding categorical syllogisms, but also motivate more interdisciplinary research between communities, specifically computational linguists and logicians."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Conformalized Link Prediction on Graph Neural Networks", "authors": "Tianyi Zhao, Jian Kang, Lu Cheng", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Graph Neural Networks (GNNs) excel in diverse tasks, yet their applications in high-stakes domains are often hampered by unreliable predictions. Although numerous uncertainty quantification methods have been proposed to address this limitation, they often lack \\textit{rigorous} uncertainty estimates. This work makes the first attempt to introduce a distribution-free and model-agnostic uncertainty quantification approach to construct a predictive interval with a statistical guarantee for GNN-based link prediction. We term it as \\textit{conformalized link prediction.} Our approach builds upon conformal prediction (CP), a framework that promises to construct statistically robust prediction sets or intervals. We first theoretically and empirically establish a permutation invariance condition for the application of CP in link prediction tasks, along with an exact test-time coverage. Leveraging the important structural information in graphs, we then identify a novel and crucial connection between a graph's adherence to the power law distribution and the efficiency of CP. This insight leads to the development of a simple yet effective sampling-based method to align the graph structure with a power law distribution prior to the standard CP procedure. Extensive experiments demonstrate that for conformalized link prediction, our approach achieves the desired marginal coverage while significantly improving the efficiency of CP compared to baseline methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          WV-Net: A foundation model for SAR WV-mode satellite imagery trained using contrastive self-supervised learning on 10 million images", "authors": "Yannik Glaser, Justin E. Stopa, Linnea M. Wolniewicz, Ralph Foster, Doug Vandemark, Alexis Mouche, Bertrand Chapron, Peter Sadowski", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The European Space Agency's Copernicus Sentinel-1 (S-1) mission is a constellation of C-band synthetic aperture radar (SAR) satellites that provide unprecedented monitoring of the world's oceans. S-1's wave mode (WV) captures 20x20 km image patches at 5 m pixel resolution and is unaffected by cloud cover or time-of-day. The mission's open data policy has made SAR data easily accessible for a range of applications, but the need for manual image annotations is a bottleneck that hinders the use of machine learning methods. This study uses nearly 10 million WV-mode images and contrastive self-supervised learning to train a semantic embedding model called WV-Net. In multiple downstream tasks, WV-Net outperforms a comparable model that was pre-trained on natural images (ImageNet) with supervised learning. Experiments show improvements for estimating wave height (0.50 vs 0.60 RMSE using linear probing), estimating near-surface air temperature (0.90 vs 0.97 RMSE), and performing multilabel-classification of geophysical and atmospheric phenomena (0.96 vs 0.95 micro-averaged AUROC). WV-Net embeddings are also superior in an unsupervised image-retrieval task and scale better in data-sparse settings. Together, these results demonstrate that WV-Net embeddings can support geophysical research by providing a convenient foundation model for a variety of data analysis and exploration tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ADO-LLM: Analog Design Bayesian Optimization with In-Context Learning of Large Language Models", "authors": "Yuxuan Yin, Yu Wang, Boxun Xu, Peng Li", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Analog circuit design requires substantial human expertise and involvement, which is a significant roadblock to design productivity. Bayesian Optimization (BO), a popular machine learning based optimization strategy, has been leveraged to automate analog design given its applicability across various circuit topologies and technologies. Traditional BO methods employ black box Gaussian Process surrogate models and optimized labeled data queries to find optimization solutions by trading off between exploration and exploitation. However, the search for the optimal design solution in BO can be expensive from both a computational and data usage point of view, particularly for high dimensional optimization problems. This paper presents ADO-LLM, the first work integrating large language models (LLMs) with Bayesian Optimization for analog design optimization. ADO-LLM leverages the LLM's ability to infuse domain knowledge to rapidly generate viable design points to remedy BO's inefficiency in finding high value design areas specifically under the limited design space coverage of the BO's probabilistic surrogate model. In the meantime, sampling of design points evaluated in the iterative BO process provides quality demonstrations for the LLM to generate high quality design points while leveraging infused broad design knowledge. Furthermore, the diversity brought by BO's exploration enriches the contextual understanding of the LLM and allows it to more broadly search in the design space and prevent repetitive and redundant suggestions. We evaluate the proposed framework on two different types of analog circuits and demonstrate notable improvements in design efficiency and effectiveness."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Implicit Discourse Relation Classification For Nigerian Pidgin", "authors": "Muhammed Saeed, Peter Bourgonje, Vera Demberg", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Despite attempts to make Large Language Models multi-lingual, many of the world's languages are still severely under-resourced. This widens the performance gap between NLP and AI applications aimed at well-financed, and those aimed at less-resourced languages. In this paper, we focus on Nigerian Pidgin (NP), which is spoken by nearly 100 million people, but has comparatively very few NLP resources and corpora. We address the task of Implicit Discourse Relation Classification (IDRC) and systematically compare an approach translating NP data to English and then using a well-resourced IDRC tool and back-projecting the labels versus creating a synthetic discourse corpus for NP, in which we translate PDTB and project PDTB labels, and then train an NP IDR classifier. The latter approach of learning a \"native\" NP classifier outperforms our baseline by 13.27\\% and 33.98\\% in f$_{1}$ score for 4-way and 11-way classification, respectively."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Aligning Model Properties via Conformal Risk Control", "authors": "William Overman, Jacqueline Jil Vallon, Mohsen Bayati", "subjects": "Subjects:\nMachine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "AI model alignment is crucial due to inadvertent biases in training data and the underspecified pipeline in modern machine learning, where numerous models with excellent test set metrics can be produced, yet they may not meet end-user requirements. Recent advances demonstrate that post-training model alignment via human feedback can address some of these challenges. However, these methods are often confined to settings (such as generative AI) where humans can interpret model outputs and provide feedback. In traditional non-generative settings, where model outputs are numerical values or classes, detecting misalignment through single-sample outputs is highly challenging. In this paper we consider an alternative strategy. We propose interpreting model alignment through property testing, defining an aligned model $f$ as one belonging to a subset $\\mathcal{P}$ of functions that exhibit specific desired behaviors. We focus on post-processing a pre-trained model $f$ to better align with $\\mathcal{P}$ using conformal risk control. Specifically, we develop a general procedure for converting queries for a given property $\\mathcal{P}$ to a collection of loss functions suitable for use in a conformal risk control algorithm. We prove a probabilistic guarantee that the resulting conformal interval around $f$ contains a function approximately satisfying $\\mathcal{P}$. Given the capabilities of modern AI models with extensive parameters and training data, one might assume alignment issues will resolve naturally. However, increasing training data or parameters in a random feature model doesn't eliminate the need for alignment techniques when pre-training data is biased. We demonstrate our alignment methodology on supervised learning datasets for properties like monotonicity and concavity. Our flexible procedure can be applied to various desired properties."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Psychological Profiling in Cybersecurity: A Look at LLMs and Psycholinguistic Features", "authors": "Jean Marie Tshimula, D'Jeff K. Nkashama, Jean Tshibangu Muabila, Ren\u00e9 Manass\u00e9 Galekwa, Hugues Kanda, Maximilien V. Dialufuma, Mbuyi Mukendi Didier, Kalala Kalonji, Serge Mundele, Patience Kinshie Lenye, Tighana Wenge Basele, Aristarque Ilunga, Christian N. Mayemba, Nathana\u00ebl M. Kasoro, Selain K. Kasereka, Hardy Mikese, Pierre-Martin Tardif, Marc Frappier, Froduald Kabanza, Belkacem Chikhaoui, Shengrui Wang, Ali Mulenda Sumbu, Xavier Ndona, Raoul Kienge-Kienge Intudi", "subjects": "Subjects:\nComputation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "The increasing sophistication of cyber threats necessitates innovative approaches to cybersecurity. In this paper, we explore the potential of psychological profiling techniques, particularly focusing on the utilization of Large Language Models (LLMs) and psycholinguistic features. We investigate the intersection of psychology and cybersecurity, discussing how LLMs can be employed to analyze textual data for identifying psychological traits of threat actors. We explore the incorporation of psycholinguistic features, such as linguistic patterns and emotional cues, into cybersecurity frameworks. \\iffalse Through case studies and experiments, we discuss the effectiveness of these methods in enhancing threat detection and mitigation strategies.\\fi Our research underscores the importance of integrating psychological perspectives into cybersecurity practices to bolster defense mechanisms against evolving threats."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Constable: Improving Performance and Power Efficiency by Safely Eliminating Load Instruction Execution", "authors": "Rahul Bera, Adithya Ranganathan, Joydeep Rakshit, Sujit Mahto, Anant V. Nori, Jayesh Gaur, Ataberk Olgun, Konstantinos Kanellopoulos, Mohammad Sadrosadati, Sreenivas Subramoney, Onur Mutlu", "subjects": "Subjects:\nHardware Architecture (cs.AR)", "abstract": "Load instructions often limit instruction-level parallelism (ILP) in modern processors due to data and resource dependences they cause. Prior techniques like Load Value Prediction (LVP) and Memory Renaming (MRN) mitigate load data dependence by predicting the data value of a load instruction. However, they fail to mitigate load resource dependence as the predicted load instruction gets executed nonetheless. Our goal in this work is to improve ILP by mitigating both load data dependence and resource dependence. To this end, we propose a purely-microarchitectural technique called Constable, that safely eliminates the execution of load instructions. Constable dynamically identifies load instructions that have repeatedly fetched the same data from the same load address. We call such loads likely-stable. For every likely-stable load, Constable (1) tracks modifications to its source architectural registers and memory location via lightweight hardware structures, and (2) eliminates the execution of subsequent instances of the load instruction until there is a write to its source register or a store or snoop request to its load address. Our extensive evaluation using a wide variety of 90 workloads shows that Constable improves performance by 5.1% while reducing the core dynamic power consumption by 3.4% on average over a strong baseline system that implements MRN and other dynamic instruction optimizations (e.g., move and zero elimination, constant and branch folding). In presence of 2-way simultaneous multithreading (SMT), Constable's performance improvement increases to 8.8% over the baseline system. When combined with a state-of-the-art load value predictor (EVES), Constable provides an additional 3.7% and 7.8% average performance benefit over the load value predictor alone, in the baseline system without and with 2-way SMT, respectively."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Unified Uncertainties: Combining Input, Data and Model Uncertainty into a Single Formulation", "authors": "Matias Valdenegro-Toro, Ivo Pascal de Jong, Marco Zullich", "subjects": "Subjects:\nMachine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "Modelling uncertainty in Machine Learning models is essential for achieving safe and reliable predictions. Most research on uncertainty focuses on output uncertainty (predictions), but minimal attention is paid to uncertainty at inputs. We propose a method for propagating uncertainty in the inputs through a Neural Network that is simultaneously able to estimate input, data, and model uncertainty. Our results show that this propagation of input uncertainty results in a more stable decision boundary even under large amounts of input noise than comparatively simple Monte Carlo sampling. Additionally, we discuss and demonstrate that input uncertainty, when propagated through the model, results in model uncertainty at the outputs. The explicit incorporation of input uncertainty may be beneficial in situations where the amount of input uncertainty is known, though good datasets for this are still needed."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MUMU: Bootstrapping Multimodal Image Generation from Text-to-Image Data", "authors": "William Berman, Alexander Peysakhovich", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "We train a model to generate images from multimodal prompts of interleaved text and images such as \"a <picture of a man> man and his <picture of a dog> dog in an <picture of a cartoon> animated style.\" We bootstrap a multimodal dataset by extracting semantically meaningful image crops corresponding to words in the image captions of synthetically generated and publicly available text-image data. Our model, MUMU, is composed of a vision-language model encoder with a diffusion decoder and is trained on a single 8xH100 GPU node. Despite being only trained on crops from the same image, MUMU learns to compose inputs from different images into a coherent output. For example, an input of a realistic person and a cartoon will output the same person in the cartoon style, and an input of a standing subject and a scooter will output the subject riding the scooter. As a result, our model generalizes to tasks such as style transfer and character consistency. Our results show the promise of using multimodal models as general purpose controllers for image generation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A data-driven assessment of biomedical terminology evolution using information theoretical and network analysis approaches", "authors": "Jenny Copara, Nona Naderi, Gilles Falquet, Douglas Teodoro", "subjects": "Subjects:\nSocial and Information Networks (cs.SI)", "abstract": "The Medical Subject Headings (MeSH), one of the main knowledge organization systems in the biomedical domain, is constantly evolving following the latest scientific discoveries in health and life sciences. Previous research focused on quantifying information in MeSH using its hierarchical structure. In this work, we propose a data-driven approach based on information theory and network analyses to quantify the knowledge evolution in MeSH and the relevance of its individual concepts. Our approach leverages article annotations and their citation networks to compute the level of informativeness, usefulness, disruptiveness, and influence of MeSH concepts over time. The citation network includes the instances of MeSH concepts or MeSH headings, and the concept relevance is calculated individually. Then, this computation is propagated to the hierarchy to establish the relevance of a concept. We quantitatively evaluated our approach using changes in the MeSH terminology and showed that it effectively captures the evolution of the terminology. Moreover, we validated the ability of our framework to characterize retracted articles and show that concepts used to annotate retracted articles differ substantially from those used to annotate non-retracted. The proposed framework provides an effective method to rank concept relevance and can be useful in maintaining evolving knowledge organization systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Operator Learning of Lipschitz Operators: An Information-Theoretic Perspective", "authors": "Samuel Lanthaler", "subjects": "Subjects:\nMachine Learning (cs.LG); Numerical Analysis (math.NA)", "abstract": "Operator learning based on neural operators has emerged as a promising paradigm for the data-driven approximation of operators, mapping between infinite-dimensional Banach spaces. Despite significant empirical progress, our theoretical understanding regarding the efficiency of these approximations remains incomplete. This work addresses the parametric complexity of neural operator approximations for the general class of Lipschitz continuous operators. Motivated by recent findings on the limitations of specific architectures, termed curse of parametric complexity, we here adopt an information-theoretic perspective. Our main contribution establishes lower bounds on the metric entropy of Lipschitz operators in two approximation settings; uniform approximation over a compact set of input functions, and approximation in expectation, with input functions drawn from a probability measure. It is shown that these entropy bounds imply that, regardless of the activation function used, neural operator architectures attaining an approximation accuracy $\\epsilon$ must have a size that is exponentially large in $\\epsilon^{-1}$. The size of architectures is here measured by counting the number of encoded bits necessary to store the given model in computational memory. The results of this work elucidate fundamental trade-offs and limitations in"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Infinite Width Models That Work: Why Feature Learning Doesn't Matter as Much as You Think", "authors": "Luke Sernau", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Common infinite-width architectures such as Neural Tangent Kernels (NTKs) have historically shown weak performance compared to finite models. This has been attributed to the absence of feature learning. We show that this is not the case. In fact, we show that infinite width NTK models are able to access richer features than finite models by selecting relevant subfeatures from their (infinite) feature vector. In fact, we show experimentally that NTKs under-perform traditional finite models even when feature learning is artificially disabled. Instead, weak performance is due to the fact that existing constructions depend on weak optimizers like SGD. We provide an infinite width limit based on ADAM-like learning dynamics and demonstrate empirically that the resulting models erase this performance gap."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Ksurf: Attention Kalman Filter and Principal Component Analysis for Prediction under Highly Variable Cloud Workloads", "authors": "Michael Dang'ana, Arno Jacobsen", "subjects": "Subjects:\nDistributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Cloud platforms have become essential in rapidly deploying application systems online to serve large numbers of users. Resource estimation and workload forecasting are critical in cloud data centers. Complexity in the cloud provider environment due to varying numbers of virtual machines introduces high variability in workloads and resource usage, making resource predictions problematic using state-of-the-art models that fail to deal with nonlinear characteristics. Estimating and predicting the resource metrics of cloud systems across packet networks influenced by unknown external dynamics is a task affected by high measurement noise and variance. An ideal solution to these problems is the Kalman filter, a variance-minimizing estimator used for system state estimation and efficient low latency system state prediction. Kalman filters are optimal estimators for highly variable data with Gaussian state space characteristics such as internet workloads. This work provides a solution by making these contributions: i) it introduces and evaluates the Kalman filter-based model parameter prediction using principal component analysis and an attention mechanism for noisy cloud data, ii) evaluates the scheme on a Google Cloud benchmark comparing it to the state-of-the-art Bi-directional Grid Long Short-Term Memory network model on prediction tasks, iii) it applies these techniques to demonstrate the accuracy and stability improvements on a realtime messaging system auto-scaler in Apache Kafka. The new scheme improves prediction accuracy by $37\\%$ over state-of-the-art Kalman filters in noisy signal prediction tasks. It reduces the prediction error of the neural network model by over $40\\%$. It is shown to improve Apache Kafka workload-based scaling stability by $58\\%$."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          All Random Features Representations are Equivalent", "authors": "Luke Sernau, Silvano Bonacina, Rif A. Saurous", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Random features are an important technique that make it possible to rewrite positive-definite kernels as infinite-dimensional dot products. Over time, increasingly elaborate random feature representations have been developed in pursuit of finite approximations with ever lower error. We resolve this arms race by deriving an optimal sampling policy, and show that under this policy all random features representations have the same approximation error. This establishes a lower bound that holds across all random feature representations, and shows that we are free to choose whatever representation we please, provided we sample optimally."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          State and Input Constrained Output-Feedback Adaptive Optimal Control of Affine Nonlinear Systems", "authors": "Tochukwu Elijah Ogri, Muzaffar Qureshi, Zachary I. Bell, Rushikesh Kamalapurkar", "subjects": "Subjects:\nSystems and Control (eess.SY)", "abstract": "In this paper, a novel online, output-feedback, critic-only, model-based reinforcement learning framework is developed for safety-critical control systems operating in complex environments. The developed framework ensures system stability and safety, regardless of the lack of full-state measurement, while learning and implementing an optimal controller. The approach leverages linear matrix inequality-based observer design method to efficiently search for observer gains for effective state estimation. Then, approximate dynamic programming is used to develop an approximate controller that uses simulated experiences to guarantee the safety and stability of the closed-loop system. Safety is enforced by adding a recentered robust Lyapunov-like barrier function to the cost function that effectively enforces safety constraints, even in the presence of uncertainty in the state. Lyapunov-based stability analysis is used to guarantee uniform ultimate boundedness of the trajectories of the closed-loop system and ensure safety. Simulation studies are performed to demonstrate the effectiveness of the developed method through two real-world safety-critical scenarios, ensuring that the state trajectories of a given system remain in a given set and obstacle avoidance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Online Stackelberg Optimization via Nonlinear Control", "authors": "William Brown, Christos Papadimitriou, Tim Roughgarden", "subjects": "Subjects:\nMachine Learning (cs.LG); Computer Science and Game Theory (cs.GT)", "abstract": "In repeated interaction problems with adaptive agents, our objective often requires anticipating and optimizing over the space of possible agent responses. We show that many problems of this form can be cast as instances of online (nonlinear) control which satisfy \\textit{local controllability}, with convex losses over a bounded state space which encodes agent behavior, and we introduce a unified algorithmic framework for tractable regret minimization in such cases. When the instance dynamics are known but otherwise arbitrary, we obtain oracle-efficient $O(\\sqrt{T})$ regret by reduction to online convex optimization, which can be made computationally efficient if dynamics are locally \\textit{action-linear}. In the presence of adversarial disturbances to the state, we give tight bounds in terms of either the cumulative or per-round disturbance magnitude (for \\textit{strongly} or \\textit{weakly} locally controllable dynamics, respectively). Additionally, we give sublinear regret results for the cases of unknown locally action-linear dynamics as well as for the bandit feedback setting. Finally, we demonstrate applications of our framework to well-studied problems including performative prediction, recommendations for adaptive agents, adaptive pricing of real-valued goods, and repeated gameplay against no-regret learners, directly yielding extensions beyond prior results in each case."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Divide, Ensemble and Conquer: The Last Mile on Unsupervised Domain Adaptation for On-Board Semantic Segmentation", "authors": "Tao Lian, Jose L. G\u00f3mez, Antonio M. L\u00f3pez", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "The last mile of unsupervised domain adaptation (UDA) for semantic segmentation is the challenge of solving the syn-to-real domain gap. Recent UDA methods have progressed significantly, yet they often rely on strategies customized for synthetic single-source datasets (e.g., GTA5), which limits their generalisation to multi-source datasets. Conversely, synthetic multi-source datasets hold promise for advancing the last mile of UDA but remain underutilized in current research. Thus, we propose DEC, a flexible UDA framework for multi-source datasets. Following a divide-and-conquer strategy, DEC simplifies the task by categorizing semantic classes, training models for each category, and fusing their outputs by an ensemble model trained exclusively on synthetic datasets to obtain the final segmentation mask. DEC can integrate with existing UDA methods, achieving state-of-the-art performance on Cityscapes, BDD100K, and Mapillary Vistas, significantly narrowing the syn-to-real domain gap."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Survey on Privacy Attacks Against Digital Twin Systems in AI-Robotics", "authors": "Ivan A. Fernandez, Subash Neupane, Trisha Chakraborty, Shaswata Mitra, Sudip Mittal, Nisha Pillai, Jingdao Chen, Shahram Rahimi", "subjects": "Subjects:\nRobotics (cs.RO); Artificial Intelligence (cs.AI)", "abstract": "Industry 4.0 has witnessed the rise of complex robots fueled by the integration of Artificial Intelligence/Machine Learning (AI/ML) and Digital Twin (DT) technologies. While these technologies offer numerous benefits, they also introduce potential privacy and security risks. This paper surveys privacy attacks targeting robots enabled by AI and DT models. Exfiltration and data leakage of ML models are discussed in addition to the potential extraction of models derived from first-principles (e.g., physics-based). We also discuss design considerations with DT-integrated robotics touching on the impact of ML model training, responsible AI and DT safeguards, data governance and ethical considerations on the effectiveness of these attacks. We advocate for a trusted autonomy approach, emphasizing the need to combine robotics, AI, and DT technologies with robust ethical frameworks and trustworthiness principles for secure and reliable AI robotic systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Secure Management of Edge-Cloud IoT Microservices using Policy as Code", "authors": "Samodha Pallewatta, Muhammad Ali Babar", "subjects": "Subjects:\nCryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); Software Engineering (cs.SE)", "abstract": "IoT application providers increasingly use MicroService Architecture (MSA) to develop applications that convert IoT data into valuable information. The independently deployable and scalable nature of microservices enables dynamic utilization of edge and cloud resources provided by various service providers, thus improving performance. However, IoT data security should be ensured during multi-domain data processing and transmission among distributed and dynamically composed microservices. The ability to implement granular security controls at the microservices level has the potential to solve this. To this end, edge-cloud environments require intricate and scalable security frameworks that operate across multi-domain environments to enforce various security policies during the management of microservices (i.e., initial placement, scaling, migration, and dynamic composition), considering the sensitivity of the IoT data. To address the lack of such a framework, we propose an architectural framework that uses Policy-as-Code to ensure secure microservice management within multi-domain edge-cloud environments. The proposed framework contains a \"control plane\" to intelligently and dynamically utilise and configure cloud-native (i.e., container orchestrators and service mesh) technologies to enforce security policies. We implement a prototype of the proposed framework using open-source cloud-native technologies such as Docker, Kubernetes, Istio, and Open Policy Agent to validate the framework. Evaluations verify our proposed framework's ability to enforce security policies for distributed microservices management, thus harvesting the MSA characteristics to ensure IoT application security needs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MissionGNN: Hierarchical Multimodal GNN-based Weakly Supervised Video Anomaly Recognition with Mission-Specific Knowledge Graph Generation", "authors": "Sanggeon Yun, Ryozo Masukawa, Minhyoung Na, Mohsen Imani", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "In the context of escalating safety concerns across various domains, the tasks of Video Anomaly Detection (VAD) and Video Anomaly Recognition (VAR) have emerged as critically important for applications in intelligent surveillance, evidence investigation, violence alerting, etc. These tasks, aimed at identifying and classifying deviations from normal behavior in video data, face significant challenges due to the rarity of anomalies which leads to extremely imbalanced data and the impracticality of extensive frame-level data annotation for supervised learning. This paper introduces a novel hierarchical graph neural network (GNN) based model MissionGNN that addresses these challenges by leveraging a state-of-the-art large language model and a comprehensive knowledge graph for efficient weakly supervised learning in VAR. Our approach circumvents the limitations of previous methods by avoiding heavy gradient computations on large multimodal models and enabling fully frame-level training without fixed video segmentation. Utilizing automated, mission-specific knowledge graph generation, our model provides a practical and efficient solution for real-time video analysis without the constraints of previous segmentation-based or multimodal approaches. Experimental validation on benchmark datasets demonstrates our model's performance in VAD and VAR, highlighting its potential to redefine the landscape of anomaly detection and recognition in video surveillance systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Correspondence-Free Non-Rigid Point Set Registration Using Unsupervised Clustering Analysis", "authors": "Mingyang Zhao, Jingen Jiang, Lei Ma, Shiqing Xin, Gaofeng Meng, Dong-Ming Yan", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "This paper presents a novel non-rigid point set registration method that is inspired by unsupervised clustering analysis. Unlike previous approaches that treat the source and target point sets as separate entities, we develop a holistic framework where they are formulated as clustering centroids and clustering members, separately. We then adopt Tikhonov regularization with an $\\ell_1$-induced Laplacian kernel instead of the commonly used Gaussian kernel to ensure smooth and more robust displacement fields. Our formulation delivers closed-form solutions, theoretical guarantees, independence from dimensions, and the ability to handle large deformations. Subsequently, we introduce a clustering-improved Nystr\u00f6m method to effectively reduce the computational complexity and storage of the Gram matrix to linear, while providing a rigorous bound for the low-rank approximation. Our method achieves high accuracy results across various scenarios and surpasses competitors by a significant margin, particularly on shapes with substantial deformations. Additionally, we demonstrate the versatility of our method in challenging tasks such as shape transfer and medical registration."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Universal Checkpointing: Efficient and Flexible Checkpointing for Large Scale Distributed Training", "authors": "Xinyu Lian, Sam Ade Jacobs, Lev Kurilenko, Masahiro Tanaka, Stas Bekman, Olatunji Ruwase, Minjia Zhang", "subjects": "Subjects:\nDistributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)", "abstract": "Existing checkpointing approaches seem ill-suited for distributed training even though hardware limitations make model parallelism, i.e., sharding model state across multiple accelerators, a requirement for model scaling. Consolidating distributed model state into a single checkpoint unacceptably slows down training, and is impractical at extreme scales. Distributed checkpoints, in contrast, are tightly coupled to the model parallelism and hardware configurations of the training run, and thus unusable on different configurations. To address this problem, we propose Universal Checkpointing, a technique that enables efficient checkpoint creation while providing the flexibility of resuming on arbitrary parallelism strategy and hardware configurations. Universal Checkpointing unlocks unprecedented capabilities for large-scale training such as improved resilience to hardware failures through continued training on remaining healthy hardware, and reduced training time through opportunistic exploitation of elastic capacity. The key insight of Universal Checkpointing is the selection of the optimal representation in each phase of the checkpointing life cycle: distributed representation for saving, and consolidated representation for loading. This is achieved using two key mechanisms. First, the universal checkpoint format, which consists of a consolidated representation of each model parameter and metadata for mapping parameter fragments into training ranks of arbitrary model-parallelism configuration. Second, the universal checkpoint language, a simple but powerful specification language for converting distributed checkpoints into the universal checkpoint format. Our evaluation demonstrates the effectiveness and generality of Universal Checkpointing on state-of-the-art model architectures and a wide range of parallelism techniques."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ELCoRec: Enhance Language Understanding with Co-Propagation of Numerical and Categorical Features for Recommendation", "authors": "Jizheng Chen, Kounianhua Du, Jianghao Lin, Bo Chen, Ruiming Tang, Weinan Zhang", "subjects": "Subjects:\nInformation Retrieval (cs.IR)", "abstract": "Large language models have been flourishing in the natural language processing (NLP) domain, and their potential for recommendation has been paid much attention to. Despite the intelligence shown by the recommendation-oriented finetuned models, LLMs struggle to fully understand the user behavior patterns due to their innate weakness in interpreting numerical features and the overhead for long context, where the temporal relations among user behaviors, subtle quantitative signals among different ratings, and various side features of items are not well explored. Existing works only fine-tune a sole LLM on given text data without introducing that important information to it, leaving these problems unsolved. In this paper, we propose ELCoRec to Enhance Language understanding with CoPropagation of numerical and categorical features for Recommendation. Concretely, we propose to inject the preference understanding capability into LLM via a GAT expert model where the user preference is better encoded by parallelly propagating the temporal relations, and rating signals as well as various side information of historical items. The parallel propagation mechanism could stabilize heterogeneous features and offer an informative user preference encoding, which is then injected into the language models via soft prompting at the cost of a single token embedding. To further obtain the user's recent interests, we proposed a novel Recent interaction Augmented Prompt (RAP) template. Experiment results over three datasets against strong baselines validate the effectiveness of ELCoRec. The code is available at https://anonymous.4open.science/r/CIKM_Code_Repo-E6F5/README.md."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          OutlierTune: Efficient Channel-Wise Quantization for Large Language Models", "authors": "Jinguang Wang, Yuexi Yin, Haifeng Sun, Qi Qi, Jingyu Wang, Zirui Zhuang, Tingting Yang, Jianxin Liao", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Quantizing the activations of large language models (LLMs) has been a significant challenge due to the presence of structured outliers. Most existing methods focus on the per-token or per-tensor quantization of activations, making it difficult to achieve both accuracy and hardware efficiency. To address this problem, we propose OutlierTune, an efficient per-channel post-training quantization (PTQ) method for the activations of LLMs. OutlierTune consists of two components: pre-execution of dequantization and symmetrization. The pre-execution of dequantization updates the model weights by the activation scaling factors, avoiding the internal scaling and costly additional computational overheads brought by the per-channel activation quantization. The symmetrization further reduces the quantization differences arising from the weight updates by ensuring the balanced numerical ranges across different activation channels. OutlierTune is easy to implement and hardware-efficient, introducing almost no additional computational overheads during the inference. Extensive experiments show that the proposed framework outperforms existing methods across multiple different tasks. Demonstrating better generalization, this framework improves the Int6 quantization of the instruction-tuning LLMs, such as OPT-IML, to the same level as half-precision (FP16). Moreover, we have shown that the proposed framework is 1.48x faster than the FP16 implementation while reducing approximately 2x memory usage."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Quantum annealing-based structural optimization with a multiplicative design update", "authors": "Naruethep Sukulthanasorn, Junsen Xiao, Koya Wagatsuma, Shuji Moriguchi, Kenjiro Terada", "subjects": "Subjects:\nComputational Engineering, Finance, and Science (cs.CE); Numerical Analysis (math.NA); Quantum Physics (quant-ph)", "abstract": "This paper presents a new structural design framework, developed based on iterative optimization via quantum annealing (QA). The novelty lies in its successful design update using an unknown design multiplier obtained by iteratively solving the optimization problems with QA. In addition, to align with density-based approaches in structural optimization, multipliers are multiplicative to represent design material and serve as design variables. In particular, structural analysis is performed on a classical computer using the finite element method, and QA is utilized for topology updating. The primary objective of the framework is to minimize compliance under an inequality volume constraint, while an encoding process for the design variable is adopted, enabling smooth iterative updates to the optimized design. The proposed framework incorporates both penalty methods and slack variables to transform the inequality constraint into an equality constraint and is implemented in a quadratic unconstrained binary optimization (QUBO) model through QA. To demonstrate its performance, design optimization is performed for both truss and continuum structures. Promising results from these applications indicate that the proposed framework is capable of creating an optimal shape and topology similar to those benchmarked by the optimality criteria (OC) method on a classical computer."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Approximate Minimum Sum Colorings and Maximum $k$-Colorable Subgraphs of Chordal Graphs", "authors": "Ian DeHaan, Zachary Friggstad", "subjects": "Subjects:\nData Structures and Algorithms (cs.DS)", "abstract": "We give a $(1.796+\\epsilon)$-approximation for the minimum sum coloring problem on chordal graphs, improving over the previous 3.591-approximation by Gandhi et al. [2005]. To do so, we also design the first polynomial-time approximation scheme for the maximum $k$-colorable subgraph problem in chordal graphs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Zero-shot Composed Image Retrieval Considering Query-target Relationship Leveraging Masked Image-text Pairs", "authors": "Huaying Zhang, Rintaro Yanagi, Ren Togo, Takahiro Ogawa, Miki Haseyama", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR)", "abstract": "This paper proposes a novel zero-shot composed image retrieval (CIR) method considering the query-target relationship by masked image-text pairs. The objective of CIR is to retrieve the target image using a query image and a query text. Existing methods use a textual inversion network to convert the query image into a pseudo word to compose the image and text and use a pre-trained visual-language model to realize the retrieval. However, they do not consider the query-target relationship to train the textual inversion network to acquire information for retrieval. In this paper, we propose a novel zero-shot CIR method that is trained end-to-end using masked image-text pairs. By exploiting the abundant image-text pairs that are convenient to obtain with a masking strategy for learning the query-target relationship, it is expected that accurate zero-shot CIR using a retrieval-focused textual inversion network can be realized. Experimental results show the effectiveness of the proposed method."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Dense Monocular Motion Segmentation Using Optical Flow and Pseudo Depth Map: A Zero-Shot Approach", "authors": "Yuxiang Huang, Yuhao Chen, John Zelek", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "abstract": "Motion segmentation from a single moving camera presents a significant challenge in the field of computer vision. This challenge is compounded by the unknown camera movements and the lack of depth information of the scene. While deep learning has shown impressive capabilities in addressing these issues, supervised models require extensive training on massive annotated datasets, and unsupervised models also require training on large volumes of unannotated data, presenting significant barriers for both. In contrast, traditional methods based on optical flow do not require training data, however, they often fail to capture object-level information, leading to over-segmentation or under-segmentation. In addition, they also struggle in complex scenes with substantial depth variations and non-rigid motion, due to the overreliance of optical flow. To overcome these challenges, we propose an innovative hybrid approach that leverages the advantages of both deep learning methods and traditional optical flow based methods to perform dense motion segmentation without requiring any training. Our method initiates by automatically generating object proposals for each frame using foundation models. These proposals are then clustered into distinct motion groups using both optical flow and relative depth maps as motion cues. The integration of depth maps derived from state-of-the-art monocular depth estimation models significantly enhances the motion cues provided by optical flow, particularly in handling motion parallax issues. Our method is evaluated on the DAVIS-Moving and YTVOS-Moving datasets, and the results demonstrate that our method outperforms the best unsupervised method and closely matches with the state-of-theart supervised methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Disentangling Knowledge-based and Visual Reasoning by Question Decomposition in KB-VQA", "authors": "Elham J. Barezi, Parisa Kordjamshidi", "subjects": "Subjects:\nArtificial Intelligence (cs.AI)", "abstract": "We study the Knowledge-Based visual question-answering problem, for which given a question, the models need to ground it into the visual modality to find the answer. Although many recent works use question-dependent captioners to verbalize the given image and use Large Language Models to solve the VQA problem, the research results show they are not reasonably performing for multi-hop questions. Our study shows that replacing a complex question with several simpler questions helps to extract more relevant information from the image and provide a stronger comprehension of it. Moreover, we analyze the decomposed questions to find out the modality of the information that is required to answer them and use a captioner for the visual questions and LLMs as a general knowledge source for the non-visual KB-based questions. Our results demonstrate the positive impact of using simple questions before retrieving visual or non-visual information. We have provided results and analysis on three well-known VQA datasets including OKVQA, A-OKVQA, and KRVQA, and achieved up to 2% improvement in accuracy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Navigating LLM Ethics: Advancements, Challenges, and Future Directions", "authors": "Junfeng Jiao, Saleh Afroogh, Yiming Xu, Connor Phillips", "subjects": "Subjects:\nComputers and Society (cs.CY); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "This study addresses ethical issues surrounding Large Language Models (LLMs) within the field of artificial intelligence. It explores the common ethical challenges posed by both LLMs and other AI systems, such as privacy and fairness, as well as ethical challenges uniquely arising from LLMs. It highlights challenges such as hallucination, verifiable accountability, and decoding censorship complexity, which are unique to LLMs and distinct from those encountered in traditional AI systems. The study underscores the need to tackle these complexities to ensure accountability, reduce biases, and enhance transparency in the influential role that LLMs play in shaping information dissemination. It proposes mitigation strategies and future directions for LLM ethics, advocating for interdisciplinary collaboration. It recommends ethical frameworks tailored to specific domains and dynamic auditing systems adapted to diverse contexts. This roadmap aims to guide responsible development and integration of LLMs, envisioning a future where ethical considerations govern AI advancements in society."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The global landscape of academic guidelines for generative AI and Large Language Models", "authors": "Junfeng Jiao, Saleh Afroogh, Kevin Chen, David Atkinson, Amit Dhurandhar", "subjects": "Subjects:\nComputers and Society (cs.CY); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "The integration of Generative Artificial Intelligence (GAI) and Large Language Models (LLMs) in academia has spurred a global discourse on their potential pedagogical benefits and ethical considerations. Positive reactions highlight some potential, such as collaborative creativity, increased access to education, and empowerment of trainers and trainees. However, negative reactions raise concerns about ethical complexities, balancing innovation and academic integrity, unequal access, and misinformation risks. Through a systematic survey and text-mining-based analysis of global and national directives, insights from independent research, and eighty university-level guidelines, this study provides a nuanced understanding of the opportunities and challenges posed by GAI and LLMs in education. It emphasizes the importance of balanced approaches that harness the benefits of these technologies while addressing ethical considerations and ensuring equitable access and educational outcomes. The paper concludes with recommendations for fostering responsible innovation and ethical practices to guide the integration of GAI and LLMs in academia."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Revisiting Backdoor Attacks against Large Vision-Language Models", "authors": "Siyuan Liang, Jiawei Liang, Tianyu Pang, Chao Du, Aishan Liu, Ee-Chien Chang, Xiaochun Cao", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Instruction tuning enhances large vision-language models (LVLMs) but raises security risks through potential backdoor attacks due to their openness. Previous backdoor studies focus on enclosed scenarios with consistent training and testing instructions, neglecting the practical domain gaps that could affect attack effectiveness. This paper empirically examines the generalizability of backdoor attacks during the instruction tuning of LVLMs for the first time, revealing certain limitations of most backdoor strategies in practical scenarios. We quantitatively evaluate the generalizability of six typical backdoor attacks on image caption benchmarks across multiple LVLMs, considering both visual and textual domain offsets. Our findings indicate that attack generalizability is positively correlated with the backdoor trigger's irrelevance to specific images/models and the preferential correlation of the trigger pattern. Additionally, we modify existing backdoor attacks based on the above key observations, demonstrating significant improvements in cross-domain scenario generalizability (+86% attack success rate). Notably, even without access to the instruction datasets, a multimodal instruction set can be successfully poisoned with a very low poisoning rate (0.2%), achieving an attack success rate of over 97%. This paper underscores that even simple traditional backdoor strategies pose a serious threat to LVLMs, necessitating more attention and in-depth research."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Retain, Blend, and Exchange: A Quality-aware Spatial-Stereo Fusion Approach for Event Stream Recognition", "authors": "Lan Chen, Dong Li, Xiao Wang, Pengpeng Shao, Wei Zhang, Yaowei Wang, Yonghong Tian, Jin Tang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)", "abstract": "Existing event stream-based pattern recognition models usually represent the event stream as the point cloud, voxel, image, etc., and design various deep neural networks to learn their features. Although considerable results can be achieved in simple cases, however, the model performance may be limited by monotonous modality expressions, sub-optimal fusion, and readout mechanisms. In this paper, we propose a novel dual-stream framework for event stream-based pattern recognition via differentiated fusion, termed EFV++. It models two common event representations simultaneously, i.e., event images and event voxels. The spatial and three-dimensional stereo information can be learned separately by utilizing Transformer and Graph Neural Network (GNN). We believe the features of each representation still contain both efficient and redundant features and a sub-optimal solution may be obtained if we directly fuse them without differentiation. Thus, we divide each feature into three levels and retain high-quality features, blend medium-quality features, and exchange low-quality features. The enhanced dual features will be fed into the fusion Transformer together with bottleneck features. In addition, we introduce a novel hybrid interaction readout mechanism to enhance the diversity of features as final representations. Extensive experiments demonstrate that our proposed framework achieves state-of-the-art performance on multiple widely used event stream-based classification datasets. Specifically, we achieve new state-of-the-art performance on the Bullying10k dataset, i.e., $90.51\\%$, which exceeds the second place by $+2.21\\%$. The source code of this paper has been released on \\url{this https URL}."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AFBench: A Large-scale Benchmark for Airfoil Design", "authors": "Jian Liu, Jianyu Wu, Hairun Xie, Guoqing Zhang, Jing Wang, Wei Liu, Wanli Ouyang, Junjun Jiang, Xianming Liu, Shixiang Tang, Miao Zhang", "subjects": "Subjects:\nComputational Engineering, Finance, and Science (cs.CE)", "abstract": "Data-driven generative models have emerged as promising approaches towards achieving efficient mechanical inverse design. However, due to prohibitively high cost in time and money, there is still lack of open-source and large-scale benchmarks in this field. It is mainly the case for airfoil inverse design, which requires to generate and edit diverse geometric-qualified and aerodynamic-qualified airfoils following the multimodal instructions, \\emph{i.e.,} dragging points and physical parameters. This paper presents the open-source endeavors in airfoil inverse design, \\emph{AFBench}, including a large-scale dataset with 200 thousand airfoils and high-quality aerodynamic and geometric labels, two novel and practical airfoil inverse design tasks, \\emph{i.e.,} conditional generation on multimodal physical parameters, controllable editing, and comprehensive metrics to evaluate various existing airfoil inverse design methods. Our aim is to establish \\emph{AFBench} as an ecosystem for training and evaluating airfoil inverse design methods, with a specific focus on data-driven controllable inverse design models by multimodal instructions capable of bridging the gap between ideas and execution, the academic research and industrial applications. We have provided baseline models, comprehensive experimental observations, and analysis to accelerate future research. Our baseline model is trained on an RTX 3090 GPU within 16 hours. The codebase, datasets and benchmarks will be available at \\url{this https URL}."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Learning Retrieval Augmentation for Personalized Dialogue Generation", "authors": "Qiushi Huang, Shuai Fu, Xubo Liu, Wenwu Wang, Tom Ko, Yu Zhang, Lilian Tang", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Personalized dialogue generation, focusing on generating highly tailored responses by leveraging persona profiles and dialogue context, has gained significant attention in conversational AI applications. However, persona profiles, a prevalent setting in current personalized dialogue datasets, typically composed of merely four to five sentences, may not offer comprehensive descriptions of the persona about the agent, posing a challenge to generate truly personalized dialogues. To handle this problem, we propose $\\textbf{L}$earning Retrieval $\\textbf{A}$ugmentation for $\\textbf{P}$ersonalized $\\textbf{D}$ial$\\textbf{O}$gue $\\textbf{G}$eneration ($\\textbf{LAPDOG}$), which studies the potential of leveraging external knowledge for persona dialogue generation. Specifically, the proposed LAPDOG model consists of a story retriever and a dialogue generator. The story retriever uses a given persona profile as queries to retrieve relevant information from the story document, which serves as a supplementary context to augment the persona profile. The dialogue generator utilizes both the dialogue history and the augmented persona profile to generate personalized responses. For optimization, we adopt a joint training framework that collaboratively learns the story retriever and dialogue generator, where the story retriever is optimized towards desired ultimate metrics (e.g., BLEU) to retrieve content for the dialogue generator to generate personalized responses. Experiments conducted on the CONVAI2 dataset with ROCStory as a supplementary data source show that the proposed LAPDOG method substantially outperforms the baselines, indicating the effectiveness of the proposed method. The LAPDOG model code is publicly available for further exploration. this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Temporally Multi-Scale Sparse Self-Attention for Physical Activity Data Imputation", "authors": "Hui Wei, Maxwell A. Xu, Colin Samplawski, James M. Rehg, Santosh Kumar, Benjamin M. Marlin", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Wearable sensors enable health researchers to continuously collect data pertaining to the physiological state of individuals in real-world settings. However, such data can be subject to extensive missingness due to a complex combination of factors. In this work, we study the problem of imputation of missing step count data, one of the most ubiquitous forms of wearable sensor data. We construct a novel and large scale data set consisting of a training set with over 3 million hourly step count observations and a test set with over 2.5 million hourly step count observations. We propose a domain knowledge-informed sparse self-attention model for this task that captures the temporal multi-scale nature of step-count data. We assess the performance of the model relative to baselines and conduct ablation studies to verify our specific model designs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Dysca: A Dynamic and Scalable Benchmark for Evaluating Perception Ability of LVLMs", "authors": "Jie Zhang, Zhongqi Wang, Mengqi Lei, Zheng Yuan, Bei Yan, Shiguang Shan, Xilin Chen", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Currently many benchmarks have been proposed to evaluate the perception ability of the Large Vision-Language Models (LVLMs). However, most benchmarks conduct questions by selecting images from existing datasets, resulting in the potential data leakage. Besides, these benchmarks merely focus on evaluating LVLMs on the realistic style images and clean scenarios, leaving the multi-stylized images and noisy scenarios unexplored. In response to these challenges, we propose a dynamic and scalable benchmark named Dysca for evaluating LVLMs by leveraging synthesis images. Specifically, we leverage Stable Diffusion and design a rule-based method to dynamically generate novel images, questions and the corresponding answers. We consider 51 kinds of image styles and evaluate the perception capability in 20 subtasks. Moreover, we conduct evaluations under 4 scenarios (i.e., Clean, Corruption, Print Attacking and Adversarial Attacking) and 3 question types (i.e., Multi-choices, True-or-false and Free-form). Thanks to the generative paradigm, Dysca serves as a scalable benchmark for easily adding new subtasks and scenarios. A total of 8 advanced open-source LVLMs with 10 checkpoints are evaluated on Dysca, revealing the drawbacks of current LVLMs. The benchmark is released in \\url{this https URL}."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RAVE: A Framework for Radar Ego-Velocity Estimation", "authors": "Vlaho-Josip \u0160tironja, Luka Petrovi\u0107, Juraj Per\u0161i\u0107, Ivan Markovi\u0107, Ivan Petrovi\u0107", "subjects": "Subjects:\nRobotics (cs.RO)", "abstract": "State estimation is an essential component of autonomous systems, usually relying on sensor fusion that integrates data from cameras, LiDARs and IMUs. Recently, radars have shown the potential to improve the accuracy and robustness of state estimation and perception, especially in challenging environmental conditions such as adverse weather and low-light scenarios. In this paper, we present a framework for ego-velocity estimation, which we call RAVE, that relies on 3D automotive radar data and encompasses zero velocity detection, outlier rejection, and velocity estimation. In addition, we propose a simple filtering method to discard infeasible ego-velocity estimates. We also conduct a systematic analysis of how different existing outlier rejection techniques and optimization loss functions impact estimation accuracy. Our evaluation on three open-source datasets demonstrates the effectiveness of the proposed filter and a significant positive impact of RAVE on the odometry accuracy. Furthermore, we release an open-source implementation of the proposed framework for radar ego-velocity estimation accompanied with a ROS interface."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          LICO: Large Language Models for In-Context Molecular Optimization", "authors": "Tung Nguyen, Aditya Grover", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Chemical Physics (physics.chem-ph); Biomolecules (q-bio.BM); Quantitative Methods (q-bio.QM)", "abstract": "Optimizing black-box functions is a fundamental problem in science and engineering. To solve this problem, many approaches learn a surrogate function that estimates the underlying objective from limited historical evaluations. Large Language Models (LLMs), with their strong pattern-matching capabilities via pretraining on vast amounts of data, stand out as a potential candidate for surrogate modeling. However, directly prompting a pretrained language model to produce predictions is not feasible in many scientific domains due to the scarcity of domain-specific data in the pretraining corpora and the challenges of articulating complex problems in natural language. In this work, we introduce LICO, a general-purpose model that extends arbitrary base LLMs for black-box optimization, with a particular application to the molecular domain. To achieve this, we equip the language model with a separate embedding layer and prediction layer, and train the model to perform in-context predictions on a diverse set of functions defined over the domain. Once trained, LICO can generalize to unseen molecule properties simply via in-context prompting. LICO achieves state-of-the-art performance on PMO, a challenging molecular optimization benchmark comprising over 20 objective functions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Decoding-Time Language Model Alignment with Multiple Objectives", "authors": "Ruizhe Shi, Yifang Chen, Yushi Hu, ALisa Liu, Noah Smith, Hannaneh Hajishirzi, Simon Du", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Aligning language models (LMs) to human preferences has emerged as a critical pursuit, enabling these models to better serve diverse user needs. Existing methods primarily focus on optimizing LMs for a single reward function, limiting their adaptability to varied objectives. Here, we propose $\\textbf{multi-objective decoding (MOD)}$, a decoding-time algorithm that outputs the next token from a linear combination of predictions of all base models, for any given weightings over different objectives. We exploit a common form among a family of $f$-divergence regularized alignment approaches (such as PPO, DPO, and their variants) to identify a closed-form solution by Legendre transform, and derive an efficient decoding strategy. Theoretically, we show why existing approaches can be sub-optimal even in natural settings and obtain optimality guarantees for our method. Empirical results demonstrate the effectiveness of the algorithm. For example, compared to a parameter-merging baseline, MOD achieves 12.8% overall reward improvement when equally optimizing towards $3$ objectives. Moreover, we experiment with MOD on combining three fully-finetuned LLMs of different model sizes, each aimed at different objectives such as safety, coding, and general user preference. Unlike traditional methods that require careful curation of a mixture of datasets to achieve comprehensive improvement, we can quickly experiment with preference weightings using MOD to find the best combination of models. Our best combination reduces toxicity on Toxigen to nearly 0% and achieves 7.9--33.3% improvement across other three metrics ($\\textit{i.e.}$, Codex@1, GSM-COT, BBH-COT)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          What Is Missing In Homophily? Disentangling Graph Homophily For Graph Neural Networks", "authors": "Yilun Zheng, Sitao Luan, Lihui Chen", "subjects": "Subjects:\nMachine Learning (cs.LG); Social and Information Networks (cs.SI)", "abstract": "Graph homophily refers to the phenomenon that connected nodes tend to share similar characteristics. Understanding this concept and its related metrics is crucial for designing effective Graph Neural Networks (GNNs). The most widely used homophily metrics, such as edge or node homophily, quantify such \"similarity\" as label consistency across the graph topology. These metrics are believed to be able to reflect the performance of GNNs, especially on node-level tasks. However, many recent studies have empirically demonstrated that the performance of GNNs does not always align with homophily metrics, and how homophily influences GNNs still remains unclear and controversial. Then, a crucial question arises: What is missing in our current understanding of homophily? To figure out the missing part, in this paper, we disentangle the graph homophily into $3$ aspects: label, structural, and feature homophily, providing a more comprehensive understanding of GNN performance. To investigate their synergy, we propose a Contextual Stochastic Block Model with $3$ types of Homophily (CSBM-3H), where the topology and feature generation are controlled by the $3$ metrics. Based on the theoretical analysis of CSBM-3H, we derive a new composite metric, named Tri-Hom, that considers all $3$ aspects and overcomes the limitations of conventional homophily metrics. The theoretical conclusions and the effectiveness of Tri-Hom have been verified through synthetic experiments on CSBM-3H. In addition, we conduct experiments on $31$ real-world benchmark datasets and calculate the correlations between homophily metrics and model performance. Tri-Hom has significantly higher correlation values than $17$ existing metrics that only focus on a single homophily aspect, demonstrating its superiority and the importance of homophily synergy. Our code is available at \\url{this https URL}."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FFN: a Fine-grained Chinese-English Financial Domain Parallel Corpus", "authors": "Yuxin Fu, Shijing Si, Leyi Mai, Xi-ang Li", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)", "abstract": "Large Language Models (LLMs) have stunningly advanced the field of machine translation, though their effectiveness within the financial domain remains largely underexplored. To probe this issue, we constructed a fine-grained Chinese-English parallel corpus of financial news called FFN. We acquired financial news articles spanning between January 1st, 2014, to December 31, 2023, from mainstream media websites such as CNN, FOX, and China Daily. The dataset consists of 1,013 main text and 809 titles, all of which have been manually corrected. We measured the translation quality of two LLMs -- ChatGPT and ERNIE-bot, utilizing BLEU, TER and chrF scores as the evaluation metrics. For comparison, we also trained an OpenNMT model based on our dataset. We detail problems of LLMs and provide in-depth analysis, intending to stimulate further research and solutions in this largely uncharted territory. Our research underlines the need to optimize LLMs within the specific field of financial translation to ensure accuracy and quality."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Two-Pronged Human Evaluation of ChatGPT Self-Correction in Radiology Report Simplification", "authors": "Ziyu Yang, Santhosh Cherian, Slobodan Vucetic", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Radiology reports are highly technical documents aimed primarily at doctor-doctor communication. There has been an increasing interest in sharing those reports with patients, necessitating providing them patient-friendly simplifications of the original reports. This study explores the suitability of large language models in automatically generating those simplifications. We examine the usefulness of chain-of-thought and self-correction prompting mechanisms in this domain. We also propose a new evaluation protocol that employs radiologists and laypeople, where radiologists verify the factual correctness of simplifications, and laypeople assess simplicity and comprehension. Our experimental results demonstrate the effectiveness of self-correction prompting in producing high-quality simplifications. Our findings illuminate the preferences of radiologists and laypeople regarding text simplification, informing future research on this topic."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Thermo-Electro-Mechanical Model for Long-Term Reliability of Aging Transmission Lines", "authors": "Eduardo A. Barros De Moraes, Prakash KC, Mohsen Zayernouri", "subjects": "Subjects:\nSystems and Control (eess.SY); Numerical Analysis (math.NA)", "abstract": "Integrity and reliability of a national power grid system are essential to society's development and security. Among the power grid components, transmission lines are critical due to exposure and vulnerability to severe external conditions, including high winds, ice, and extreme temperatures. The combined effects of external agents with high electrical load and presence of damage precursors greatly affects the conducting material's properties due to a thermal runaway cycle that accelerates the aging process. In this paper, we develop a thermo-electro-mechanical model for long-term failure analysis of overhead transmission lines. A phase-field model of damage and fatigue, coupled with electrical and thermal modules, provides a detailed description of the conductor's temperature evolution. We define a limit state function based on maximum operating temperature to avoid excessive overheating and sagging. We study four representative scenarios deterministically, and propose the Probabilistic Collocation Method (PCM) as a tool to understand the stochastic behavior of the system. We use PCM in forward parametric uncertainty quantification, global sensitivity analysis, and computation of failure probability curves in a straightforward and computationally efficient fashion, and we quantify the most influential parameters that affect the failure predictability from a physics-based perspective."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Predicting the duration of traffic incidents for Sydney greater metropolitan area using machine learning methods", "authors": "Artur Grigorev, Sajjad Shafiei, Hanna Grzybowska, Adriana-Simona Mihaita", "subjects": "Subjects:\nMachine Learning (cs.LG); Computers and Society (cs.CY)", "abstract": "This research presents a comprehensive approach to predicting the duration of traffic incidents and classifying them as short-term or long-term across the Sydney Metropolitan Area. Leveraging a dataset that encompasses detailed records of traffic incidents, road network characteristics, and socio-economic indicators, we train and evaluate a variety of advanced machine learning models including Gradient Boosted Decision Trees (GBDT), Random Forest, LightGBM, and XGBoost. The models are assessed using Root Mean Square Error (RMSE) for regression tasks and F1 score for classification tasks. Our experimental results demonstrate that XGBoost and LightGBM outperform conventional models with XGBoost achieving the lowest RMSE of 33.7 for predicting incident duration and highest classification F1 score of 0.62 for a 30-minute duration threshold. For classification, the 30-minute threshold balances performance with 70.84\\% short-term duration classification accuracy and 62.72\\% long-term duration classification accuracy. Feature importance analysis, employing both tree split counts and SHAP values, identifies the number of affected lanes, traffic volume, and types of primary and secondary vehicles as the most influential features. The proposed methodology not only achieves high predictive accuracy but also provides stakeholders with vital insights into factors contributing to incident durations. These insights enable more informed decision-making for traffic management and response strategies. The code is available by the link: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Streaming Decoder-Only Automatic Speech Recognition with Discrete Speech Units: A Pilot Study", "authors": "Peikun Chen, Sining Sun, Changhao Shan, Qing Yang, Lei Xie", "subjects": "Subjects:\nSound (cs.SD); Audio and Speech Processing (eess.AS)", "abstract": "Unified speech-text models like SpeechGPT, VioLA, and AudioPaLM have shown impressive performance across various speech-related tasks, especially in Automatic Speech Recognition (ASR). These models typically adopt a unified method to model discrete speech and text tokens, followed by training a decoder-only transformer. However, they are all designed for non-streaming ASR tasks, where the entire speech utterance is needed during decoding. Hence, we introduce a decoder-only model exclusively designed for streaming recognition, incorporating a dedicated boundary token to facilitate streaming recognition and employing causal attention masking during the training phase. Furthermore, we introduce right-chunk attention and various data augmentation techniques to improve the model's contextual modeling abilities. While achieving streaming speech recognition, experiments on the AISHELL-1 and -2 datasets demonstrate the competitive performance of our streaming approach with non-streaming decoder-only counterparts."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Learning Modality Knowledge Alignment for Cross-Modality Transfer", "authors": "Wenxuan Ma, Shuang Li, Lincan Cai, Jingxuan Kang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Cross-modality transfer aims to leverage large pretrained models to complete tasks that may not belong to the modality of pretraining data. Existing works achieve certain success in extending classical finetuning to cross-modal scenarios, yet we still lack understanding about the influence of modality gap on the transfer. In this work, a series of experiments focusing on the source representation quality during transfer are conducted, revealing the connection between larger modality gap and lesser knowledge reuse which means ineffective transfer. We then formalize the gap as the knowledge misalignment between modalities using conditional distribution P(Y|X). Towards this problem, we present Modality kNowledge Alignment (MoNA), a meta-learning approach that learns target data transformation to reduce the modality knowledge discrepancy ahead of the transfer. Experiments show that out method enables better reuse of source modality knowledge in cross-modality transfer, which leads to improvements upon existing finetuning methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          From Biased Selective Labels to Pseudo-Labels: An Expectation-Maximization Framework for Learning from Biased Decisions", "authors": "Trenton Chang, Jenna Wiens", "subjects": "Subjects:\nMachine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "Selective labels occur when label observations are subject to a decision-making process; e.g., diagnoses that depend on the administration of laboratory tests. We study a clinically-inspired selective label problem called disparate censorship, where labeling biases vary across subgroups and unlabeled individuals are imputed as \"negative\" (i.e., no diagnostic test = no illness). Machine learning models naively trained on such labels could amplify labeling bias. Inspired by causal models of selective labels, we propose Disparate Censorship Expectation-Maximization (DCEM), an algorithm for learning in the presence of disparate censorship. We theoretically analyze how DCEM mitigates the effects of disparate censorship on model performance. We validate DCEM on synthetic data, showing that it improves bias mitigation (area between ROC curves) without sacrificing discriminative performance (AUC) compared to baselines. We achieve similar results in a sepsis classification task using clinical data."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Advancing Cross-domain Discriminability in Continual Learning of Vison-Language Models", "authors": "Yicheng Xu, Yuxin Chen, Jiahao Nie, Yusong Wang, Huiping Zhuang, Manabu Okumura", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Continual learning (CL) with Vision-Language Models (VLMs) has overcome the constraints of traditional CL, which only focuses on previously encountered classes. During the CL of VLMs, we need not only to prevent the catastrophic forgetting on incrementally learned knowledge but also to preserve the zero-shot ability of VLMs. However, existing methods require additional reference datasets to maintain such zero-shot ability and rely on domain-identity hints to classify images across different domains. In this study, we propose Regression-based Analytic Incremental Learning (RAIL), which utilizes a recursive ridge regression-based adapter to learn from a sequence of domains in a non-forgetting manner and decouple the cross-domain correlations by projecting features to a higher-dimensional space. Cooperating with a training-free fusion module, RAIL absolutely preserves the VLM's zero-shot ability on unseen domains without any reference data. Additionally, we introduce Cross-domain Task-Agnostic Incremental Learning (X-TAIL) setting. In this setting, a CL learner is required to incrementally learn from multiple domains and classify test images from both seen and unseen domains without any domain-identity hint. We theoretically prove RAIL's absolute memorization on incrementally learned domains. Experiment results affirm RAIL's state-of-the-art performance in both X-TAIL and existing Multi-domain Task-Incremental Learning settings. The code will be released upon acceptance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Efficacy of Language Model Self-Play in Non-Zero-Sum Games", "authors": "Austen Liao, Nicholas Tomlin, Dan Klein", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Game-playing agents like AlphaGo have achieved superhuman performance through self-play, which is theoretically guaranteed to yield optimal policies in competitive games. However, most language tasks are partially or fully cooperative, so it is an open question whether techniques like self-play can effectively be used to improve language models. We empirically investigate this question in a negotiation game setting known as Deal or No Deal (DoND). Crucially, the objective in DoND can be modified to produce a fully cooperative game, a strictly competitive one, or anything in between. We finetune language models in self-play over multiple rounds of filtered behavior cloning in DoND for each of these objectives. Contrary to expectations, we find that language model self-play leads to significant performance gains in both cooperation and competition with humans, suggesting that self-play and related techniques have promise despite a lack of theoretical guarantees."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          LayoutCopilot: An LLM-powered Multi-agent Collaborative Framework for Interactive Analog Layout Design", "authors": "Bingyang Liu, Haoyi Zhang, Xiaohan Gao, Zichen Kong, Xiyuan Tang, Yibo Lin, Runsheng Wang, Ru Huang", "subjects": "Subjects:\nHardware Architecture (cs.AR)", "abstract": "Analog layout design heavily involves interactive processes between humans and design tools. The tools are usually designed to use scripting commands or visualized buttons for manipulation, especially for those interactive automation functionalities, which have a steep learning curve and cumbersome user experience, making a notable barrier to their adoption by designers. Aiming to address such a usability issue, this paper introduces LayoutCopilot, a pioneering multi-agent collaborative framework powered by Large Language Models (LLMs) for interactive analog layout design. LayoutCopilot simplifies human-tool interaction by converting natural language instructions into executable script commands, and it interprets high-level design intents into actionable suggestions, significantly streamlining the design process. Experimental results demonstrate the flexibility, efficiency, and accessibility of LayoutCopilot in handling real-world analog designs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models", "authors": "Vipul Rathore, Aniruddha Deb, Ankish Chandresh, Parag Singla, Mausam", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Recently, very large language models (LLMs) have shown exceptional performance on several English NLP tasks with just in-context learning (ICL), but their utility in other languages is still underexplored. We investigate their effectiveness for NLP tasks in low-resource languages (LRLs), especially in the setting of zero-labelled cross-lingual transfer (0-CLT), where no labelled training data for the target language is available -- however training data from one or more related medium-resource languages (MRLs) is utilized, alongside the available unlabeled test data for a target language. We introduce Self-Supervised Prompting (SSP), a novel ICL approach tailored for the 0-CLT setting. SSP is based on the key observation that LLMs output more accurate labels if in-context exemplars are from the target language (even if their labels are slightly noisy). To operationalize this, since target language training data is not available in 0-CLT, SSP operates in two stages. In Stage I, using source MRL training data, target language's test data is noisily labeled. In Stage II, these noisy test data points are used as exemplars in ICL for further improved labelling. Additionally, our implementation of SSP uses a novel Integer Linear Programming (ILP)-based exemplar selection that balances similarity, prediction confidence (when available) and label coverage. Experiments on three tasks and eleven LRLs (from three regions) demonstrate that SSP strongly outperforms existing SOTA fine-tuned and prompting-based baselines in 0-CLT setup."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Sequential three-way group decision-making for double hierarchy hesitant fuzzy linguistic term set", "authors": "Nanfang Luo, Qinghua Zhang, Qin Xie, Yutai Wang, Longjun Yin, Guoyin Wang", "subjects": "Subjects:\nArtificial Intelligence (cs.AI)", "abstract": "Group decision-making (GDM) characterized by complexity and uncertainty is an essential part of various life scenarios. Most existing researches lack tools to fuse information quickly and interpret decision results for partially formed decisions. This limitation is particularly noticeable when there is a need to improve the efficiency of GDM. To address this issue, a novel multi-level sequential three-way decision for group decision-making (S3W-GDM) method is constructed from the perspective of granular computing. This method simultaneously considers the vagueness, hesitation, and variation of GDM problems under double hierarchy hesitant fuzzy linguistic term sets (DHHFLTS) environment. First, for fusing information efficiently, a novel multi-level expert information fusion method is proposed, and the concepts of expert decision table and the extraction/aggregation of decision-leveled information based on the multi-level granularity are defined. Second, the neighborhood theory, outranking relation and regret theory (RT) are utilized to redesign the calculations of conditional probability and relative loss function. Then, the granular structure of DHHFLTS based on the sequential three-way decision (S3WD) is defined to improve the decision-making efficiency, and the decision-making strategy and interpretation of each decision-level are proposed. Furthermore, the algorithm of S3W-GDM is given. Finally, an illustrative example of diagnosis is presented, and the comparative and sensitivity analysis with other methods are performed to verify the efficiency and rationality of the proposed method."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          LearnedKV: Integrating LSM and Learned Index for Superior Performance on SSD", "authors": "Wenlong Wang, David Hung-Chang Du", "subjects": "Subjects:\nDatabases (cs.DB); Machine Learning (cs.LG)", "abstract": "In this paper, we introduce LearnedKV, a novel tiered key-value (KV) store that seamlessly integrates a Log-Structured Merge (LSM) tree with a Learned Index. This integration yields superior read and write performance compared to standalone indexing structures on SSDs. Our design capitalizes on the LSM tree's high write/update throughput and the Learned Index's fast read capabilities, enabling each component to leverage its strengths. We analyze the impact of size on LSM tree performance and demonstrate how the tiered Learned Index significantly mitigates the LSM tree's size-related performance degradation, particularly by reducing the intensive I/O operations resulting from re-insertions after Garbage Collection (GC). To maintain rapid read performance for newly inserted keys, we introduce a non-blocking conversion mechanism that efficiently transforms the existing LSM tree into a new Learned Index with minimal overhead during GC. Our experimental results, conducted across diverse workloads, show that LearnedKV outperforms state-of-the-art solutions by up to 1.32x in read requests and 1.31x in write performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AlignIT: Enhancing Prompt Alignment in Customization of Text-to-Image Models", "authors": "Aishwarya Agarwal, Srikrishna Karanam, Balaji Vasan Srinivasan", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "We consider the problem of customizing text-to-image diffusion models with user-supplied reference images. Given new prompts, the existing methods can capture the key concept from the reference images but fail to align the generated image with the prompt. In this work, we seek to address this key issue by proposing new methods that can easily be used in conjunction with existing customization methods that optimize the embeddings/weights at various intermediate stages of the text encoding process. The first contribution of this paper is a dissection of the various stages of the text encoding process leading up to the conditioning vector for text-to-image models. We take a holistic view of existing customization methods and notice that key and value outputs from this process differs substantially from their corresponding baseline (non-customized) models (e.g., baseline stable diffusion). While this difference does not impact the concept being customized, it leads to other parts of the generated image not being aligned with the prompt (see first row in Fig 1). Further, we also observe that these keys and values allow independent control various aspects of the final generation, enabling semantic manipulation of the output. Taken together, the features spanning these keys and values, serve as the basis for our next contribution where we fix the aforementioned issues with existing methods. We propose a new post-processing algorithm, \\textbf{AlignIT}, that infuses the keys and values for the concept of interest while ensuring the keys and values for all other tokens in the input prompt are unchanged. Our proposed method can be plugged in directly to existing customization methods, leading to a substantial performance improvement in the alignment of the final result with the input prompt while retaining the customization quality."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Assessing the Effectiveness of LLMs in Android Application Vulnerability Analysis", "authors": "Vasileios Kouliaridis, Georgios Karopoulos, Georgios Kambourakis", "subjects": "Subjects:\nCryptography and Security (cs.CR)", "abstract": "The increasing frequency of attacks on Android applications coupled with the recent popularity of large language models (LLMs) necessitates a comprehensive understanding of the capabilities of the latter in identifying potential vulnerabilities, which is key to mitigate the overall risk. To this end, the work at hand compares the ability of nine state-of-the-art LLMs to detect Android code vulnerabilities listed in the latest Open Worldwide Application Security Project (OWASP) Mobile Top 10. Each LLM was evaluated against an open dataset of over 100 vulnerable code samples, including obfuscated ones, assessing each model's ability to identify key vulnerabilities. Our analysis reveals the strengths and weaknesses of each LLM, identifying important factors that contribute to their performance. Additionally, we offer insights into context augmentation with retrieval-augmented generation (RAG) for detecting Android code vulnerabilities, which in turn may propel secure application development. Finally, while the reported findings regarding code vulnerability analysis show promise, they also reveal significant discrepancies among the different LLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Can we teach language models to gloss endangered languages?", "authors": "Michael Ginn, Mans Hulden, Alexis Palmer", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Interlinear glossed text (IGT) is a popular format in language documentation projects, where each morpheme is labeled with a descriptive annotation. Automating the creation of interlinear glossed text can be desirable to reduce annotator effort and maintain consistency across annotated corpora. Prior research has explored a number of statistical and neural methods for automatically producing IGT. As large language models (LLMs) have showed promising results across multilingual tasks, even for rare, endangered languages, it is natural to wonder whether they can be utilized for the task of generating IGT. We explore whether LLMs can be effective at the task of interlinear glossing with in-context learning, without any traditional training. We propose new approaches for selecting examples to provide in-context, observing that targeted selection can significantly improve performance. We find that LLM-based methods beat standard transformer baselines, despite requiring no training at all. These approaches still underperform state-of-the-art supervised systems for the task, but are highly practical for researchers outside of the NLP community, requiring minimal effort to use."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          360 in the Wild: Dataset for Depth Prediction and View Synthesis", "authors": "Kibaek Park, Francois Rameau, Jaesik Park, In So Kweon", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "The large abundance of perspective camera datasets facilitated the emergence of novel learning-based strategies for various tasks, such as camera localization, single image depth estimation, or view synthesis. However, panoramic or omnidirectional image datasets, including essential information, such as pose and depth, are mostly made with synthetic scenes. In this work, we introduce a large scale 360$^{\\circ}$ videos dataset in the wild. This dataset has been carefully scraped from the Internet and has been captured from various locations worldwide. Hence, this dataset exhibits very diversified environments (e.g., indoor and outdoor) and contexts (e.g., with and without moving objects). Each of the 25K images constituting our dataset is provided with its respective camera's pose and depth map. We illustrate the relevance of our dataset for two main tasks, namely, single image depth estimation and view synthesis."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Autonomous Control of a Novel Closed Chain Five Bar Active Suspension via Deep Reinforcement Learning", "authors": "Nishesh Singh, Sidharth Ramesh, Abhishek Shankar, Jyotishka Duttagupta, Leander Stephen D'Souza, Sanjay Singh", "subjects": "Subjects:\nRobotics (cs.RO); Artificial Intelligence (cs.AI)", "abstract": "Planetary exploration requires traversal in environments with rugged terrains. In addition, Mars rovers and other planetary exploration robots often carry sensitive scientific experiments and components onboard, which must be protected from mechanical harm. This paper deals with an active suspension system focused on chassis stabilisation and an efficient traversal method while encountering unavoidable obstacles. Soft Actor-Critic (SAC) was applied along with Proportional Integral Derivative (PID) control to stabilise the chassis and traverse large obstacles at low speeds. The model uses the rover's distance from surrounding obstacles, the height of the obstacle, and the chassis' orientation to actuate the control links of the suspension accurately. Simulations carried out in the Gazebo environment are used to validate the proposed active system."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Rise of Artificial Intelligence in Educational Measurement: Opportunities and Ethical Challenges", "authors": "Okan Bulut, Maggie Beiting-Parrish, Jodi M. Casabianca, Sharon C. Slater, Hong Jiao, Dan Song, Christopher M. Ormerod, Deborah Gbemisola Fabiyi, Rodica Ivan, Cole Walsh, Oscar Rios, Joshua Wilson, Seyma N. Yildirim-Erbasli, Tarid Wongvorachan, Joyce Xinle Liu, Bin Tan, Polina Morilova", "subjects": "Subjects:\nComputers and Society (cs.CY); Artificial Intelligence (cs.AI)", "abstract": "The integration of artificial intelligence (AI) in educational measurement has revolutionized assessment methods, enabling automated scoring, rapid content analysis, and personalized feedback through machine learning and natural language processing. These advancements provide timely, consistent feedback and valuable insights into student performance, thereby enhancing the assessment experience. However, the deployment of AI in education also raises significant ethical concerns regarding validity, reliability, transparency, fairness, and equity. Issues such as algorithmic bias and the opacity of AI decision-making processes pose risks of perpetuating inequalities and affecting assessment outcomes. Responding to these concerns, various stakeholders, including educators, policymakers, and organizations, have developed guidelines to ensure ethical AI use in education. The National Council of Measurement in Education's Special Interest Group on AI in Measurement and Education (AIME) also focuses on establishing ethical standards and advancing research in this area. In this paper, a diverse group of AIME members examines the ethical implications of AI-powered tools in educational measurement, explores significant challenges such as automation bias and environmental impact, and proposes solutions to ensure AI's responsible and effective use in education."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Autoencoder based approach for the mitigation of spurious correlations", "authors": "Srinitish Srinivasan, Karthik Seemakurthy", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Deep neural networks (DNNs) have exhibited remarkable performance across various tasks, yet their susceptibility to spurious correlations poses a significant challenge for out-of-distribution (OOD) generalization. Spurious correlations refer to erroneous associations in data that do not reflect true underlying relationships but are instead artifacts of dataset characteristics or biases. These correlations can lead DNNs to learn patterns that are not robust across diverse datasets or real-world scenarios, hampering their ability to generalize beyond training data. In this paper, we propose an autoencoder-based approach to analyze the nature of spurious correlations that exist in the Global Wheat Head Detection (GWHD) 2021 dataset. We then use inpainting followed by Weighted Boxes Fusion (WBF) to achieve a 2% increase in the Average Domain Accuracy (ADA) over the YOLOv5 baseline and consistently show that our approach has the ability to suppress some of the spurious correlations in the GWHD 2021 dataset. The key advantage of our approach is that it is more suitable in scenarios where there is limited scope to adapt or fine-tune the trained model in unseen test environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets", "authors": "Melanie Walsh, Anna Preus, Maria Antoniak", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Large language models (LLMs) can now generate and recognize text in a wide range of styles and genres, including highly specialized, creative genres like poetry. But what do LLMs really know about poetry? What can they know about poetry? We develop a task to evaluate how well LLMs recognize a specific aspect of poetry, poetic form, for more than 20 forms and formal elements in the English language. Poetic form captures many different poetic features, including rhyme scheme, meter, and word or line repetition. We use this task to reflect on LLMs' current poetic capabilities, as well as the challenges and pitfalls of creating NLP benchmarks for poetry and for other creative tasks. In particular, we use this task to audit and reflect on the poems included in popular pretraining datasets. Our findings have implications for NLP researchers interested in model evaluation, digital humanities and cultural analytics scholars, and cultural heritage professionals."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Historia Magistra Vitae: Dynamic Topic Modeling of Roman Literature using Neural Embeddings", "authors": "Michael Ginn, Mans Hulden", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Dynamic topic models have been proposed as a tool for historical analysis, but traditional approaches have had limited usefulness, being difficult to configure, interpret, and evaluate. In this work, we experiment with a recent approach for dynamic topic modeling using BERT embeddings. We compare topic models built using traditional statistical models (LDA and NMF) and the BERT-based model, modeling topics over the entire surviving corpus of Roman literature. We find that while quantitative metrics prefer statistical models, qualitative evaluation finds better insights from the neural model. Furthermore, the neural topic model is less sensitive to hyperparameter configuration and thus may make dynamic topic modeling more viable for historical researchers."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Universal Railway Obstacle Detection System based on Semi-supervised Segmentation And Optical Flow", "authors": "Qiushi Guo", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Detecting obstacles in railway scenarios is both crucial and challenging due to the wide range of obstacle categories and varying ambient conditions such as weather and light. Given the impossibility of encompassing all obstacle categories during the training stage, we address this out-of-distribution (OOD) issue with a semi-supervised segmentation approach guided by optical flow clues. We reformulate the task as a binary segmentation problem instead of the traditional object detection approach. To mitigate data shortages, we generate highly realistic synthetic images using Segment Anything (SAM) and YOLO, eliminating the need for manual annotation to produce abundant pixel-level annotations. Additionally, we leverage optical flow as prior knowledge to train the model effectively. Several experiments are conducted, demonstrating the feasibility and effectiveness of our approach."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Factor-Conditioned Speaking-Style Captioning", "authors": "Atsushi Ando, Takafumi Moriya, Shota Horiguchi, Ryo Masumura", "subjects": "Subjects:\nComputation and Language (cs.CL); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "abstract": "This paper presents a novel speaking-style captioning method that generates diverse descriptions while accurately predicting speaking-style information. Conventional learning criteria directly use original captions that contain not only speaking-style factor terms but also syntax words, which disturbs learning speaking-style information. To solve this problem, we introduce factor-conditioned captioning (FCC), which first outputs a phrase representing speaking-style factors (e.g., gender, pitch, etc.), and then generates a caption to ensure the model explicitly learns speaking-style factors. We also propose greedy-then-sampling (GtS) decoding, which first predicts speaking-style factors deterministically to guarantee semantic accuracy, and then generates a caption based on factor-conditioned sampling to ensure diversity. Experiments show that FCC outperforms the original caption-based training, and with GtS, it generates more diverse captions while keeping style prediction performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Verification and Synthesis of Compatible Control Lyapunov and Control Barrier Functions", "authors": "Hongkai Dai, Chuanrui Jiang, Hongchao Zhang, Andrew Clark", "subjects": "Subjects:\nSystems and Control (eess.SY); Robotics (cs.RO)", "abstract": "Safety and stability are essential properties of control systems. Control Barrier Functions (CBFs) and Control Lyapunov Functions (CLFs) have been proposed to ensure safety and stability respectively. However, previous approaches typically verify and synthesize the CBFs and CLFs separately, satisfying their respective constraints, without proving that the CBFs and CLFs are compatible with each other, namely at every state, there exists control actions that satisfy both the CBF and CLF constraints simultaneously. There exists some recent works that synthesized compatible CLF and CBF, but relying on nominal polynomial or rational controllers, which is just a sufficient but not necessary condition for compatibility. In this work, we investigate verification and synthesis of compatible CBF and CLF independent from any nominal controllers. We derive exact necessary and sufficient conditions for compatibility, and further formulate Sum-Of-Squares program for the compatibility verification. Based on our verification framework, we also design an alternating nominal-controller-free synthesis method. We evaluate our method in a linear toy, a non-linear toy, and a power converter example."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Manipulate-Anything: Automating Real-World Robots using Vision-Language Models", "authors": "Jiafei Duan, Wentao Yuan, Wilbert Pumacay, Yi Ru Wang, Kiana Ehsani, Dieter Fox, Ranjay Krishna", "subjects": "Subjects:\nRobotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Large-scale endeavors like RT-1 and widespread community efforts such as Open-X-Embodiment have contributed to growing the scale of robot demonstration data. However, there is still an opportunity to improve the quality, quantity, and diversity of robot demonstration data. Although vision-language models have been shown to automatically generate demonstration data, their utility has been limited to environments with privileged state information, they require hand-designed skills, and are limited to interactions with few object instances. We propose Manipulate-Anything, a scalable automated generation method for real-world robotic manipulation. Unlike prior work, our method can operate in real-world environments without any privileged state information, hand-designed skills, and can manipulate any static object. We evaluate our method using two setups. First, Manipulate-Anything successfully generates trajectories for all 5 real-world and 12 simulation tasks, significantly outperforming existing methods like VoxPoser. Second, Manipulate-Anything's demonstrations can train more robust behavior cloning policies than training with human demonstrations, or from data generated by VoxPoser and Code-As-Policies. We believe \\methodLong\\ can be the scalable method for both generating data for robotics and solving novel tasks in a zero-shot setting."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          TrustUQA: A Trustful Framework for Unified Structured Data Question Answering", "authors": "Wen Zhang, Long Jin, Yushan Zhu, Jiaoyan Chen, Zhiwei Huang, Junjie Wang, Yin Hua, Lei Liang, Huajun Chen", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Natural language question answering (QA) over structured data sources such as tables and knowledge graphs (KGs) have been widely investigated, for example with Large Language Models (LLMs). The main solutions include question to formal query parsing and retrieval-based answer generation. However, current methods of the former often suffer from weak generalization, failing to dealing with multiple sources simultaneously, while the later is limited in trustfulness. In this paper, we propose UnifiedTQA, a trustful QA framework that can simultaneously support multiple types of structured data in a unified way. To this end, it adopts an LLM-friendly and unified knowledge representation method called Condition Graph (CG), and uses an LLM and demonstration-based two-level method for CG querying. For enhancement, it is also equipped with dynamic demonstration retrieval. We have evaluated UnifiedTQA with 5 benchmarks covering 3 types of structured data. It outperforms 2 existing unified structured data QA methods and in comparison with the baselines that are specific to a data type, it achieves state-of-the-art on 2 of them. Further more, we demonstrates potential of our method for more general QA tasks, QA over mixed structured data and QA across structured data."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Regular Expressions with Backreferences on Multiple Context-Free Languages, and the Closed-Star Condition", "authors": "Taisei Nogami, Tachio Terauchi", "subjects": "Subjects:\nFormal Languages and Automata Theory (cs.FL)", "abstract": "Backreference is a well-known practical extension of regular expressions and most modern programming languages, such as Java, Python, JavaScript and more, support regular expressions with backreferences (rewb) in their standard libraries for string processing. A difficulty of backreference is non-regularity: unlike some other extensions, backreference strictly enhances the expressive power of regular expressions and thus rewbs can describe non-regular (in fact, even non-context-free) languages. In this paper, we investigate the expressive power of rewbs by comparing rewbs to multiple context-free languages (MCFL) and parallel multiple context-free languages (PMCFL). First, we prove that the language class of rewbs is a proper subclass of unary-PMCFLs. The class of unary-PMCFLs coincides with that of EDT0L languages, and our result strictly improves the known upper bound of rewbs. Additionally, we show that, however, the language class of rewbs is not contained in that of MCFLs even when restricted to rewbs with only one capturing group and no captured references. Therefore, in general, the parallelism seems essential for rewbs. Backed by these results, we define a novel syntactic condition on rewbs that we call closed-star and observe that it provides an upper bound on the number of times a rewb references the same captured string. The closed-star condition allows dispensing with the parallelism: that is, we prove that the language class of closed-star rewbs falls inside the class of unary-MCFLs, which is equivalent to that of EDT0L systems of finite index. Furthermore, as additional evidence for the robustness of the condition, we show that the language class of closed-star rewbs also falls inside the class of nonerasing stack languages (NESL)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data", "authors": "Yiting Ran, Xintao Wang, Rui Xu, Xinfeng Yuan, Jiaqing Liang, Yanghua Xiao, Deqing Yang", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Role-playing agents (RPA) have been a popular application area for large language models (LLMs), attracting significant interest from both industry and academia.While existing RPAs well portray the characters' knowledge and tones, they face challenges in capturing their minds, especially for small role-playing language models (RPLMs). In this paper, we propose to enhance RPLMs via personality-indicative data. Specifically, we leverage questions from psychological scales and distill advanced RPAs to generate dialogues that grasp the minds of characters. Experimental results validate that RPLMs trained with our dataset exhibit advanced role-playing capabilities for both general and personality-related evaluations. Code and data are available at \\href{this https URL}{this URL}."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Time Matters: Scaling Laws for Any Budget", "authors": "Itay Inbar, Luke Sernau", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "A primary cost driver for training large models is wall-clock training time. We show that popular time estimates based on FLOPs are poor estimates, and construct a more accurate proxy based on memory copies. We show that with some simple accounting, we can estimate the training speed of a transformer model from its hyperparameters. Combined with a scaling law curve like Chinchilla, this lets us estimate the final loss of the model. We fit our estimate to real data with a linear regression, and apply the result to rewrite Chinchilla in terms of a model's estimated training time as opposed to the amount of training data. This gives an expression for the loss in terms of the model's hyperparameters alone. We show that this expression is accurate across a wide range of model hyperparameter values, enabling us to analytically make architectural decisions and train models more efficiently."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Learning Pareto Set for Multi-Objective Continuous Robot Control", "authors": "Tianye Shu, Ke Shang, Cheng Gong, Yang Nan, Hisao Ishibuchi", "subjects": "Subjects:\nArtificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)", "abstract": "For a control problem with multiple conflicting objectives, there exists a set of Pareto-optimal policies called the Pareto set instead of a single optimal policy. When a multi-objective control problem is continuous and complex, traditional multi-objective reinforcement learning (MORL) algorithms search for many Pareto-optimal deep policies to approximate the Pareto set, which is quite resource-consuming. In this paper, we propose a simple and resource-efficient MORL algorithm that learns a continuous representation of the Pareto set in a high-dimensional policy parameter space using a single hypernet. The learned hypernet can directly generate various well-trained policy networks for different user preferences. We compare our method with two state-of-the-art MORL algorithms on seven multi-objective continuous robot control problems. Experimental results show that our method achieves the best overall performance with the least training parameters. An interesting observation is that the Pareto set is well approximated by a curved line or surface in a high-dimensional parameter space. This observation will provide insight for researchers to design new MORL algorithms."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Selective Vision is the Challenge for Visual Reasoning: A Benchmark for Visual Argument Understanding", "authors": "Jiwan Chung, Sungjae Lee, Minseo Kim, Seungju Han, Ashkan Yousefpour, Jack Hessel, Youngjae Yu", "subjects": "Subjects:\nComputation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Visual arguments, often used in advertising or social causes, rely on images to persuade viewers to do or believe something. Understanding these arguments requires selective vision: only specific visual stimuli within an image are relevant to the argument, and relevance can only be understood within the context of a broader argumentative structure. While visual arguments are readily appreciated by human audiences, we ask: are today's AI capable of similar understanding? We collect and release VisArgs, an annotated corpus designed to make explicit the (usually implicit) structures underlying visual arguments. VisArgs includes 1,611 images accompanied by three types of textual annotations: 5,112 visual premises (with region annotations), 5,574 commonsense premises, and reasoning trees connecting them to a broader argument. We propose three tasks over VisArgs to probe machine capacity for visual argument understanding: localization of premises, identification of premises, and deduction of conclusions. Experiments demonstrate that 1) machines cannot fully identify the relevant visual cues. The top-performing model, GPT-4-O, achieved an accuracy of only 78.5%, whereas humans reached 98.0%. All models showed a performance drop, with an average decrease in accuracy of 19.5%, when the comparison set was changed from objects outside the image to irrelevant objects within the image. Furthermore, 2) this limitation is the greatest factor impacting their performance in understanding visual arguments. Most models improved the most when given relevant visual premises as additional inputs, compared to other inputs, for deducing the conclusion of the visual argument."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fine-tuned network relies on generic representation to solve unseen cognitive task", "authors": "Dongyan Lin", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Fine-tuning pretrained language models has shown promising results on a wide range of tasks, but when encountering a novel task, do they rely more on generic pretrained representation, or develop brand new task-specific solutions? Here, we fine-tuned GPT-2 on a context-dependent decision-making task, novel to the model but adapted from neuroscience literature. We compared its performance and internal mechanisms to a version of GPT-2 trained from scratch on the same task. Our results show that fine-tuned models depend heavily on pretrained representations, particularly in later layers, while models trained from scratch develop different, more task-specific mechanisms. These findings highlight the advantages and limitations of pretraining for task generalization and underscore the need for further investigation into the mechanisms underpinning task-specific fine-tuning in LLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RoFIR: Robust Fisheye Image Rectification Framework Impervious to Optical Center Deviation", "authors": "Zhaokang Liao, Hao Feng, Shaokai Liu, Wengang Zhou, Houqiang Li", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Fisheye images are categorized fisheye into central and deviated based on the optical center position. Existing rectification methods are limited to central fisheye images, while this paper proposes a novel method that extends to deviated fisheye image rectification. The challenge lies in the variant global distortion distribution pattern caused by the random optical center position. To address this challenge, we propose a distortion vector map (DVM) that measures the degree and direction of local distortion. By learning the DVM, the model can independently identify local distortions at each pixel without relying on global distortion patterns. The model adopts a pre-training and fine-tuning training paradigm. In the pre-training stage, it predicts the distortion vector map and perceives the local distortion features of each pixel. In the fine-tuning stage, it predicts a pixel-wise flow map for deviated fisheye image rectification. We also propose a data augmentation method mixing central, deviated, and distorted-free images. Such data augmentation promotes the model performance in rectifying both central and deviated fisheye images, compared with models trained on single-type fisheye images. Extensive experiments demonstrate the effectiveness and superiority of the proposed method."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enhanced ASR Robustness to Packet Loss with a Front-End Adaptation Network", "authors": "Yehoshua Dissen, Shiry Yonash, Israel Cohen, Joseph Keshet", "subjects": "Subjects:\nSound (cs.SD); Computation and Language (cs.CL); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)", "abstract": "In the realm of automatic speech recognition (ASR), robustness in noisy environments remains a significant challenge. Recent ASR models, such as Whisper, have shown promise, but their efficacy in noisy conditions can be further enhanced. This study is focused on recovering from packet loss to improve the word error rate (WER) of ASR models. We propose using a front-end adaptation network connected to a frozen ASR model. The adaptation network is trained to modify the corrupted input spectrum by minimizing the criteria of the ASR model in addition to an enhancement loss function. Our experiments demonstrate that the adaptation network, trained on Whisper's criteria, notably reduces word error rates across domains and languages in packet-loss scenarios. This improvement is achieved with minimal affect to Whisper model's foundational performance, underscoring our method's practicality and potential in enhancing ASR models in challenging acoustic environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Reasoning About Action and Change", "authors": "Florence Dupin de Saint-Cyr (IRIT-ADRIA, UT3), Andreas Herzig (IRIT-LILaC, CNRS), J\u00e9r\u00f4me Lang (LAMSADE, PSL, IRIT-ADRIA), Pierre Marquis (CRIL)", "subjects": "Subjects:\nArtificial Intelligence (cs.AI); Discrete Mathematics (cs.DM); Logic in Computer Science (cs.LO); Symbolic Computation (cs.SC)", "abstract": "The purpose of this book is to provide an overview of AI research, ranging from basic work to interfaces and applications, with as much emphasis on results as on current issues. It is aimed at an audience of master students and Ph.D. students, and can be of interest as well for researchers and engineers who want to know more about AI. The book is split into three volumes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Semi-adaptive Synergetic Two-way Pseudoinverse Learning System", "authors": "Binghong Liu, Ziqi Zhao, Shupan Li, Ke Wang", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Deep learning has become a crucial technology for making breakthroughs in many fields. Nevertheless, it still faces two important challenges in theoretical and applied aspects. The first lies in the shortcomings of gradient descent based learning schemes which are time-consuming and difficult to determine the learning control hyperparameters. Next, the architectural design of the model is usually tricky. In this paper, we propose a semi-adaptive synergetic two-way pseudoinverse learning system, wherein each subsystem encompasses forward learning, backward learning, and feature concatenation modules. The whole system is trained using a non-gradient descent learning algorithm. It simplifies the hyperparameter tuning while improving the training efficiency. The architecture of the subsystems is designed using a data-driven approach that enables automated determination of the depth of the subsystems. We compare our method with the baselines of mainstream non-gradient descent based methods and the results demonstrate the effectiveness of our proposed method. The source code for this paper is available at this http URL}{this http URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Crossing Number is NP-hard for Constant Path-width (and Tree-width)", "authors": "Petr Hlin\u011bn\u00fd, Liana Khazaliya", "subjects": "Subjects:\nComputational Geometry (cs.CG); Discrete Mathematics (cs.DM)", "abstract": "Crossing Number is a celebrated problem in graph drawing. It is known to be NP-complete since 1980s, and fairly involved techniques were already required to show its fixed-parameter tractability when parameterized by the vertex cover number. In this paper we prove that computing exactly the crossing number is NP-hard even for graphs of path-width 12 (and as a result, even of tree-width 9). Thus, while tree-width and path-width have been very successful tools in many graph algorithm scenarios, our result shows that general crossing number computations unlikely (under P!=NP) could be successfully tackled using bounded width of graph decompositions, which has been a 'tantalizing open problem' [S. Cabello, Hardness of Approximation for Crossing Number, 2013] till now."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The single-use restriction for register automata and transducers over infinite alphabets", "authors": "Rafa\u0142 Stefa\u0144ski", "subjects": "Subjects:\nFormal Languages and Automata Theory (cs.FL); Computation and Language (cs.CL)", "abstract": "This thesis studies the single-use restriction for register automata and transducers over infinite alphabets. The restriction requires that a read-access to a register should have the side effect of destroying its contents. This constraint results in robust classes of languages and transductions. For automata models, we show that one-way register automata, two-way register automata, and orbit-finite monoids have the same expressive power. For transducer models, we show that single-use Mealy machines and single-use two-way transducers admit versions of the Krohn-Rhodes decomposition theorem. Moreover, single-use Mealy machines are equivalent to an algebraic model called local algebraic semigroup transductions. Additionally, we show that single-use two-way transducers are equivalent to single-use streaming string transducers (SSTs) over infinite alphabets and to regular list functions with atoms. Compared with the previous work arXiv:1907.10504, this thesis offers a coherent narrative on the single-use restriction. We introduce an abstract notion of single-use functions and use them to define all the discussed single-use models. We also introduce and study the algebraic models of local semigroup transduction and local rational semigroup transduction."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Generalized Averaging Method for Power Electronics Modeling from DC to above Half the Switching Frequency", "authors": "Hongchang Li, Kangping Wang, Jingyang Fang, Wenjie Chen, Xu Yang", "subjects": "Subjects:\nSystems and Control (eess.SY)", "abstract": "Modeling power electronic converters at frequencies close to or above half the switching frequency has been difficult due to the time-variant and discontinuous switching actions. This paper uses the properties of moving Fourier coefficients to develop the generalized averaging method, breaking though the limit of half the switching frequency. The paper also proposes the generalized average model for various switching signals, including pulse-width modulation (PWM), phase-shift modulation, pulse-frequency modulation (PFM), and state-dependent switching signals, so that circuits and modulators/controllers can be modeled separately and combined flexibly. Using the Laplace transform of moving Fourier coefficients, the coupling of signals and their sidebands at different frequencies is clearly described as the coupling of moving Fourier coefficients at the same frequency in a linear time-invariant system framework. The modeling method is applied to a PWM controlled boost converter, a V2 constant on-time controlled buck converter, and a PFM controlled LLC converter, for demonstration and validation. Experimental results of the converters in different operating modes show that the proposed models have higher accuracy than exiting models, especially in the frequency range close to or above half the switching frequency. The developed method can be applied to almost all types of power electronic converters."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Federated Graph Semantic and Structural Learning", "authors": "Wenke Huang, Guancheng Wan, Mang Ye, Bo Du", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Federated graph learning collaboratively learns a global graph neural network with distributed graphs, where the non-independent and identically distributed property is one of the major challenges. Most relative arts focus on traditional distributed tasks like images and voices, incapable of graph structures. This paper firstly reveals that local client distortion is brought by both node-level semantics and graph-level structure. First, for node-level semantics, we find that contrasting nodes from distinct classes is beneficial to provide a well-performing discrimination. We pull the local node towards the global node of the same class and push it away from the global node of different classes. Second, we postulate that a well-structural graph neural network possesses similarity for neighbors due to the inherent adjacency relationships. However, aligning each node with adjacent nodes hinders discrimination due to the potential class inconsistency. We transform the adjacency relationships into the similarity distribution and leverage the global model to distill the relation knowledge into the local model, which preserves the structural information and discriminability of the local model. Empirical results on three graph datasets manifest the superiority of the proposed method over its counterparts."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Personalized Federated Multi-scenario Multi-task Recommendation", "authors": "Yue Ding, Yanbiao Ji, Xun Cai, Xin Xin, Xiaofeng Gao, Hongtao Lu", "subjects": "Subjects:\nInformation Retrieval (cs.IR)", "abstract": "In modern recommender system applications, such as e-commerce, predicting multiple targets like click-through rate (CTR) and post-view click-through \\& conversion rate (CTCVR) is common. Multi-task recommender systems are gaining traction in research and practical use. Existing multi-task recommender systems tackle diverse business scenarios, merging and modeling these scenarios unlocks shared knowledge to boost overall performance. As new and more complex real-world recommendation scenarios have emerged, data privacy issues make it difficult to train a single global multi-task recommendation model that processes multiple separate scenarios. In this paper, we propose a novel framework for personalized federated multi-scenario multi-task recommendation, called PF-MSMTrec. We assign each scenario to a dedicated client, with each client utilizing the Mixture-of-Experts (MMoE) structure. Our proposed method aims to tackle the unique challenge posed by multiple optimization conflicts in this setting. We introduce a bottom-up joint learning mechanism. Firstly, we design a parameter template to decouple the parameters of the expert network. Thus, scenario parameters are shared knowledge for federated parameter aggregation, while task-specific parameters are personalized local parameters. Secondly, we conduct personalized federated learning for the parameters of each expert network through a federated communication round, utilizing three modules: federated batch normalization, conflict coordination, and personalized aggregation. Finally, we perform another round of personalized federated parameter aggregation on the task tower network to obtain the prediction results for multiple tasks. We conduct extensive experiments on two public datasets, and the results demonstrate that our proposed method surpasses state-of-the-art methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Evaluating AI Group Fairness: a Fuzzy Logic Perspective", "authors": "Emmanouil Krasanakis, Symeon Papadopoulos", "subjects": "Subjects:\nArtificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)", "abstract": "Artificial intelligence systems often address fairness concerns by evaluating and mitigating measures of group discrimination, for example that indicate biases against certain genders or races. However, what constitutes group fairness depends on who is asked and the social context, whereas definitions are often relaxed to accept small deviations from the statistical constraints they set out to impose. Here we decouple definitions of group fairness both from the context and from relaxation-related uncertainty by expressing them in the axiomatic system of Basic fuzzy Logic (BL) with loosely understood predicates, like encountering group members. We then evaluate the definitions in subclasses of BL, such as Product or Lukasiewicz logics. Evaluation produces continuous instead of binary truth values by choosing the logic subclass and truth values for predicates that reflect uncertain context-specific beliefs, such as stakeholder opinions gathered through questionnaires. Internally, it follows logic-specific rules to compute the truth values of definitions. We show that commonly held propositions standardize the resulting mathematical formulas and we transcribe logic and truth value choices to layperson terms, so that anyone can answer them. We also use our framework to study several literature definitions of algorithmic fairness, for which we rationalize previous expedient practices that are non-probabilistic and show how to re-interpret their formulas and parameters in new contexts."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Efficient Verifiable Differential Privacy with Input Authenticity in the Local and Shuffle Model", "authors": "Tariq Bontekoe, Hassan Jameel Asghar, Fatih Turkmen", "subjects": "Subjects:\nCryptography and Security (cs.CR)", "abstract": "Local differential privacy (LDP) is an efficient solution for providing privacy to client's sensitive data while simultaneously releasing aggregate statistics without relying on a trusted central server (aggregator) as in the central model of differential privacy. The shuffle model with LDP provides an additional layer of privacy, by disconnecting the link between clients and the aggregator, further improving the utility of LDP. However, LDP has been shown to be vulnerable to malicious clients who can perform both input and output manipulation attacks, i.e., before and after applying the LDP mechanism, to skew the aggregator's results. In this work, we show how to prevent malicious clients from compromising LDP schemes. Specifically, we give efficient constructions to prevent both input \u00e1nd output manipulation attacks from malicious clients for generic LDP algorithms. Our proposed schemes for verifiable LDP (VLDP), completely protect from output manipulation attacks, and prevent input attacks using signed data, requiring only one-time interaction between client and server, unlike existing alternatives [28, 33]. Most importantly, we are the first to provide an efficient scheme for VLDP in the shuffle model. We describe and prove secure, two schemes for VLDP in the regular model, and one in the shuffle model. We show that all schemes are highly practical, with client runtimes of < 2 seconds, and server runtimes of 5-7 milliseconds per client."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CLIP3D-AD: Extending CLIP for 3D Few-Shot Anomaly Detection with Multi-View Images Generation", "authors": "Zuo Zuo, Jiahao Dong, Yao Wu, Yanyun Qu, Zongze Wu", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Few-shot anomaly detection methods can effectively address data collecting difficulty in industrial scenarios. Compared to 2D few-shot anomaly detection (2D-FSAD), 3D few-shot anomaly detection (3D-FSAD) is still an unexplored but essential task. In this paper, we propose CLIP3D-AD, an efficient 3D-FSAD method extended on CLIP. We successfully transfer strong generalization ability of CLIP into 3D-FSAD. Specifically, we synthesize anomalous images on given normal images as sample pairs to adapt CLIP for 3D anomaly classification and segmentation. For classification, we introduce an image adapter and a text adapter to fine-tune global visual features and text features. Meanwhile, we propose a coarse-to-fine decoder to fuse and facilitate intermediate multi-layer visual representations of CLIP. To benefit from geometry information of point cloud and eliminate modality and data discrepancy when processed by CLIP, we project and render point cloud to multi-view normal and anomalous images. Then we design multi-view fusion module to fuse features of multi-view images extracted by CLIP which are used to facilitate visual representations for further enhancing vision-language correlation. Extensive experiments demonstrate that our method has a competitive performance of 3D few-shot anomaly classification and segmentation on MVTec-3D AD dataset."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Investigating and Defending Shortcut Learning in Personalized Diffusion Models", "authors": "Yixin Liu, Ruoxi Chen, Lichao Sun", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "abstract": "Personalized diffusion models have gained popularity for adapting pre-trained text-to-image models to generate images of specific topics with only a few images. However, recent studies find that these models are vulnerable to minor adversarial perturbation, and the fine-tuning performance is largely degraded on corrupted datasets. Such characteristics are further exploited to craft protective perturbation on sensitive images like portraits that prevent unauthorized generation. In response, diffusion-based purification methods have been proposed to remove these perturbations and retain generation performance. However, existing works lack detailed analysis of the fundamental shortcut learning vulnerability of personalized diffusion models and also turn to over-purifying the images cause information loss. In this paper, we take a closer look at the fine-tuning process of personalized diffusion models through the lens of shortcut learning and propose a hypothesis that could explain the underlying manipulation mechanisms of existing perturbation methods. Specifically, we find that the perturbed images are greatly shifted from their original paired prompt in the CLIP-based latent space. As a result, training with this mismatched image-prompt pair creates a construction that causes the models to dump their out-of-distribution noisy patterns to the identifier, thus causing serious performance degradation. Based on this observation, we propose a systematic approach to retain the training performance with purification that realigns the latent image and its semantic meaning and also introduces contrastive learning with a negative token to decouple the learning of wanted clean identity and the unwanted noisy pattern, that shows strong potential capacity against further adaptive perturbation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Road Less Travelled and Beyond: Towards a Roadmap for Integrating Sustainability into Computing Education", "authors": "Ana Moreira, Ola Leifler, Stefanie Betz, Ian Brooks, Rafael Capilla, Vlad Constantin Coroama, Leticia Duboc, Joao Paulo Fernandes, Rogardt Heldal, Patricia Lago, Ngoc-Thanh Nguyen, Shola Oyedeji, Birgit Penzenstadler, Anne Kathrin Peters, Jari Porras, Colin C. Venters", "subjects": "Subjects:\nSoftware Engineering (cs.SE)", "abstract": "Education for sustainable development has evolved to include more constructive approaches and a better understanding of what is needed to align education with the cultural, societal, and pedagogical changes required to avoid the risks posed by an unsustainable society. This evolution aims to lead us toward viable, equitable, and sustainable futures. However, computing education, including software engineering, is not fully aligned with the current understanding of what is needed for transformational learning in light of our current challenges. This is partly because computing is primarily seen as a technical field, focused on industry needs. Until recently, sustainability was not a high priority for most businesses, including the digital sector, nor was it a prominent focus for higher education institutions and society. Given these challenges, we aim to propose a research roadmap to integrate sustainability principles and essential skills into the crowded computing curriculum, nurturing future software engineering professionals with a sustainability mindset. We conducted two extensive studies: a systematic review of academic literature on sustainability in computing education and a survey of industry professionals on their interest in sustainability and desired skills for graduates. Using insights from these studies, we identified key topics for teaching sustainability, including core sustainability principles, values and ethics, systems thinking, impact measurement, soft skills, business value, legal standards, and advocacy. Based on these findings, we will develop recommendations for future computing education programs that emphasise sustainability. The paper is accepted at the 2030 Software Engineering workshop, which is co-located with the FSE'24 conference."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Supercloseness of the HDG method on Shishkin mesh for a singularly perturbed convection diffusion problem in 2D", "authors": "Xiaoqi Ma, Jin Zhang", "subjects": "Subjects:\nNumerical Analysis (math.NA)", "abstract": "This paper presents the first analysis of parameter-uniform convergence for a hybridizable discontinuous Galerkin (HDG) method applied to a singularly perturbed convection-diffusion problem in 2D using a Shishkin mesh. The primary difficulty lies in accurately estimating the convection term in the layer, where existing methods often fall short. To address this, a novel error control technique is employed, along with reasonable assumptions regarding the stabilization function. The results show that, with polynomial degrees not exceeding $k$, the method achieves supercloseness of almost $k+\\frac{1}{2}$ order in an energy norm. Numerical experiments confirm the theoretical accuracy and efficiency of the proposed method."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Alignment For Performance Improvement in Conversation Bots", "authors": "Raghav Garg, Kapil Sharma, Shrey Singla", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "This paper shows that alignment methods can achieve superior adherence to guardrails compared to instruction fine-tuning alone in conversational agents, also known as bots, within predefined guidelines or 'guardrails'. It examines traditional training approaches such as instruction fine-tuning and the recent advancements in direct alignment methods like Identity Preference Optimization (IPO), and Kahneman-Tversky Optimization (KTO). The effectiveness of alignment techniques both pre and post-instruction tuning is highlighted, illustrating their potential to optimize conversational bots in domains that require strict adherence to specified rules, such as customer care."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Treatment of EIP-1559: Enhancing Transaction Fee Mechanism through Nth-Price Auction", "authors": "Kun Li, Guangpeng Qi, Guangyong Shang, Wanli Deng, Minghui Xu, Xiuzhen Cheng", "subjects": "Subjects:\nDistributed, Parallel, and Cluster Computing (cs.DC); Computer Science and Game Theory (cs.GT)", "abstract": "With the widespread adoption of blockchain technology, the transaction fee mechanism (TFM) in blockchain systems has become a prominent research topic. An ideal TFM should satisfy user incentive compatibility (UIC), miner incentive compatibility (MIC), and miner-user side contract proofness ($c$-SCP). However, state-of-the-art works either fail to meet these three properties simultaneously or only satisfy them under certain conditions. In this paper, we propose a burning $N$-price auction TFM named BNP. This mechanism divides the transaction fee into a base fee, which is burned, and a priority fee, which is allocated to miners. Theoretical proofs and experimental analyses demonstrate that, even under conditions of significant transaction congestion, this mechanism satisfies UIC, MIC, and $c$-SCP simultaneously. Furthermore, the BNP mechanism is not constrained by the type of blockchain consensus, making it widely applicable."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AnyControl: Create Your Artwork with Versatile Control on Text-to-Image Generation", "authors": "Yanan Sun, Yanchen Liu, Yinhao Tang, Wenjie Pei, Kai Chen", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "The field of text-to-image (T2I) generation has made significant progress in recent years, largely driven by advancements in diffusion models. Linguistic control enables effective content creation, but struggles with fine-grained control over image generation. This challenge has been explored, to a great extent, by incorporating additional user-supplied spatial conditions, such as depth maps and edge maps, into pre-trained T2I models through extra encoding. However, multi-control image synthesis still faces several challenges. Specifically, current approaches are limited in handling free combinations of diverse input control signals, overlook the complex relationships among multiple spatial conditions, and often fail to maintain semantic alignment with provided textual prompts. This can lead to suboptimal user experiences. To address these challenges, we propose AnyControl, a multi-control image synthesis framework that supports arbitrary combinations of diverse control signals. AnyControl develops a novel Multi-Control Encoder that extracts a unified multi-modal embedding to guide the generation process. This approach enables a holistic understanding of user inputs, and produces high-quality, faithful results under versatile control signals, as demonstrated by extensive quantitative and qualitative evaluations. Our project page is available in \\url{this https URL}."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          How Do Users Revise Architectural Related Questions on Stack Overflow: An Empirical Study", "authors": "Musengamana Jean de Dieu, Peng Liang, Mojtaba Shahin, Arif Ali Khan", "subjects": "Subjects:\nSoftware Engineering (cs.SE)", "abstract": "Technical Questions and Answers (Q&A) sites, such as Stack Overflow (SO), accumulate a significant variety of information related to software development in posts from users. To ensure the quality of this information, SO encourages its users to review posts through various mechanisms (e.g., question and answer revision processes). Although Architecture Related Posts (ARPs) communicate architectural information that has a system-wide impact on development, little is known about how SO users revise information shared in ARPs. To fill this gap, we conducted an empirical study to understand how users revise Architecture Related Questions (ARQs) on SO. We manually checked 13,205 ARPs and finally identified 4,114 ARQs that contain revision information. Our main findings are that: (1) The revision of ARQs is not prevalent in SO, and an ARQ revision starts soon after this question is posted (i.e., from 1 minute onward). Moreover, the revision of an ARQ occurs before and after this question receives its first answer/architecture solution, with most revisions beginning before the first architecture solution is posted. Both Question Creators (QCs) and non-QCs actively participate in ARQ revisions, with most revisions being made by QCs. (2) A variety of information (14 categories) is missing and further provided in ARQs after being posted, among which design context, component dependency, and architecture concern are dominant information. (3) Clarify the understanding of architecture under design and improve the readability of architecture problem are the two major purposes of the further provided information in ARQs. (4) The further provided information in ARQs has several impacts on the quality of answers/architecture solutions, including making architecture solution useful, making architecture solution informative, making architecture solution relevant, among others."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Surprisingly Simple yet Effective Multi-Query Rewriting Method for Conversational Passage Retrieval", "authors": "Ivica Kostric, Krisztian Balog", "subjects": "Subjects:\nInformation Retrieval (cs.IR)", "abstract": "Conversational passage retrieval is challenging as it often requires the resolution of references to previous utterances and needs to deal with the complexities of natural language, such as coreference and ellipsis. To address these challenges, pre-trained sequence-to-sequence neural query rewriters are commonly used to generate a single de-contextualized query based on conversation history. Previous research shows that combining multiple query rewrites for the same user utterance has a positive effect on retrieval performance. We propose the use of a neural query rewriter to generate multiple queries and show how to integrate those queries in the passage retrieval pipeline efficiently. The main strength of our approach lies in its simplicity: it leverages how the beam search algorithm works and can produce multiple query rewrites at no additional cost. Our contributions further include devising ways to utilize multi-query rewrites in both sparse and dense first-pass retrieval. We demonstrate that applying our approach on top of a standard passage retrieval pipeline delivers state-of-the-art performance without sacrificing efficiency."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Formation Under Communication Constraints: Control Performance Meets Channel Capacity", "authors": "Yaru Chen, Yirui Cong, Xiangyun Zhou, Long Cheng, Xiangke Wang", "subjects": "Subjects:\nMultiagent Systems (cs.MA)", "abstract": "In wireless communication-based formation control systems, the control performance is significantly impacted by the channel capacity of each communication link between agents. This relationship, however, remains under-investigated in the existing studies. To address this gap, the formation control problem of classical second-order multi-agent systems with bounded process noises was considered taking into account the channel capacity. More specifically, the model of communication links between agents is first established, based on a new concept -- guaranteed communication region, which characterizes all possible locations for successful message decoding in the present of control-system uncertainty. Furthermore, we rigorously prove that, the guaranteed communication region does not unboundedly increase with the transmission time, which indicates an important trade-off between the guaranteed communication region and the data rate. The fundamental limits of data rate for any desired accuracy are also obtained. Finally, the integrated design to achieve the desired formation accuracy is proposed, where an estimation-based controller and transmit power control strategy are developed."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Multi-modal Food Recommendation using Clustering and Self-supervised Learning", "authors": "Yixin Zhang, Xin Zhou, Qianwen Meng, Fanglin Zhu, Yonghui Xu, Zhiqi Shen, Lizhen Cui", "subjects": "Subjects:\nInformation Retrieval (cs.IR)", "abstract": "Food recommendation systems serve as pivotal components in the realm of digital lifestyle services, designed to assist users in discovering recipes and food items that resonate with their unique dietary predilections. Typically, multi-modal descriptions offer an exhaustive profile for each recipe, thereby ensuring recommendations that are both personalized and accurate. Our preliminary investigation of two datasets indicates that pre-trained multi-modal dense representations might precipitate a deterioration in performance compared to ID features when encapsulating interactive relationships. This observation implies that ID features possess a relative superiority in modeling interactive collaborative signals. Consequently, contemporary cutting-edge methodologies augment ID features with multi-modal information as supplementary features, overlooking the latent semantic relations between recipes. To rectify this, we present CLUSSL, a novel food recommendation framework that employs clustering and self-supervised learning. Specifically, CLUSSL formulates a modality-specific graph tailored to each modality with discrete/continuous features, thereby transforming semantic features into structural representation. Furthermore, CLUSSL procures recipe representations pertinent to different modalities via graph convolutional operations. A self-supervised learning objective is proposed to foster independence between recipe representations derived from different unimodal graphs. Comprehensive experiments on real-world datasets substantiate that CLUSSL consistently surpasses state-of-the-art recommendation benchmarks in performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Generation of Random (Generalized) Orthogonal Matrices", "authors": "Ali Saraeb", "subjects": "Subjects:\nNumerical Analysis (math.NA); Number Theory (math.NT); Probability (math.PR)", "abstract": "This paper presents an algorithmic method for generating random orthogonal matrices \\(A\\) that satisfy the property \\(A^t S A = S\\), where \\(S\\) is a fixed real invertible symmetric or skew-symmetric matrix. This method is significant as it generalizes the procedures for generating orthogonal matrices that fix a general fixed symmetric or skew-symmetric bilinear form. These include orthogonal matrices that fall to groups such as the symplectic group, Lorentz group, Poincar\u00e9 group, and more generally the indefinite orthogonal group, to name a few. These classes of matrices play crucial roles in diverse fields such as theoretical physics, where they are used to describe symmetries and conservation laws, as well as in computational geometry, numerical analysis, and number theory, where they are integral to the study of quadratic forms and modular forms. The implementation of our algorithms can be accomplished using standard linear algebra libraries."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DNLSAT: A Dynamic Variable Ordering MCSAT Framework for Nonlinear Real Arithmetic", "authors": "Zhonghan Wang", "subjects": "Subjects:\nSymbolic Computation (cs.SC)", "abstract": "Satisfiability modulo nonlinear real arithmetic theory (SMT(NRA)) solving is essential to multiple applications, including program verification, program synthesis and software testing. In this context, recently model constructing satisfiability calculus (MCSAT) has been invented to directly search for models in the theory space. Although following papers discussed practical directions and updates on MCSAT, less attention has been paid to the detailed implementation. In this paper, we present an efficient implementation of dynamic variable orderings of MCSAT, called dnlsat. We show carefully designed data structures and promising mechanisms, such as branching heuristic, restart, and lemma management. Besides, we also give a theoretical study of potential influences brought by the dynamic variablr ordering. The experimental evaluation shows that dnlsat accelerates the solving speed and solves more satisfiable instances than other state-of-the-art SMT solvers. Demonstration Video: this https URL Code: this https URL Benchmark this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          UniGen: A Unified Framework for Textual Dataset Generation Using Large Language Models", "authors": "Siyuan Wu, Yue Huang, Chujie Gao, Dongping Chen, Qihui Zhang, Yao Wan, Tianyi Zhou, Xiangliang Zhang, Jianfeng Gao, Chaowei Xiao, Lichao Sun", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Large Language Models (LLMs) such as GPT-4 and Llama3 have significantly impacted various fields by enabling high-quality synthetic data generation and reducing dependence on expensive human-generated datasets. Despite this, challenges remain in the areas of generalization, controllability, diversity, and truthfulness within the existing generative frameworks. To address these challenges, this paper presents UniGen, a comprehensive LLM-powered framework designed to produce diverse, accurate, and highly controllable datasets. UniGen is adaptable, supporting all types of text datasets and enhancing the generative process through innovative mechanisms. To augment data diversity, UniGen incorporates an attribute-guided generation module and a group checking feature. For accuracy, it employs a code-based mathematical assessment for label verification alongside a retrieval-augmented generation technique for factual validation. The framework also allows for user-specified constraints, enabling customization of the data generation process to suit particular requirements. Extensive experiments demonstrate the superior quality of data generated by UniGen, and each module within UniGen plays a critical role in this enhancement. Additionally, UniGen is applied in two practical scenarios: benchmarking LLMs and data augmentation. The results indicate that UniGen effectively supports dynamic and evolving benchmarking, and that data augmentation improves LLM capabilities in various domains, including agent-oriented abilities and reasoning skills."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Structural Attention: Rethinking Transformer for Unpaired Medical Image Synthesis", "authors": "Vu Minh Hieu Phan, Yutong Xie, Bowen Zhang, Yuankai Qi, Zhibin Liao, Antonios Perperidis, Son Lam Phung, Johan W. Verjans, Minh-Son To", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Unpaired medical image synthesis aims to provide complementary information for an accurate clinical diagnostics, and address challenges in obtaining aligned multi-modal medical scans. Transformer-based models excel in imaging translation tasks thanks to their ability to capture long-range dependencies. Although effective in supervised training settings, their performance falters in unpaired image synthesis, particularly in synthesizing structural details. This paper empirically demonstrates that, lacking strong inductive biases, Transformer can converge to non-optimal solutions in the absence of paired data. To address this, we introduce UNet Structured Transformer (UNest), a novel architecture incorporating structural inductive biases for unpaired medical image synthesis. We leverage the foundational Segment-Anything Model to precisely extract the foreground structure and perform structural attention within the main anatomy. This guides the model to learn key anatomical regions, thus improving structural synthesis under the lack of supervision in unpaired training. Evaluated on two public datasets, spanning three modalities, i.e., MR, CT, and PET, UNest improves recent methods by up to 19.30% across six medical image synthesis tasks. Our code is released at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RoboUniView: Visual-Language Model with Unified View Representation for Robotic Manipulaiton", "authors": "Fanfan Liu, Feng Yan, Liming Zheng, Chengjian Feng, Yiyang Huang, Lin Ma", "subjects": "Subjects:\nRobotics (cs.RO); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Utilizing Vision-Language Models (VLMs) for robotic manipulation represents a novel paradigm, aiming to enhance the model's ability to generalize to new objects and instructions. However, due to variations in camera specifications and mounting positions, existing methods exhibit significant performance disparities across different robotic platforms. To address this challenge, we propose RoboUniView in this paper, an innovative approach that decouples visual feature extraction from action learning. We first learn a unified view representation from multi-perspective views by pre-training on readily accessible data, and then derive actions from this unified view representation to control robotic manipulation. This unified view representation more accurately mirrors the physical world and is not constrained by the robotic platform's camera parameters. Thanks to this methodology, we achieve state-of-the-art performance on the demanding CALVIN benchmark, enhancing the success rate in the $D \\to D$ setting from 88.7% to 96.2%, and in the $ABC \\to D$ setting from 82.4% to 94.2%. Moreover, our model exhibits outstanding adaptability and flexibility: it maintains high performance under unseen camera parameters, can utilize multiple datasets with varying camera parameters, and is capable of joint cross-task learning across datasets. Code is provided for re-implementation. this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          E-Mapper: Energy-Efficient Resource Allocation for Traditional Operating Systems on Heterogeneous Processors", "authors": "Till Smejkal, Robert Khasanov, Jeronimo Castrillon, Hermann H\u00e4rtig", "subjects": "Subjects:\nOperating Systems (cs.OS)", "abstract": "Energy efficiency has become a key concern in modern computing. Major processor vendors now offer heterogeneous architectures that combine powerful cores with energy-efficient ones, such as Intel P/E systems, Apple M1 chips, and Samsungs Exyno's CPUs. However, apart from simple cost-based thread allocation strategies, today's OS schedulers do not fully exploit these systems' potential for adaptive energy-efficient computing. This is, in part, due to missing application-level interfaces to pass information about task-level energy consumption and application-level elasticity. This paper presents E-Mapper, a novel resource management approach integrated into Linux for improved execution on heterogeneous processors. In E-Mapper, we base resource allocation decisions on high-level application descriptions that user can attach to programs or that the system can learn automatically at runtime. Our approach supports various programming models including OpenMP, Intel TBB, and TensorFlow. Crucially, E-Mapper leverages this information to extend beyond existing thread-to-core allocation strategies by actively managing application configurations through a novel uniform application-resource manager interface. By doing so, E-Mapper achieves substantial enhancements in both performance and energy efficiency, particularly in multi-application scenarios. On an Intel Raptor Lake and an Arm big.LITTLE system, E-Mapper reduces the application execution on average by 20 % with an average reduction in energy consumption of 34 %. We argue that our solution marks a crucial step toward creating a generic approach for sustainable and efficient computing across different processor architectures."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Amplify Graph Learning for Recommendation via Sparsity Completion", "authors": "Peng Yuan, Haojie Li, Minying Fang, Xu Yu, Yongjing Hao, Junwei Du", "subjects": "Subjects:\nInformation Retrieval (cs.IR)", "abstract": "Graph learning models have been widely deployed in collaborative filtering (CF) based recommendation systems. Due to the issue of data sparsity, the graph structure of the original input lacks potential positive preference edges, which significantly reduces the performance of recommendations. In this paper, we study how to enhance the graph structure for CF more effectively, thereby optimizing the representation of graph nodes. Previous works introduced matrix completion techniques into CF, proposing the use of either stochastic completion methods or superficial structure completion to address this issue. However, most of these approaches employ random numerical filling that lack control over noise perturbations and limit the in-depth exploration of higher-order interaction features of nodes, resulting in biased graph representations. In this paper, we propose an Amplify Graph Learning framework based on Sparsity Completion (called AGL-SC). First, we utilize graph neural network to mine direct interaction features between user and item nodes, which are used as the inputs of the encoder. Second, we design a factorization-based method to mine higher-order interaction features. These features serve as perturbation factors in the latent space of the hidden layer to facilitate generative enhancement. Finally, by employing the variational inference, the above multi-order features are integrated to implement the completion and enhancement of missing graph structures. We conducted benchmark and strategy experiments on four real-world datasets related to recommendation tasks. The experimental results demonstrate that AGL-SC significantly outperforms the state-of-the-art methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Exploiting Structured Sparsity in Near Field: From the Perspective of Decomposition", "authors": "Xufeng Guo, Yuanbin Chen, Ying Wang, Chau Yuen", "subjects": "Subjects:\nInformation Theory (cs.IT); Signal Processing (eess.SP)", "abstract": "The structured sparsity can be leveraged in traditional far-field channels, greatly facilitating efficient sparse channel recovery by compressing the complexity of overheads to the level of the scatterer number. However, when experiencing a fundamental shift from planar-wave-based far-field modeling to spherical-wave-based near-field modeling, whether these benefits persist in the near-field regime remains an open issue. To answer this question, this article delves into structured sparsity in the near-field realm, examining its peculiarities and challenges. In particular, we present the key features of near-field structured sparsity in contrast to the far-field counterpart, drawing from both physical and mathematical perspectives. Upon unmasking the theoretical bottlenecks, we resort to bypassing them by decoupling the geometric parameters of the scatterers, termed the triple parametric decomposition (TPD) framework. It is demonstrated that our novel TPD framework can achieve robust recovery of near-field sparse channels by applying the potential structured sparsity and avoiding the curse of complexity and overhead."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Fast Learning-Based Surrogate of Electrical Machines using a Reduced Basis", "authors": "Alejandro Rib\u00e9s, Nawfal Benchekroun, Th\u00e9o Delagnes", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "A surrogate model approximates the outputs of a solver of Partial Differential Equations (PDEs) with a low computational cost. In this article, we propose a method to build learning-based surrogates in the context of parameterized PDEs, which are PDEs that depend on a set of parameters but are also temporal and spatial processes. Our contribution is a method hybridizing the Proper Orthogonal Decomposition and several Support Vector Regression machines. This method is conceived to work in real-time, thus aimed for being used in the context of digital twins, where a user can perform an interactive analysis of results based on the proposed surrogate. We present promising results on two use cases concerning electrical machines. These use cases are not toy examples but are produced an industrial computational code, they use meshes representing non-trivial geometries and contain non-linearities."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Semi-supervised Concept Bottleneck Models", "authors": "Lijie Hu, Tianhao Huang, Huanyi Xie, Chenyang Ren, Zhengyu Hu, Lu Yu, Di Wang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Concept Bottleneck Models (CBMs) have garnered increasing attention due to their ability to provide concept-based explanations for black-box deep learning models while achieving high final prediction accuracy using human-like concepts. However, the training of current CBMs heavily relies on the accuracy and richness of annotated concepts in the dataset. These concept labels are typically provided by experts, which can be costly and require significant resources and effort. Additionally, concept saliency maps frequently misalign with input saliency maps, causing concept predictions to correspond to irrelevant input features - an issue related to annotation alignment. To address these limitations, we propose a new framework called SSCBM (Semi-supervised Concept Bottleneck Model). Our SSCBM is suitable for practical situations where annotated data is scarce. By leveraging joint training on both labeled and unlabeled data and aligning the unlabeled data at the concept level, we effectively solve these issues. We proposed a strategy to generate pseudo labels and an alignment loss. Experiments demonstrate that our SSCBM is both effective and efficient. With only 20% labeled data, we achieved 93.19% (96.39% in a fully supervised setting) concept accuracy and 75.51% (79.82% in a fully supervised setting) prediction accuracy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity", "authors": "Zhaobin Sun (1), Nannan Wu (1), Junjie Shi (1), Li Yu (1), Xin Yang (1), Kwang-Ting Cheng (2), Zengqiang Yan (1) ((1) School of Electronic Information and Communications, Huazhong University of Science and Technology, (2) School of Engineering, Hong Kong University of Science and Technology)", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Cross-silo federated learning (FL) enables decentralized organizations to collaboratively train models while preserving data privacy and has made significant progress in medical image classification. One common assumption is task homogeneity where each client has access to all classes during training. However, in clinical practice, given a multi-label classification task, constrained by the level of medical knowledge and the prevalence of diseases, each institution may diagnose only partial categories, resulting in task heterogeneity. How to pursue effective multi-label medical image classification under task heterogeneity is under-explored. In this paper, we first formulate such a realistic label missing setting in the multi-label FL domain and propose a two-stage method FedMLP to combat class missing from two aspects: pseudo label tagging and global knowledge learning. The former utilizes a warmed-up model to generate class prototypes and select samples with high confidence to supplement missing labels, while the latter uses a global model as a teacher for consistency regularization to prevent forgetting missing class knowledge. Experiments on two publicly-available medical datasets validate the superiority of FedMLP against the state-of-the-art both federated semi-supervised and noisy label learning approaches under task heterogeneity. Code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Zero-shot domain adaptation based on dual-level mix and contrast", "authors": "Yu Zhe, Jun Sakuma", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Zero-shot domain adaptation (ZSDA) is a domain adaptation problem in the situation that labeled samples for a target task (task of interest) are only available from the source domain at training time, but for a task different from the task of interest (irrelevant task), labeled samples are available from both source and target domains. In this situation, classical domain adaptation techniques can only learn domain-invariant features in the irrelevant task. However, due to the difference in sample distribution between the two tasks, domain-invariant features learned in the irrelevant task are biased and not necessarily domain-invariant in the task of interest. To solve this problem, this paper proposes a new ZSDA method to learn domain-invariant features with low task bias. To this end, we propose (1) data augmentation with dual-level mixups in both task and domain to fill the absence of target task-of-interest data, (2) an extension of domain adversarial learning to learn domain-invariant features with less task bias, and (3) a new dual-level contrastive learning method that enhances domain-invariance and less task biasedness of features. Experimental results show that our proposal achieves good performance on several benchmarks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Improving Taxonomic Image-based Out-of-distribution Detection With DNA Barcodes", "authors": "Mikko Impi\u00f6, Jenni Raitoharju", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Image-based species identification could help scaling biodiversity monitoring to a global scale. Many challenges still need to be solved in order to implement these systems in real-world applications. A reliable image-based monitoring system must detect out-of-distribution (OOD) classes it has not been presented before. This is challenging especially with fine-grained classes. Emerging environmental monitoring techniques, DNA metabarcoding and eDNA, can help by providing information on OOD classes that are present in a sample. In this paper, we study if DNA barcodes can also support in finding the outlier images based on the outlier DNA sequence's similarity to the seen classes. We propose a re-ordering approach that can be easily applied on any pre-trained models and existing OOD detection methods. We experimentally show that the proposed approach improves taxonomic OOD detection compared to all common baselines. We also show that the method works thanks to a correlation between visual similarity and DNA barcode proximity. The code and data are available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Simpson's quadrature for a nonlinear variational symplectic scheme", "authors": "Fran\u00e7ois Dubois (LMO, LMSSC), Juan Antonio Rojas-Quintero", "subjects": "Subjects:\nNumerical Analysis (math.NA)", "abstract": "We propose a variational symplectic numerical method for the time integration of dynamical systems issued from the least action principle. We assume a quadratic internal interpolation of the state between two time steps and we approximate the action in one time step by the Simpson's quadrature formula. The resulting scheme is nonlinear and symplectic. First numerical experiments concern a nonlinear pendulum and we have observed experimentally very good convergence properties."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Coded Cooperative Networks for Semi-Decentralized Federated Learning", "authors": "Shudi Weng, Ming Xiao, Mikael Skoglund", "subjects": "Subjects:\nInformation Theory (cs.IT)", "abstract": "To enhance straggler resilience in federated learning (FL) systems, a semi-decentralized approach has been recently proposed, enabling collaboration between clients. Unlike the existing semi-decentralized schemes, which adaptively adjust the collaboration weight according to the network topology, this letter proposes a deterministic coded network that leverages wireless diversity for semi-decentralized FL without requiring prior information about the entire network. Furthermore, the theoretical analyses of the outage and the convergence rate of the proposed scheme are provided. Finally, the superiority of our proposed method over benchmark methods is demonstrated through comprehensive simulations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          VideoMambaPro: A Leap Forward for Mamba in Video Understanding", "authors": "Hui Lu, Albert Ali Salah, Ronald Poppe", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Video understanding requires the extraction of rich spatio-temporal representations, which transformer models achieve through self-attention. Unfortunately, self-attention poses a computational burden. In NLP, Mamba has surfaced as an efficient alternative for transformers. However, Mamba's successes do not trivially extend to computer vision tasks, including those in video analysis. In this paper, we theoretically analyze the differences between self-attention and Mamba. We identify two limitations in Mamba's token processing: historical decay and element contradiction. We propose VideoMambaPro (VMP) that solves the identified limitations by adding masked backward computation and elemental residual connections to a VideoMamba backbone. VideoMambaPro shows state-of-the-art video action recognition performance compared to transformer models, and surpasses VideoMamba by clear margins: 7.9% and 8.1% top-1 on Kinetics-400 and Something-Something V2, respectively. Our VideoMambaPro-M model achieves 91.9% top-1 on Kinetics-400, only 0.2% below InternVideo2-6B but with only 1.2% of its parameters. The combination of high performance and efficiency makes VideoMambaPro an interesting alternative for transformer models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards a Formal Characterization of User Simulation Objectives in Conversational Information Access", "authors": "Nolwenn Bernard, Krisztian Balog", "subjects": "Subjects:\nInformation Retrieval (cs.IR)", "abstract": "User simulation is a promising approach for automatically training and evaluating conversational information access agents, enabling the generation of synthetic dialogues and facilitating reproducible experiments at scale. However, the objectives of user simulation for the different uses remain loosely defined, hindering the development of effective simulators. In this work, we formally characterize the distinct objectives for user simulators: training aims to maximize behavioral similarity to real users, while evaluation focuses on the accurate prediction of real-world conversational agent performance. Through an empirical study, we demonstrate that optimizing for one objective does not necessarily lead to improved performance on the other. This finding underscores the need for tailored design considerations depending on the intended use of the simulator. By establishing clear objectives and proposing concrete measures to evaluate user simulators against those objectives, we pave the way for the development of simulators that are specifically tailored to their intended use, ultimately leading to more effective conversational agents."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          VertiMRF: Differentially Private Vertical Federated Data Synthesis", "authors": "Fangyuan Zhao, Zitao Li, Xuebin Ren, Bolin Ding, Shusen Yang, Yaliang Li", "subjects": "Subjects:\nData Structures and Algorithms (cs.DS)", "abstract": "Data synthesis is a promising solution to share data for various downstream analytic tasks without exposing raw data. However, without a theoretical privacy guarantee, a synthetic dataset would still leak some sensitive information. Differential privacy is thus widely adopted to safeguard data synthesis by strictly limiting the released information. This technique is advantageous yet presents significant challenges in the vertical federated setting, where data attributes are distributed among different data parties. The main challenge lies in maintaining privacy while efficiently and precisely reconstructing the correlation among cross-party attributes. In this paper, we propose a novel algorithm called VertiMRF, designed explicitly for generating synthetic data in the vertical setting and providing differential privacy protection for all information shared from data parties. We introduce techniques based on the Flajolet-Martin sketch (or frequency oracle) for encoding local data satisfying differential privacy and estimating cross-party marginals. We provide theoretical privacy and utility proof for encoding in this multi-attribute data. Collecting the locally generated private Markov Random Field (MRF) and the sketches, a central server can reconstruct a global MRF, maintaining the most useful information. Additionally, we introduce two techniques tailored for datasets with large attribute domain sizes, namely dimension reduction and consistency enforcement. These two techniques allow flexible and inconsistent binning strategies of local private MRF and the data sketching module, which can preserve information to the greatest extent. We conduct extensive experiments on four real-world datasets to evaluate the effectiveness of VertiMRF. End-to-end comparisons demonstrate the superiority of VertiMRF, and ablation studies validate the effectiveness of each component."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On the Energy Consumption of Rotary Wing and Fixed Wing UAVs in Flying Networks", "authors": "Pedro Ribeiro, Andr\u00e9 Coelho, Rui Campos", "subjects": "Subjects:\nNetworking and Internet Architecture (cs.NI); Signal Processing (eess.SP)", "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly used to enable wireless communications. Due to their characteristics, such as the ability to hover and carry cargo, UAVs can serve as communications nodes, including Wi-Fi Access Points and Cellular Base Stations. In previous work, we proposed the Sustainable multi-UAV Performance-aware Placement (SUPPLY) algorithm, which focuses on the energy-efficient placement of multiple UAVs acting as Flying Access Points (FAPs). Additionally, we developed the Multi-UAV Energy Consumption (MUAVE) simulator to evaluate the UAV energy consumption, specifically when using the SUPPLY algorithm. However, MUAVE was initially designed to compute the energy consumption for rotary-wing UAVs only. In this paper, we propose eMUAVE, an enhanced version of the MUAVE simulator that allows the evaluation of the energy consumption for both rotary-wing and fixed-wing UAVs. Our energy consumption evaluation using eMUAVE considers reference and random networking scenarios. The results show that fixed-wing UAVs can be employed in the majority of networking scenarios. However, rotary-wing UAVs are typically more energy-efficient than fixed-wing UAVs when following the trajectories defined by SUPPLY."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Impact of Autonomous Vehicles on Ride-Hailing Platforms with Strategic Human Drivers", "authors": "Shuqin Gao, Xinyuan Wu, Antonis Dimakis, Costas Courcoubetis", "subjects": "Subjects:\nComputer Science and Game Theory (cs.GT)", "abstract": "Motivated by the rapid development of autonomous vehicle technology, this work focuses on the challenges of introducing them in ride-hailing platforms with conventional strategic human drivers. We consider a ride-hailing platform that operates a mixed fleet of autonomous vehicles (AVs) and conventional vehicles (CVs), where AVs are fully controlled by the platform and CVs are operated by self-interested human drivers. Each vehicle is modelled as a Markov Decision Process that maximizes long-run average reward by choosing its repositioning actions. The behavior of the CVs corresponds to a large game where agents interact through resource constraints that result in queuing delays. In our fluid model, drivers may wait in queues in the different regions when the supply of drivers tends to exceed the service demand by customers. Our primary objective is to optimize the mixed AV-CV system so that the total profit of the platform generated by AVs and CVs is maximized. To achieve that, we formulate this problem as a bi-level optimization problem OPT where the platform moves first by controlling the actions of the AVs and the demand revealed to CVs, and then the CVs react to the revealed demand by forming an equilibrium that can be characterized by the solution of a convex optimization problem. We prove several interesting structural properties of the optimal solution and analyze simple heuristics such as AV-first where we solve for the optimal dispatch of AVs without taking into account the subsequent reaction of the CVs. We propose three numerical algorithms to solve OPT which is a non-convex problem in the platform decision parameters. We evaluate their performance and use them to show some interesting trends in the optimal AV-CV fleet dimensioning when supply is exogenous and endogenous."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Lithium-Ion Battery System Health Monitoring and Fault Analysis from Field Data Using Gaussian Processes", "authors": "Joachim Schaeffer, Eric Lenz, Duncan Gulla, Martin Z. Bazant, Richard D. Braatz, Rolf Findeisen", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Systems and Control (eess.SY); Applications (stat.AP)", "abstract": "Health monitoring, fault analysis, and detection are critical for the safe and sustainable operation of battery systems. We apply Gaussian process resistance models on lithium iron phosphate battery field data to effectively separate the time-dependent and operating point-dependent resistance. The data set contains 29 battery systems returned to the manufacturer for warranty, each with eight cells in series, totaling 232 cells and 131 million data rows. We develop probabilistic fault detection rules using recursive spatiotemporal Gaussian processes. These processes allow the quick processing of over a million data points, enabling advanced online monitoring and furthering the understanding of battery pack failure in the field. The analysis underlines that often, only a single cell shows abnormal behavior or a knee point, consistent with weakest-link failure for cells connected in series, amplified by local resistive heating. The results further the understanding of how batteries degrade and fail in the field and demonstrate the potential of efficient online monitoring based on data. We open-source the code and publish the large data set upon completion of the review of this article."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Robust Multi-Robot Global Localization with Unknown Initial Pose based on Neighbor Constraints", "authors": "Yaojie Zhang, Haowen Luo, Weijun Wang, Wei Feng", "subjects": "Subjects:\nRobotics (cs.RO)", "abstract": "Multi-robot global localization (MR-GL) with unknown initial positions in a large scale environment is a challenging task. The key point is the data association between different robots' viewpoints. It also makes traditional Appearance-based localization methods unusable. Recently, researchers have utilized the object's semantic invariance to generate a semantic graph to address this issue. However, previous works lack robustness and are sensitive to overlap rate of maps, resulting in unpredictable performance in real-world environments. In this paper, we propose a data association algorithm based on neighbor constraints to improve the robustness of the system. We demonstrate the effectiveness of our method on three different datasets, indicating a significant improvement in robustness compared to previous works."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Efficient course recommendations with T5-based ranking and summarization", "authors": "Thijmen Bijl, Niels van Weeren, Suzan Verberne", "subjects": "Subjects:\nInformation Retrieval (cs.IR)", "abstract": "In this paper, we implement and evaluate a two-stage retrieval pipeline for a course recommender system that ranks courses for skill-occupation pairs. The in-production recommender system BrightFit provides course recommendations from multiple sources. Some of the course descriptions are long and noisy, while retrieval and ranking in an online system have to be highly efficient. We developed a two-step retrieval pipeline with RankT5 finetuned on MSMARCO as re-ranker. We compare two summarizers for course descriptions: a LongT5 model that we finetuned for the task, and a generative LLM (Vicuna) with in-context learning. We experiment with quantization to reduce the size of the ranking model and increase inference speed. We evaluate our rankers on two newly labelled datasets, with an A/B test, and with a user questionnaire. On the two labelled datasets, our proposed two-stage ranking with automatic summarization achieves a substantial improvement over the in-production (BM25) ranker: nDCG@10 scores improve from 0.482 to 0.684 and from 0.447 to 0.844 on the two datasets. We also achieve a 40% speed-up by using a quantized version of RankT5. The improved quality of the ranking was confirmed by the questionnaire completed by 29 respondents, but not by the A/B test. In the A/B test, a higher clickthrough rate was observed for the BM25-ranking than for the proposed two-stage retrieval. We conclude that T5-based re-ranking and summarization for online course recommendation can obtain much better effectiveness than single-step lexical retrieval, and that quantization has a large effect on RankT5. In the online evaluation, however, other factors than relevance play a role (such as speed and interpretability of the retrieval results), as well as individual preferences."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Isogeometric Shape Optimization of Multi-Tapered Coaxial Baluns Simulated by an Integral Equation Method", "authors": "Boian Balouchev, J\u00fcrgen D\u00f6lz, Maximilian Nolte, Sebastian Sch\u00f6ps, Riccardo Torchio", "subjects": "Subjects:\nComputational Engineering, Finance, and Science (cs.CE)", "abstract": "We discuss the advantages of a spline-based freeform shape optimization approach using the example of a multi-tapered coaxial balun connected to a spiral antenna. The underlying simulation model is given in terms of a recently proposed isogeometric integral equation formulation, which can be interpreted as a high-order generalization of the partial element equivalent circuit method. We demonstrate a significant improvement in the optimized design, i.e., a reduction in the magnitude of the scattering parameter over a wide frequency range."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Completely decomposable rank-metric codes", "authors": "Paolo Santonastaso", "subjects": "Subjects:\nInformation Theory (cs.IT)", "abstract": "In this paper, we investigate completely decomposable rank-metric codes, i.e. rank-metric codes that are the direct sum of 1-dimensional maximum rank distance codes. We study the weight distribution of such codes, characterizing codewords with certain rank weights. Additionally, we obtain classification results for codes with the largest number of minimum weight codewords within the class of completely decomposable codes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Using diffusion model as constraint: Empower Image Restoration Network Training with Diffusion Model", "authors": "Jiangtong Tan, Feng Zhao", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Image restoration has made marvelous progress with the advent of deep learning. Previous methods usually rely on designing powerful network architecture to elevate performance, however, the natural visual effect of the restored results is limited by color and texture distortions. Besides the visual perceptual quality, the semantic perception recovery is an important but often overlooked perspective of restored image, which is crucial for the deployment in high-level tasks. In this paper, we propose a new perspective to resort these issues by introducing a naturalness-oriented and semantic-aware optimization mechanism, dubbed DiffLoss. Specifically, inspired by the powerful distribution coverage capability of the diffusion model for natural image generation, we exploit the Markov chain sampling property of diffusion model and project the restored results of existing networks into the sampling space. Besides, we reveal that the bottleneck feature of diffusion models, also dubbed h-space feature, is a natural high-level semantic space. We delve into this property and propose a semantic-aware loss to further unlock its potential of semantic perception recovery, which paves the way to connect image restoration task and downstream high-level recognition task. With these two strategies, the DiffLoss can endow existing restoration methods with both more natural and semantic-aware results. We verify the effectiveness of our method on substantial common image restoration tasks and benchmarks. Code will be available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Improving Weak-to-Strong Generalization with Reliability-Aware Alignment", "authors": "Yue Guo, Yi Yang", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Large language models (LLMs) are now rapidly advancing and surpassing human abilities on many natural language tasks. However, aligning these super-human LLMs with human knowledge remains challenging because the supervision signals from human annotators may be wrong. This issue, known as the \"super-alignment\" problem, requires enhancing weak-to-strong generalization, where a strong LLM must generalize from imperfect supervision provided by a weaker source. To address this issue, we propose an approach to improve weak-to-strong generalization by involving the reliability of weak supervision signals in the alignment process. In our method, we query the weak supervisor for multiple answers, estimate the answer reliability, and enhance the alignment process by filtering out uncertain data or re-weighting reliable data. Experiments on four datasets demonstrate that our methods effectively identify the quality of weak labels and significantly enhance weak-to-strong generalization. Our work presents effective techniques for error-robust model alignment, reducing error propagation from noisy supervision and enhancing the accuracy and reliability of LLMs. Codes are publicly available at this http URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SD-BLS: Privacy Preserving Selective Disclosure and Unlinkable Revocation of Verifiable Credentials", "authors": "Denis Roio, Rebecca Selvaggini, Andrea D'Intino", "subjects": "Subjects:\nCryptography and Security (cs.CR)", "abstract": "It is of critical importance to design digital identity systems that ensure the privacy of citizens as well as protecting them from issuer corruption. Unfortunately, what Europe's and USA's public sectors are currently developing does not offer such basic protections. We aim to solve this issue and propose a method for untraceable selective disclosure and privacy preserving revocation of digital credentials, using the unique homomorphic characteristics of second order Elliptic Curves and Boneh-Lynn-Shacham (BLS) signatures. Our approach ensures that users can selectively reveal only the necessary credentials, while protecting their privacy across multiple presentations. We also aim to protect users from issuer corruption, by making it possible to apply a threshold for revocation to require collective agreement among multiple revocation issuers."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Constructing and Analyzing Different Density Graphs for Path Extrapolation in Wikipedia", "authors": "Martha Sotiroudi, Anastasia-Sotiria Toufa, Constantine Kotropoulos", "subjects": "Subjects:\nDatabases (cs.DB)", "abstract": "Graph-based models have become pivotal in understanding and predicting navigational patterns within complex networks. Building on graph-based models, the paper advances path extrapolation methods to efficiently predict Wikipedia navigation paths. The Wikipedia Central Macedonia (WCM) dataset is sourced from Wikipedia, with a spotlight on the Central Macedonia region, Greece, to initiate path generation. To build WCM, a crawling process is used that simulates human navigation through Wikipedia. Experimentation shows that an extension of the graph neural network GRETEL, which resorts to dual hypergraph transformation, performs better on a dense graph of WCM than on a sparse graph of WCM. Moreover, combining hypergraph features with features extracted from graph edges has proven to enhance the model's effectiveness. A superior model's performance is reported on the WCM dense graph than on the larger Wikispeedia dataset, suggesting that size may not be as influential in predictive accuracy as the quality of connections and feature extraction. The paper fits the track Knowledge Discovery and Machine Learning of the 16th International Conference on Advances in Databases, Knowledge, and Data Applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On Convex Optimization with Semi-Sensitive Features", "authors": "Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Raghu Meka, Chiyuan Zhang", "subjects": "Subjects:\nMachine Learning (cs.LG); Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS)", "abstract": "We study the differentially private (DP) empirical risk minimization (ERM) problem under the semi-sensitive DP setting where only some features are sensitive. This generalizes the Label DP setting where only the label is sensitive. We give improved upper and lower bounds on the excess risk for DP-ERM. In particular, we show that the error only scales polylogarithmically in terms of the sensitive domain size, improving upon previous results that scale polynomially in the sensitive domain size (Ghazi et al., 2021)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Credential-based Device Registration in DApps for DePINs with ZKPs", "authors": "Jonathan Heiss, Fernando Castillo, Xinxin Fan", "subjects": "Subjects:\nCryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Decentralized Physical Infrastructure Networks (DePINS) are secured and governed by blockchains but beyond crypto-economic incentives, they lack measures to establish trust in participating devices and their services. The verification of relevant device credentials during device registration helps to overcome this problem. However, on-chain verification in decentralized applications (dApp) discloses potentially confidential device attributes whereas off-chain verification introduces undesirable trust assumptions. In this paper, we propose a credential-based device registration (CDR) mechanism that verifies device credentials on the blockchain and leverages zero-knowledge proofs (ZKP) to protect confidential device attributes from being disclosed. We characterize CDR for DePINs, present a general system model, and technically evaluate CDR using zkSNARKs with Groth16 and Marlin. Our experiments give first insights into performance impacts and reveal a tradeoff between the applied proof systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          BiCo-Fusion: Bidirectional Complementary LiDAR-Camera Fusion for Semantic- and Spatial-Aware 3D Object Detection", "authors": "Yang Song, Lin Wang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "3D object detection is an important task that has been widely applied in autonomous driving. Recently, fusing multi-modal inputs, i.e., LiDAR and camera data, to perform this task has become a new trend. Existing methods, however, either ignore the sparsity of Lidar features or fail to preserve the original spatial structure of LiDAR and the semantic density of camera features simultaneously due to the modality gap. To address issues, this letter proposes a novel bidirectional complementary Lidar-camera fusion framework, called BiCo-Fusion that can achieve robust semantic- and spatial-aware 3D object detection. The key insight is to mutually fuse the multi-modal features to enhance the semantics of LiDAR features and the spatial awareness of the camera features and adaptatively select features from both modalities to build a unified 3D representation. Specifically, we introduce Pre-Fusion consisting of a Voxel Enhancement Module (VEM) to enhance the semantics of voxel features from 2D camera features and Image Enhancement Module (IEM) to enhance the spatial characteristics of camera features from 3D voxel features. Both VEM and IEM are bidirectionally updated to effectively reduce the modality gap. We then introduce Unified Fusion to adaptively weight to select features from the enchanted Lidar and camera features to build a unified 3D representation. Extensive experiments demonstrate the superiority of our BiCo-Fusion against the prior arts. Project page: this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Accuracy on the wrong line: On the pitfalls of noisy data for out-of-distribution generalisation", "authors": "Amartya Sanyal, Yaxi Hu, Yaodong Yu, Yian Ma, Yixin Wang, Bernhard Sch\u00f6lkopf", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "abstract": "\"Accuracy-on-the-line\" is a widely observed phenomenon in machine learning, where a model's accuracy on in-distribution (ID) and out-of-distribution (OOD) data is positively correlated across different hyperparameters and data configurations. But when does this useful relationship break down? In this work, we explore its robustness. The key observation is that noisy data and the presence of nuisance features can be sufficient to shatter the Accuracy-on-the-line phenomenon. In these cases, ID and OOD accuracy can become negatively correlated, leading to \"Accuracy-on-the-wrong-line\". This phenomenon can also occur in the presence of spurious (shortcut) features, which tend to overshadow the more complex signal (core, non-spurious) features, resulting in a large nuisance feature space. Moreover, scaling to larger datasets does not mitigate this undesirable behavior and may even exacerbate it. We formally prove a lower bound on Out-of-distribution (OOD) error in a linear classification model, characterizing the conditions on the noise and nuisance features for a large OOD error. We finally demonstrate this phenomenon across both synthetic and real datasets with noisy data and nuisance features."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning", "authors": "Alexander Herzog, Robbie Southam, Ioannis Mavromatis, Aftab Khan", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Federated Learning (FL) is a distributed machine learning approach that enables training on decentralized data while preserving privacy. However, FL systems often involve resource-constrained client devices with limited computational power, memory, storage, and bandwidth. This paper introduces FedMap, a novel method that aims to enhance the communication efficiency of FL deployments by collaboratively learning an increasingly sparse global model through iterative, unstructured pruning. Importantly, FedMap trains a global model from scratch, unlike other methods reported in the literature, making it ideal for privacy-critical use cases such as in the medical and finance domains, where suitable pre-training data is often limited. FedMap adapts iterative magnitude-based pruning to the FL setting, ensuring all clients prune and refine the same subset of the global model parameters, therefore gradually reducing the global model size and communication overhead. The iterative nature of FedMap, forming subsequent models as subsets of predecessors, avoids parameter reactivation issues seen in prior work, resulting in stable performance. In this paper we provide an extensive evaluation of FedMap across diverse settings, datasets, model architectures, and hyperparameters, assessing performance in both IID and non-IID environments. Comparative analysis against the baseline approach demonstrates FedMap's ability to achieve more stable client model performance. For IID scenarios, FedMap achieves over $90$\\% pruning without significant performance degradation. In non-IID settings, it achieves at least $~80$\\% pruning while maintaining accuracy. FedMap offers a promising solution to alleviate communication bottlenecks in FL systems while retaining model accuracy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Staff Scheduling for Demand-Responsive Services", "authors": "Debsankha Manik, Rico Raber", "subjects": "Subjects:\nDiscrete Mathematics (cs.DM)", "abstract": "Staff scheduling is a well-known problem in operations research and finds its application at hospitals, airports, supermarkets, and many others. Its goal is to assign shifts to staff members such that a certain objective function, e.g. revenue, is maximized. Meanwhile, various constraints of the staff members and the organization need to be satisfied. Typically in staff scheduling problems, there are hard constraints on the minimum number of employees that should be available at specific points of time. Often multiple hard constraints guaranteeing the availability of specific number of employees with different roles need to be considered. Staff scheduling for demand-responsive services, such as, e.g., ride-pooling and ride-hailing services, differs in a key way from this: There are often no hard constraints on the minimum number of employees needed at fixed points in time. Rather, the number of employees working at different points in time should vary according to the demand at those points in time. Having too few employees at a point in time results in lost revenue, while having too many employees at a point in time results in not having enough employees at other points in time, since the total personnel-hours are limited. The objective is to maximize the total reward generated over a planning horizon, given a monotonic relationship between the number of shifts active at a point in time and the instantaneous reward generated at that point in time. This key difference makes it difficult to use existing staff scheduling algorithms for planning shifts in demand-responsive services. In this article, we present a novel approach for modelling and solving staff scheduling problems for demand-responsive services that optimizes for the relevant reward function."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A look under the hood of the Interactive Deep Learning Enterprise (No-IDLE)", "authors": "Daniel Sonntag, Michael Barz, Thiago Gouv\u00eaa", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "abstract": "This DFKI technical report presents the anatomy of the No-IDLE prototype system (funded by the German Federal Ministry of Education and Research) that provides not only basic and fundamental research in interactive machine learning, but also reveals deeper insights into users' behaviours, needs, and goals. Machine learning and deep learning should become accessible to millions of end users. No-IDLE's goals and scienfific challenges centre around the desire to increase the reach of interactive deep learning solutions for non-experts in machine learning. One of the key innovations described in this technical report is a methodology for interactive machine learning combined with multimodal interaction which will become central when we start interacting with semi-intelligent machines in the upcoming area of neural networks and large language models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SimpleFusion: A Simple Fusion Framework for Infrared and Visible Images", "authors": "Ming Chen, Yuxuan Cheng, Xinwei He, Xinyue Wang, Yan Aze, Jinhai Xiang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Integrating visible and infrared images into one high-quality image, also known as visible and infrared image fusion, is a challenging yet critical task for many downstream vision tasks. Most existing works utilize pretrained deep neural networks or design sophisticated frameworks with strong priors for this task, which may be unsuitable or lack flexibility. This paper presents SimpleFusion, a simple yet effective framework for visible and infrared image fusion. Our framework follows the decompose-and-fusion paradigm, where the visible and the infrared images are decomposed into reflectance and illumination components via Retinex theory and followed by the fusion of these corresponding elements. The whole framework is designed with two plain convolutional neural networks without downsampling, which can perform image decomposition and fusion efficiently. Moreover, we introduce decomposition loss and a detail-to-semantic loss to preserve the complementary information between the two modalities for fusion. We conduct extensive experiments on the challenging benchmarks, verifying the superiority of our method over previous state-of-the-arts. Code is available at \\href{this https URL}{this https URL}"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO", "authors": "Fuseini Mumuni, Alhassan Mumuni", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)", "abstract": "Grounding DINO and the Segment Anything Model (SAM) have achieved impressive performance in zero-shot object detection and image segmentation, respectively. Together, they have a great potential in revolutionizing zero-shot semantic segmentation or data annotation. Yet, in specialized domains like medical image segmentation, objects of interest (e.g., organs, tissues, and tumors) may not fall in existing class names. To address this problem, the referring expression comprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary targets by their language descriptions. However, recent studies have highlighted severe limitation of the REC framework in this application setting owing to its tendency to make false positive predictions when the target is absent in the given image. And, while this bottleneck is central to the prospect of open-set semantic segmentation, it is still largely unknown how much improvement can be achieved by studying the prediction errors. To this end, we perform empirical studies on eight publicly available datasets and reveal that these errors consistently follow a predictable pattern and can, thus, be mitigated by a simple strategy. Specifically, we show that these false positive detections with appreciable confidence scores generally occupy large image areas and can usually be filtered by their relative sizes. More importantly, we expect these observations to inspire future research in improving REC-based detection and automated segmentation. Using this technique, we evaluate the performance of SAM on multiple datasets from various specialized domains and report significant improvement in segmentation performance and annotation time savings over manual approaches."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Distributed Utility Optimization in Vehicular Communication Systems", "authors": "Miguel A. Diaz-Ibarra, Daniel U. Campos-Delgado, Carlos A. Gutierrez, Jose M. Luna-Rivera, Francisco J. Cabrera-Almeida", "subjects": "Subjects:\nSystems and Control (eess.SY)", "abstract": "In this paper, we study the problem of utility maximization in the uplink of vehicle-to-infrastructure communication systems. The studied scenarios consider four practical aspects of mobile radio communication links: i) Interference between adjacent channels, ii) interference between roadside units along the way, iii) fast and slow channel fadings, and iv) Doppler shift effects. We present first the system model for the IEEE 802.11p standard, which considers a communication network between vehicles and roadside infrastructure. Next, we formulate the problem of utility maximization in the network, and propose a distributed optimization scheme. This distributed scheme is based on a two-loop feedback configuration, where an outer-loop establishes the optimal signal to interference-noise ratio (SINR) that maximizes the utility function per vehicle and defines a quality-of-service objective. Meanwhile, inner-control loops adjust the transmission power to achieve this optimal SINR reference in each vehicle node regardless of interference, time-varying channel profiles and network latency. The computation complexity of the distributed utility maximization scheme is analyzed for each feedback loop. Simulation results indicate that the proposed scheme reaches the objective SINRs that maximize utility and improve energy efficiency in the network with a low time cost. The results also show that the maximum utility is consistently achieved for different propagation scenarios inside the vehicular communication network."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis", "authors": "Wenbin Li, Di Yao, Ruibo Zhao, Wenjie Chen, Zijie Xu, Chengxue Luo, Chang Gong, Quanliang Jing, Haining Tan, Jingping Bi", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "The rapid evolution of large language models (LLMs) holds promise for reforming the methodology of spatio-temporal data mining. However, current works for evaluating the spatio-temporal understanding capability of LLMs are somewhat limited and biased. These works either fail to incorporate the latest language models or only focus on assessing the memorized spatio-temporal knowledge. To address this gap, this paper dissects LLMs' capability of spatio-temporal data into four distinct dimensions: knowledge comprehension, spatio-temporal reasoning, accurate computation, and downstream applications. We curate several natural language question-answer tasks for each category and build the benchmark dataset, namely STBench, containing 13 distinct tasks and over 60,000 QA pairs. Moreover, we have assessed the capabilities of 13 LLMs, such as GPT-4o, Gemma and Mistral. Experimental results reveal that existing LLMs show remarkable performance on knowledge comprehension and spatio-temporal reasoning tasks, with potential for further enhancement on other tasks through in-context learning, chain-of-though prompting, and fine-tuning. The code and datasets of STBench are released on this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Dancing in the Shadows: Harnessing Ambiguity for Fairer Classifiers", "authors": "Ainhize Barrainkua, Paula Gordaliza, Jose A. Lozano, Novi Quadrianto", "subjects": "Subjects:\nMachine Learning (cs.LG); Computers and Society (cs.CY)", "abstract": "This paper introduces a novel approach to bolster algorithmic fairness in scenarios where sensitive information is only partially known. In particular, we propose to leverage instances with uncertain identity with regards to the sensitive attribute to train a conventional machine learning classifier. The enhanced fairness observed in the final predictions of this classifier highlights the promising potential of prioritizing ambiguity (i.e., non-normativity) as a means to improve fairness guarantees in real-world classification tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FAGhead: Fully Animate Gaussian Head from Monocular Videos", "authors": "Yixin Xuan, Xinyang Li, Gongxin Yao, Shiwei Zhou, Donghui Sun, Xiaoxin Chen, Yu Pan", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "High-fidelity reconstruction of 3D human avatars has a wild application in visual reality. In this paper, we introduce FAGhead, a method that enables fully controllable human portraits from monocular videos. We explicit the traditional 3D morphable meshes (3DMM) and optimize the neutral 3D Gaussians to reconstruct with complex expressions. Furthermore, we employ a novel Point-based Learnable Representation Field (PLRF) with learnable Gaussian point positions to enhance reconstruction performance. Meanwhile, to effectively manage the edges of avatars, we introduced the alpha rendering to supervise the alpha value of each pixel. Extensive experimental results on the open-source datasets and our capturing datasets demonstrate that our approach is able to generate high-fidelity 3D head avatars and fully control the expression and pose of the virtual avatars, which is outperforming than existing works."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          EmPO: Theory-Driven Dataset Construction for Empathetic Response Generation through Preference Optimization", "authors": "Ondrej Sotolar", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Empathetic response generation is a desirable aspect of conversational agents, crucial for facilitating engaging and emotionally intelligent multi-turn conversations between humans and machines. Leveraging large language models for this task has shown promising results, yet challenges persist in ensuring both the empathetic quality of the responses and retention of the generalization performance of the models. In this paper, we propose a novel approach where we construct theory-driven preference datasets and use them to align LLMs with preference optimization algorithms to address these challenges. To measure empathetic response generation, we employ the EmpatheticDialogues dataset, assessing empathy with the diff-EPITOME and BERTscore metrics, and evaluate the generalization performance on the MMLU benchmark. We make all datasets, source code, and models publicly available."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AMBROSIA: A Benchmark for Parsing Ambiguous Questions into Database Queries", "authors": "Irina Saparina, Mirella Lapata", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Practical semantic parsers are expected to understand user utterances and map them to executable programs, even when these are ambiguous. We introduce a new benchmark, AMBROSIA, which we hope will inform and inspire the development of text-to-SQL parsers capable of recognizing and interpreting ambiguous requests. Our dataset contains questions showcasing three different types of ambiguity (scope ambiguity, attachment ambiguity, and vagueness), their interpretations, and corresponding SQL queries. In each case, the ambiguity persists even when the database context is provided. This is achieved through a novel approach that involves controlled generation of databases from scratch. We benchmark various LLMs on AMBROSIA, revealing that even the most advanced models struggle to identify and interpret ambiguity in questions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Parameter Dependent Chen--Fliess Series and Their Nonrecursive Interconnections", "authors": "W. Steven Gray, Natalie Pham", "subjects": "Subjects:\nSystems and Control (eess.SY)", "abstract": "A class of parameter dependent Chen--Fliess series is introduced where the series coefficients are taken from a noncommutative ring of multivariable differential operators. Such series are shown in the linear case to represent formal solutions to Cauchy initial value problems for nonhomogeneous PDEs and thus are useful for characterizing the input-output maps of distributed control systems. It is also shown that this class of functional series is almost closed under the set of nonrecursive interconnections, that is, any finite combination of parallel and series interconnections without a closed-loop. Some sufficient conditions are needed for the series interconnection. Specific examples are given involving the transport equation and the wave equation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Spatial Multiplexing in Near-Field Line-of-Sight MIMO Communications: Paraxial and Non-Paraxial Deployments", "authors": "Juan Carlos Ruiz-Sicilia, Marco Di Renzo, Placido Mursia, Aryan Kaushik, Vincenzo Sciancalepore", "subjects": "Subjects:\nInformation Theory (cs.IT); Signal Processing (eess.SP)", "abstract": "Sixth generation (6G) wireless networks are envisioned to include aspects of energy footprint reduction (sustainability), besides those of network capacity and connectivity, at the design stage. This paradigm change requires radically new physical layer technologies. Notably, the integration of large-aperture arrays and the transmission over high frequency bands, such as the sub-terahertz spectrum, are two promising options. In many communication scenarios of practical interest, the use of large antenna arrays in the sub-terahertz frequency range often results in short-range transmission distances that are characterized by line-of-sight channels, in which pairs of transmitters and receivers are located in the (radiating) near field of one another. These features make the traditional designs, based on the far-field approximation, for multiple-input multiple-output (MIMO) systems sub-optimal in terms of spatial multiplexing gains. To overcome these limitations, new designs for MIMO systems are required, which account for the spherical wavefront that characterizes the electromagnetic waves in the near field, in order to ensure the highest spatial multiplexing gain without increasing the power expenditure. In this paper, we introduce an analytical framework for optimizing the deployment of antenna arrays in line-of-sight channels, which can be applied to paraxial and non-paraxial network deployments. In the paraxial setting, we devise a simpler analytical framework, which, compared to those available in the literature, provides explicit information about the impact of key design parameters. In the non-paraxial setting, we introduce a novel analytical framework that allows us to identify a set of sufficient conditions to be fulfilled for achieving the highest spatial multiplexing gain. The proposed designs are validated with numerical simulations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Dimensions underlying the representational alignment of deep neural networks with humans", "authors": "Florian P. Mahner, Lukas Muttenthaler, Umut G\u00fc\u00e7l\u00fc, Martin N. Hebart", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)", "abstract": "Determining the similarities and differences between humans and artificial intelligence is an important goal both in machine learning and cognitive neuroscience. However, similarities in representations only inform us about the degree of alignment, not the factors that determine it. Drawing upon recent developments in cognitive science, we propose a generic framework for yielding comparable representations in humans and deep neural networks (DNN). Applying this framework to humans and a DNN model of natural images revealed a low-dimensional DNN embedding of both visual and semantic dimensions. In contrast to humans, DNNs exhibited a clear dominance of visual over semantic features, indicating divergent strategies for representing images. While in-silico experiments showed seemingly-consistent interpretability of DNN dimensions, a direct comparison between human and DNN representations revealed substantial differences in how they process images. By making representations directly comparable, our results reveal important challenges for representational alignment, offering a means for improving their comparability."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SubLock: Sub-Circuit Replacement based Input Dependent Key-based Logic Locking for Robust IP Protection", "authors": "Vijaypal Singh Rathor, Munesh Singh, Kshira Sagar Sahoo, Saraju P. Mohanty", "subjects": "Subjects:\nCryptography and Security (cs.CR)", "abstract": "Intellectual Property (IP) piracy, overbuilding, reverse engineering, and hardware Trojan are serious security concerns during integrated circuit (IC) development. Logic locking has proven to be a solid defence for mitigating these threats. The existing logic locking techniques are vulnerable to SAT-based attacks. However, several SAT-resistant logic locking methods are reported; they require significant overhead. This paper proposes a novel input dependent key-based logic locking (IDKLL) that effectively prevents SAT-based attacks with low overhead. We first introduce a novel idea of IDKLL, where a design is locked such that it functions correctly for all input patterns only when their corresponding valid key sequences are applied. In contrast to conventional logic locking, the proposed IDKLL method uses multiple key sequences (instead of a single key sequence) as a valid key that provides correct functionality for all inputs. Further, we propose a sub-circuit replacement based IDKLL approach called SubLock that locks the design by replacing the original sub-circuitry with the corresponding IDKLL based locked circuit to prevent SAT attack with low overhead. The experimental evaluation on ISCAS benchmarks shows that the proposed SubLock mitigates the SAT attack with high security and reduced overhead over the well-known existing methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Adaptive Stochastic Weight Averaging", "authors": "Caglar Demir, Arnab Sharma, Axel-Cyrille Ngonga Ngomo", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Ensemble models often improve generalization performances in challenging tasks. Yet, traditional techniques based on prediction averaging incur three well-known disadvantages: the computational overhead of training multiple models, increased latency, and memory requirements at test time. To address these issues, the Stochastic Weight Averaging (SWA) technique maintains a running average of model parameters from a specific epoch onward. Despite its potential benefits, maintaining a running average of parameters can hinder generalization, as an underlying running model begins to overfit. Conversely, an inadequately chosen starting point can render SWA more susceptible to underfitting compared to an underlying running model. In this work, we propose Adaptive Stochastic Weight Averaging (ASWA) technique that updates a running average of model parameters, only when generalization performance is improved on the validation dataset. Hence, ASWA can be seen as a combination of SWA with the early stopping technique, where the former accepts all updates on a parameter ensemble model and the latter rejects any update on an underlying running model. We conducted extensive experiments ranging from image classification to multi-hop reasoning over knowledge graphs. Our experiments over 11 benchmark datasets with 7 baseline models suggest that ASWA leads to a statistically better generalization across models and datasets"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Understanding the Security Benefits and Overheads of Emerging Industry Solutions to DRAM Read Disturbance", "authors": "O\u011fuzhan Canpolat, A. Giray Ya\u011fl\u0131k\u00e7\u0131, Geraldo F. Oliveira, Ataberk Olgun, O\u011fuz Ergin, Onur Mutlu", "subjects": "Subjects:\nCryptography and Security (cs.CR); Hardware Architecture (cs.AR)", "abstract": "We present the first rigorous security, performance, energy, and cost analyses of the state-of-the-art on-DRAM-die read disturbance mitigation method, Per Row Activation Counting (PRAC), described in JEDEC DDR5 specification's April 2024 update. Unlike prior state-of-the-art that advises the memory controller to periodically issue refresh management (RFM) commands, which provides the DRAM chip with time to perform refreshes, PRAC introduces a new back-off signal. PRAC's back-off signal propagates from the DRAM chip to the memory controller and forces the memory controller to 1) stop serving requests and 2) issue RFM commands. As a result, RFM commands are issued when needed as opposed to periodically, reducing RFM's overheads. We analyze PRAC in four steps. First, we define an adversarial access pattern that represents the worst-case for PRAC's security. Second, we investigate PRAC's configurations and security implications. Our analyses show that PRAC can be configured for secure operation as long as no bitflip occurs before accessing a memory location 10 times. Third, we evaluate the performance impact of PRAC and compare it against prior works using Ramulator 2.0. Our analysis shows that while PRAC incurs less than 13.4% performance overhead for today's DRAM chips, its performance overheads can reach up to 63.2% for future DRAM chips that are more vulnerable to read disturbance bitflips. Fourth, we define an availability adversarial access pattern that exacerbates PRAC's performance overhead to perform a memory performance attack, demonstrating that such an adversarial pattern can hog up to 79% of DRAM throughput and degrade system throughput by up to 65%. We discuss PRAC's implications on future systems and foreshadow future research directions. To aid future research, we open-source our implementations and scripts at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          In-situ Controller Autotuning by Bayesian Optimization for Closed-loop Feedback Control of Laser Powder Bed Fusion Process", "authors": "Baris Kavas, Efe C. Balta, Michael R. Tucker, Raamadaas Krishnadas, Alisa Rupenyan, John Lygeros, Markus Bambach", "subjects": "Subjects:\nSystems and Control (eess.SY)", "abstract": "Open-loop control of laser powder bed fusion (LPBF) additive manufacturing (AM) has enabled the production of complex, high-criticality parts for various industries. This method relies on static parameter sets from extensive experimentation and simulations, hoping they remain stable and defect-free in production. Closed-loop control of LPBF can further enhance process stability and reduce defects despite complex thermal histories, process noise, hardware drift, and unexpected perturbations. Controller performance depends on parameter tuning, traditionally a manual, expertise-driven process with no guarantee of optimal performance and limited transferability between systems. This study proposes Bayesian Optimization (BO) to automate in-layer controller tuning by leveraging LPBF's layer-to-layer repetitive nature. Two approaches are introduced: online tuning, adjusting parameters iteratively during the process, and offline tuning, conducted in a setup such as laser exposures on a bare metal plate. These methods are experimentally implemented on an in-layer PI controller, and the performance is investigated on two wedge geometries prone to overheating. Results show that BO effectively tunes controllers using either method, significantly reducing overheating in controlled wedge specimens compared to uncontrolled ones. This study presents the first printed parts controlled by an in-layer controller subjected to microstructural analysis. Findings reveal partial presence of lack-of-fusion porosities due to insufficient laser power assigned by the controller, highlighting a significant challenge for utilizing laser power controllers. In summary, BO presents a promising method for automatic in-layer controller tuning in LPBF, enhancing control precision and mitigating overheating in production parts."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fairness and Bias in Multimodal AI: A Survey", "authors": "Tosin Adewumi, Lama Alkhaled, Namrata Gurung, Goya van Boven, Irene Pagliai", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "The importance of addressing fairness and bias in artificial intelligence (AI) systems cannot be over-emphasized. Mainstream media has been awashed with news of incidents around stereotypes and bias in many of these systems in recent years. In this survey, we fill a gap with regards to the minimal study of fairness and bias in Large Multimodal Models (LMMs) compared to Large Language Models (LLMs), providing 50 examples of datasets and models along with the challenges affecting them; we identify a new category of quantifying bias (preuse), in addition to the two well-known ones in the literature: intrinsic and extrinsic; we critically discuss the various ways researchers are addressing these challenges. Our method involved two slightly different search queries on Google Scholar, which revealed that 33,400 and 538,000 links are the results for the terms \"Fairness and bias in Large Multimodal Models\" and \"Fairness and bias in Large Language Models\", respectively. We believe this work contributes to filling this gap and providing insight to researchers and other stakeholders on ways to address the challenge of fairness and bias in multimodal A!."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DocKylin: A Large Multimodal Model for Visual Document Understanding with Efficient Visual Slimming", "authors": "Jiaxin Zhang, Wentao Yang, Songxuan Lai, Zecheng Xie, Lianwen Jin", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Current multimodal large language models (MLLMs) face significant challenges in visual document understanding (VDU) tasks due to the high resolution, dense text, and complex layouts typical of document images. These characteristics demand a high level of detail perception ability from MLLMs. While increasing input resolution improves detail perception, it also leads to longer sequences of visual tokens, increasing computational costs and straining the models' ability to handle long contexts. To address these challenges, we introduce DocKylin, a document-centric MLLM that performs visual content slimming at both the pixel and token levels, thereby reducing token sequence length in VDU scenarios. DocKylin utilizes an Adaptive Pixel Slimming (APS) preprocessing module to perform pixel-level slimming, increasing the proportion of informative pixels. Moreover, DocKylin incorporates a novel Dynamic Token Slimming (DTS) module to conduct token-level slimming, filtering essential tokens and removing others to create a compressed, adaptive visual sequence. Experiments demonstrate DocKylin's promising performance across various VDU benchmarks. Notably, both the proposed APS and DTS are parameter-free, facilitating easy integration into existing MLLMs, and our experiments indicate their potential for broader applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Statements: Universal Information Extraction from Tables with Large Language Models for ESG KPIs", "authors": "Lokesh Mishra, Sohayl Dhibi, Yusik Kim, Cesar Berrospi Ramis, Shubham Gupta, Michele Dolfi, Peter Staar", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "abstract": "Environment, Social, and Governance (ESG) KPIs assess an organization's performance on issues such as climate change, greenhouse gas emissions, water consumption, waste management, human rights, diversity, and policies. ESG reports convey this valuable quantitative information through tables. Unfortunately, extracting this information is difficult due to high variability in the table structure as well as content. We propose Statements, a novel domain agnostic data structure for extracting quantitative facts and related information. We propose translating tables to statements as a new supervised deep-learning universal information extraction task. We introduce SemTabNet - a dataset of over 100K annotated tables. Investigating a family of T5-based Statement Extraction Models, our best model generates statements which are 82% similar to the ground-truth (compared to baseline of 21%). We demonstrate the advantages of statements by applying our model to over 2700 tables from ESG reports. The homogeneous nature of statements permits exploratory data analysis on expansive information found in large collections of ESG reports."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MINE GRAPH RULE: A New Cypher-like Operator for Mining Association Rules on Property Graphs", "authors": "Francesco Cambria, Francesco Invernici, Anna Bernasconi, Stefano Ceri", "subjects": "Subjects:\nDatabases (cs.DB)", "abstract": "Mining information from graph databases is becoming overly important. To approach this problem, current methods focus on identifying subgraphs with specific topologies; as of today, no work has been focused on expressing jointly the syntax and semantics of mining operations over rich property graphs. We define MINE GRAPH RULE, a new operator for mining association rules from graph databases, by extending classical approaches used in relational databases and exploited by recommending systems. We describe the syntax and semantics of the operator, which is based on measuring the support and confidence of each rule, and then we provide several examples of increasing complexity on top of a realistic example; our operator embeds Cypher for expressing the mining conditions. MINE GRAPH RULE is implemented on top of Neo4j, the most successful graph database system; it takes advantage of built-in optimizations of the Neo4j engine, as well as optimizations that are defined in the context of relational association rules. Our implementation is available as a portable Neo4j plugin. At the end of our paper, we show the execution performance in a variety of settings, by varying the operators, the size of the graph, the ratio between node types, the method for creating relationships, and maximum support and confidence."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FDLite: A Single Stage Lightweight Face Detector Network", "authors": "Yogesh Aggarwal, Prithwijit Guha", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Face detection is frequently attempted by using heavy pre-trained backbone networks like ResNet-50/101/152 and VGG16/19. Few recent works have also proposed lightweight detectors with customized backbones, novel loss functions and efficient training strategies. The novelty of this work lies in the design of a lightweight detector while training with only the commonly used loss functions and learning strategies. The proposed face detector grossly follows the established RetinaFace architecture. The first contribution of this work is the design of a customized lightweight backbone network (BLite) having 0.167M parameters with 0.52 GFLOPs. The second contribution is the use of two independent multi-task losses. The proposed lightweight face detector (FDLite) has 0.26M parameters with 0.94 GFLOPs. The network is trained on the WIDER FACE dataset. FDLite is observed to achieve 92.3\\%, 89.8\\%, and 82.2\\% Average Precision (AP) on the easy, medium, and hard subsets of the WIDER FACE validation dataset, respectively."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Computational Life: How Well-formed, Self-replicating Programs Emerge from Simple Interaction", "authors": "Blaise Ag\u00fcera y Arcas, Jyrki Alakuijala, James Evans, Ben Laurie, Alexander Mordvintsev, Eyvind Niklasson, Ettore Randazzo, Luca Versari", "subjects": "Subjects:\nNeural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI)", "abstract": "The fields of Origin of Life and Artificial Life both question what life is and how it emerges from a distinct set of \"pre-life\" dynamics. One common feature of most substrates where life emerges is a marked shift in dynamics when self-replication appears. While there are some hypotheses regarding how self-replicators arose in nature, we know very little about the general dynamics, computational principles, and necessary conditions for self-replicators to emerge. This is especially true on \"computational substrates\" where interactions involve logical, mathematical, or programming rules. In this paper we take a step towards understanding how self-replicators arise by studying several computational substrates based on various simple programming languages and machine instruction sets. We show that when random, non self-replicating programs are placed in an environment lacking any explicit fitness landscape, self-replicators tend to arise. We demonstrate how this occurs due to random interactions and self-modification, and can happen with and without background random mutations. We also show how increasingly complex dynamics continue to emerge following the rise of self-replicators. Finally, we show a counterexample of a minimalistic programming language where self-replicators are possible, but so far have not been observed to arise."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Teacher Is Worth A Million Instructions", "authors": "Nikhil Kothari, Ravindra Nayak, Shreyas Shetty, Amey Patil, Nikesh Garera", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Large Language Models(LLMs) have shown exceptional abilities, yet training these models can be quite challenging. There is a strong dependence on the quality of data and finding the best instruction tuning set. Further, the inherent limitations in training methods create substantial difficulties to train relatively smaller models with 7B and 13B parameters. In our research, we suggest an improved training method for these models by utilising knowledge from larger models, such as a mixture of experts (8x7B) architectures. The scale of these larger models allows them to capture a wide range of variations from data alone, making them effective teachers for smaller models. Moreover, we implement a novel post-training domain alignment phase that employs domain-specific expert models to boost domain-specific knowledge during training while preserving the model's ability to generalise. Fine-tuning Mistral 7B and 2x7B with our method surpasses the performance of state-of-the-art language models with more than 7B and 13B parameters: achieving up to $7.9$ in MT-Bench and $93.04\\%$ on AlpacaEval."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MegIS: High-Performance, Energy-Efficient, and Low-Cost Metagenomic Analysis with In-Storage Processing", "authors": "Nika Mansouri Ghiasi, Mohammad Sadrosadati, Harun Mustafa, Arvid Gollwitzer, Can Firtina, Julien Eudine, Haiyu Mao, Jo\u00ebl Lindegger, Meryem Banu Cavlak, Mohammed Alser, Jisung Park, Onur Mutlu", "subjects": "Subjects:\nHardware Architecture (cs.AR); Distributed, Parallel, and Cluster Computing (cs.DC); Genomics (q-bio.GN)", "abstract": "Metagenomics has led to significant advances in many fields. Metagenomic analysis commonly involves the key tasks of determining the species present in a sample and their relative abundances. These tasks require searching large metagenomic databases. Metagenomic analysis suffers from significant data movement overhead due to moving large amounts of low-reuse data from the storage system. In-storage processing can be a fundamental solution for reducing this overhead. However, designing an in-storage processing system for metagenomics is challenging because existing approaches to metagenomic analysis cannot be directly implemented in storage effectively due to the hardware limitations of modern SSDs. We propose MegIS, the first in-storage processing system designed to significantly reduce the data movement overhead of the end-to-end metagenomic analysis pipeline. MegIS is enabled by our lightweight design that effectively leverages and orchestrates processing inside and outside the storage system. We address in-storage processing challenges for metagenomics via specialized and efficient 1) task partitioning, 2) data/computation flow coordination, 3) storage technology-aware algorithmic optimizations, 4) data mapping, and 5) lightweight in-storage accelerators. MegIS's design is flexible, capable of supporting different types of metagenomic input datasets, and can be integrated into various metagenomic analysis pipelines. Our evaluation shows that MegIS outperforms the state-of-the-art performance- and accuracy-optimized software metagenomic tools by 2.7$\\times$-37.2$\\times$ and 6.9$\\times$-100.2$\\times$, respectively, while matching the accuracy of the accuracy-optimized tool. MegIS achieves 1.5$\\times$-5.1$\\times$ speedup compared to the state-of-the-art metagenomic hardware-accelerated (using processing-in-memory) tool, while achieving significantly higher accuracy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CHEW: A Dataset of CHanging Events in Wikipedia", "authors": "Hsuvas Borkakoty, Luis Espinosa-Anke", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "We introduce CHEW, a novel dataset of changing events in Wikipedia expressed in naturally occurring text. We use CHEW for probing LLMs for their timeline understanding of Wikipedia entities and events in generative and classification experiments. Our results suggest that LLMs, despite having temporal information available, struggle to construct accurate timelines. We further show the usefulness of CHEW-derived embeddings for identifying meaning shift."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Learning Abductive Reasoning using VSA Distributed Representations", "authors": "Giacomo Camposampiero, Michael Hersche, Aleksandar Terzi\u0107, Roger Wattenhofer, Abu Sebastian, Abbas Rahimi", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Symbolic Computation (cs.SC)", "abstract": "We introduce the Abductive Rule Learner with Context-awareness (ARLC), a model that solves abstract reasoning tasks based on Learn-VRF. ARLC features a novel and more broadly applicable training objective for abductive reasoning, resulting in better interpretability and higher accuracy when solving Raven's progressive matrices (RPM). ARLC allows both programming domain knowledge and learning the rules underlying a data distribution. We evaluate ARLC on the I-RAVEN dataset, showcasing state-of-the-art accuracy across both in-distribution and out-of-distribution (unseen attribute-rule pairs) tests. ARLC surpasses neuro-symbolic and connectionist baselines, including large language models, despite having orders of magnitude fewer parameters. We show ARLC's robustness to post-programming training by incrementally learning from examples on top of programmed knowledge, which only improves its performance and does not result in catastrophic forgetting of the programmed solution. We validate ARLC's seamless transfer learning from a 2x2 RPM constellation to unseen constellations. Our code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Evidential Concept Embedding Models: Towards Reliable Concept Explanations for Skin Disease Diagnosis", "authors": "Yibo Gao, Zheyao Gao, Xin Gao, Yuanye Liu, Bomin Wang, Xiahai Zhuang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Due to the high stakes in medical decision-making, there is a compelling demand for interpretable deep learning methods in medical image analysis. Concept Bottleneck Models (CBM) have emerged as an active interpretable framework incorporating human-interpretable concepts into decision-making. However, their concept predictions may lack reliability when applied to clinical diagnosis, impeding concept explanations' quality. To address this, we propose an evidential Concept Embedding Model (evi-CEM), which employs evidential learning to model the concept uncertainty. Additionally, we offer to leverage the concept uncertainty to rectify concept misalignments that arise when training CBMs using vision-language models without complete concept supervision. With the proposed methods, we can enhance concept explanations' reliability for both supervised and label-efficient settings. Furthermore, we introduce concept uncertainty for effective test-time intervention. Our evaluation demonstrates that evi-CEM achieves superior performance in terms of concept prediction, and the proposed concept rectification effectively mitigates concept misalignments for label-efficient training. Our code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CELLO: Causal Evaluation of Large Vision-Language Models", "authors": "Meiqi Chen, Bo Peng, Yan Zhang, Chaochao Lu", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Causal reasoning is fundamental to human intelligence and crucial for effective decision-making in real-world environments. Despite recent advancements in large vision-language models (LVLMs), their ability to comprehend causality remains unclear. Previous work typically focuses on commonsense causality between events and/or actions, which is insufficient for applications like embodied agents and lacks the explicitly defined causal graphs required for formal causal reasoning. To overcome these limitations, we introduce a fine-grained and unified definition of causality involving interactions between humans and/or objects. Building on the definition, we construct a novel dataset, CELLO, consisting of 14,094 causal questions across all four levels of causality: discovery, association, intervention, and counterfactual. This dataset surpasses traditional commonsense causality by including explicit causal graphs that detail the interactions between humans and objects. Extensive experiments on CELLO reveal that current LVLMs still struggle with causal reasoning tasks, but they can benefit significantly from our proposed CELLO-CoT, a causally inspired chain-of-thought prompting strategy. Both quantitative and qualitative analyses from this study provide valuable insights for future research. Our project page is at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cuts in Graphs with Matroid Constraints", "authors": "Aritra Banik, Fedor V. Fomin, Petr A. Golovach, Tanmay Inamdar, Satyabrata Jana, Saket Saurabh", "subjects": "Subjects:\nDiscrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)", "abstract": "{\\sc Vertex $(s, t)$-Cut} and {\\sc Vertex Multiway Cut} are two fundamental graph separation problems in algorithmic graph theory. We study matroidal generalizations of these problems, where in addition to the usual input, we are given a representation $R \\in \\mathbb{F}^{r \\times n}$ of a linear matroid $\\mathcal{M} = (V(G), \\mathcal{I})$ of rank $r$ in the input, and the goal is to determine whether there exists a vertex subset $S \\subseteq V(G)$ that has the required cut properties, as well as is independent in the matroid $\\mathcal{M}$. We refer to these problems as {\\sc Independent Vertex $(s, t)$-cut}, and {\\sc Independent Multiway Cut}, respectively. We show that these problems are fixed-parameter tractable ({\\sf FPT}) when parameterized by the solution size (which can be assumed to be equal to the rank of the matroid $\\mathcal{M}$). These results are obtained by exploiting the recent technique of flow augmentation [Kim et al.~STOC '22], combined with a dynamic programming algorithm on flow-paths \u00e1 la [Feige and Mahdian,~STOC '06] that maintains a representative family of solutions w.r.t.~the given matroid [Marx, TCS '06; Fomin et al., JACM]. As a corollary, we also obtain {\\sf FPT} algorithms for the independent version of {\\sc Odd Cycle Transversal}. Further, our results can be generalized to other variants of the problems, e.g., weighted versions, or edge-deletion versions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          YZS-model: A Predictive Model for Organic Drug Solubility Based on Graph Convolutional Networks and Transformer-Attention", "authors": "Chenxu Wang, Haowei Ming, Jian He, Yao Lu", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "The accurate prediction of drug molecule solubility is essential for determining their therapeutic effectiveness and safety, influencing the drug's ADME processes. Traditional solubility prediction techniques often fail to capture the complex nature of molecular tructures, leading to notable deviations between predictions and actual results. For example, the Discussion on Advanced Drug-Like Compound Structures. Lusci highlighted issues in capturing crucial cyclic structural information in molecules with ring structures. To overcome this issue, our research introduces a novel deep learning framework combining attention-based transformers, Long Short-Term Memory (LSTM) networks, and Graph Convolutional Networks (GCN), aimed at enhancing the precision of solubility predictions. Utilizing a training set of 9,943 compounds and testing on an anticancer compound dataset, our method achieved a correlation coefficient ($R^2$) of 0.55 and a Root Mean Square Error (RMSE) of 0.59, which outperforms the benchmark models' scores of 0.52 ($R^2$) and 0.61 (RMSE). Importantly, in an additional independent test, our model significantly outperformed the baseline with an RMSE of 1.05 compared to 1.28, a relative accuracy improvement of 45.9%. This research not only demonstrates the vast potential of deep learning for improving solubility prediction accuracy but also offers novel insights for drug design and selection in the future. Continued efforts will be directed towards optimizing the model architecture and extending its application to better support the drug development process, underscoring the pivotal role of deep learning in drug discovery."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          QSketch: An Efficient Sketch for Weighted Cardinality Estimation in Streams", "authors": "Yiyan Qi, Rundong Li, Pinghui Wang, Yufang Sun, Rui Xing", "subjects": "Subjects:\nDatabases (cs.DB); Data Structures and Algorithms (cs.DS)", "abstract": "Estimating cardinality, i.e., the number of distinct elements, of a data stream is a fundamental problem in areas like databases, computer networks, and information retrieval. This study delves into a broader scenario where each element carries a positive weight. Unlike traditional cardinality estimation, limited research exists on weighted cardinality, with current methods requiring substantial memory and computational resources, challenging for devices with limited capabilities and real-time applications like anomaly detection. To address these issues, we propose QSketch, a memory-efficient sketch method for estimating weighted cardinality in streams. QSketch uses a quantization technique to condense continuous variables into a compact set of integer variables, with each variable requiring only 8 bits, making it 8 times smaller than previous methods. Furthermore, we leverage dynamic properties during QSketch generation to significantly enhance estimation accuracy and achieve a lower time complexity of $O(1)$ for updating estimations upon encountering a new element. Experimental results on synthetic and real-world datasets show that QSketch is approximately 30\\% more accurate and two orders of magnitude faster than the state-of-the-art, using only $1/8$ of the memory."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Resolving Discrepancies in Compute-Optimal Scaling of Language Models", "authors": "Tomer Porian, Mitchell Wortsman, Jenia Jitsev, Ludwig Schmidt, Yair Carmon", "subjects": "Subjects:\nMachine Learning (cs.LG); Computation and Language (cs.CL)", "abstract": "Kaplan et al. and Hoffmann et al. developed influential scaling laws for the optimal model size as a function of the compute budget, but these laws yield substantially different predictions. We explain the discrepancy by reproducing the Kaplan scaling law on two datasets (OpenWebText2 and RefinedWeb) and identifying three factors causing the difference: last layer computational cost, warmup duration, and scale-dependent optimizer tuning. With these factors corrected, we obtain excellent agreement with the Hoffmann et al. (i.e., \"Chinchilla\") scaling law. Counter to a hypothesis of Hoffmann et al., we find that careful learning rate decay is not essential for the validity of their scaling law. As a secondary result, we derive scaling laws for the optimal learning rate and batch size, finding that tuning the AdamW $\\beta_2$ parameter is essential at lower batch sizes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          BackMix: Mitigating Shortcut Learning in Echocardiography with Minimal Supervision", "authors": "Kit Mills Bransby, Arian Beqiri, Woo-Jin Cho Kim, Jorge Oliveira, Agisilaos Chartsias, Alberto Gomez", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Neural networks can learn spurious correlations that lead to the correct prediction in a validation set, but generalise poorly because the predictions are right for the wrong reason. This undesired learning of naive shortcuts (Clever Hans effect) can happen for example in echocardiogram view classification when background cues (e.g. metadata) are biased towards a class and the model learns to focus on those background features instead of on the image content. We propose a simple, yet effective random background augmentation method called BackMix, which samples random backgrounds from other examples in the training set. By enforcing the background to be uncorrelated with the outcome, the model learns to focus on the data within the ultrasound sector and becomes invariant to the regions outside this. We extend our method in a semi-supervised setting, finding that the positive effects of BackMix are maintained with as few as 5% of segmentation labels. A loss weighting mechanism, wBackMix, is also proposed to increase the contribution of the augmented examples. We validate our method on both in-distribution and out-of-distribution datasets, demonstrating significant improvements in classification accuracy, region focus and generalisability. Our source code is available at: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RAVEN: Multitask Retrieval Augmented Vision-Language Learning", "authors": "Varun Nagaraj Rao, Siddharth Choudhary, Aditya Deshpande, Ravi Kumar Satzoda, Srikar Appalaraju", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "abstract": "The scaling of large language models to encode all the world's knowledge in model parameters is unsustainable and has exacerbated resource barriers. Retrieval-Augmented Generation (RAG) presents a potential solution, yet its application to vision-language models (VLMs) is under explored. Existing methods focus on models designed for single tasks. Furthermore, they're limited by the need for resource intensive pre training, additional parameter requirements, unaddressed modality prioritization and lack of clear benefit over non-retrieval baselines. This paper introduces RAVEN, a multitask retrieval augmented VLM framework that enhances base VLMs through efficient, task specific fine-tuning. By integrating retrieval augmented samples without the need for additional retrieval-specific parameters, we show that the model acquires retrieval properties that are effective across multiple tasks. Our results and extensive ablations across retrieved modalities for the image captioning and VQA tasks indicate significant performance improvements compared to non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a +3\\% accuracy on specific VQA question types. This underscores the efficacy of applying RAG approaches to VLMs, marking a stride toward more efficient and accessible multimodal learning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Advancing operational PM2.5 forecasting with dual deep neural networks (D-DNet)", "authors": "Shengjuan Cai, Fangxin Fang, Vincent-Henri Peuch, Mihai Alexe, Ionel Michael Navon, Yanghua Wang", "subjects": "Subjects:\nMachine Learning (cs.LG); Atmospheric and Oceanic Physics (physics.ao-ph)", "abstract": "PM2.5 forecasting is crucial for public health, air quality management, and policy development. Traditional physics-based models are computationally demanding and slow to adapt to real-time conditions. Deep learning models show potential in efficiency but still suffer from accuracy loss over time due to error accumulation. To address these challenges, we propose a dual deep neural network (D-DNet) prediction and data assimilation system that efficiently integrates real-time observations, ensuring reliable operational forecasting. D-DNet excels in global operational forecasting for PM2.5 and AOD550, maintaining consistent accuracy throughout the entire year of 2019. It demonstrates notably higher efficiency than the Copernicus Atmosphere Monitoring Service (CAMS) 4D-Var operational forecasting system while maintaining comparable accuracy. This efficiency benefits ensemble forecasting, uncertainty analysis, and large-scale tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Heterogeneous Causal Metapath Graph Neural Network for Gene-Microbe-Disease Association Prediction", "authors": "Kexin Zhang, Feng Huang, Luotao Liu, Zhankun Xiong, Hongyu Zhang, Yuan Quan, Wen Zhang", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "The recent focus on microbes in human medicine highlights their potential role in the genetic framework of diseases. To decode the complex interactions among genes, microbes, and diseases, computational predictions of gene-microbe-disease (GMD) associations are crucial. Existing methods primarily address gene-disease and microbe-disease associations, but the more intricate triple-wise GMD associations remain less explored. In this paper, we propose a Heterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD associations. HCMGNN constructs a heterogeneous graph linking genes, microbes, and diseases through their pairwise associations, and utilizes six predefined causal metapaths to extract directed causal subgraphs, which facilitate the multi-view analysis of causal relations among three entity types. Within each subgraph, we employ a causal semantic sharing message passing network for node representation learning, coupled with an attentive fusion method to integrate these representations for predicting GMD associations. Our extensive experiments show that HCMGNN effectively predicts GMD associations and addresses association sparsity issue by enhancing the graph's semantics and structure."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Robust Classification of Dynamic Bichromatic point Sets in R2", "authors": "Erwin Glazenburg, Frank Staals, Marc van Kreveld", "subjects": "Subjects:\nComputational Geometry (cs.CG)", "abstract": "Let $R \\cup B$ be a set of $n$ points in $\\mathbb{R}^2$, and let $k \\in 1..n$. Our goal is to compute a line that \"best\" separates the \"red\" points $R$ from the \"blue\" points $B$ with at most $k$ outliers. We present an efficient semi-online dynamic data structure that can maintain whether such a separator exists. Furthermore, we present efficient exact and approximation algorithms that compute a linear separator that is guaranteed to misclassify at most $k$, points and minimizes the distance to the farthest outlier. Our exact algorithm runs in $O(nk + n \\log n)$ time, and our $(1+\\varepsilon)$-approximation algorithm runs in $O(\\varepsilon^{-1/2}((n + k^2) \\log n))$ time. Based on our $(1+\\varepsilon)$-approximation algorithm we then also obtain a semi-online data structure to maintain such a separator efficiently."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Single Image Estimation of Cell Migration Direction by Deep Circular Regression", "authors": "Lennart Bruns, Lucas Lamparter, Milos Galic, Xiaoyi Jiang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "In this paper we study the problem of estimating the migration direction of cells based on a single image. To the best of our knowledge, there is only one related work that uses a classification CNN for four classes (quadrants). This approach does not allow detailed directional resolution. We solve the single image estimation problem using deep circular regression with special attention to cycle-sensitive methods. On two databases we achieve an average accuracy of $\\sim$17 degrees, which is a significant improvement over the previous work."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Exact Minimum Weight Spanners via Column Generation", "authors": "Fritz B\u00f6kler, Markus Chimani, Henning Jasper, Mirko H. Wagner", "subjects": "Subjects:\nData Structures and Algorithms (cs.DS); Discrete Mathematics (cs.DM); Combinatorics (math.CO)", "abstract": "Given a weighted graph $G$, a minimum weight $\\alpha$-spanner is a least-weight subgraph $H\\subseteq G$ that preserves minimum distances between all node pairs up to a factor of $\\alpha$. There are many results on heuristics and approximation algorithms, including a recent investigation of their practical performance [20]. Exact approaches, in contrast, have long been denounced as impractical: The first exact ILP (integer linear program) method [48] from 2004 is based on a model with exponentially many path variables, solved via column generation. A second approach [2], modeling via arc-based multicommodity flow, was presented in 2019. In both cases, only graphs with 40-100 nodes were reported to be solvable. In this paper, we briefly report on a theoretical comparison between these two models from a polyhedral point of view, and then concentrate on improvements and engineering aspects. We evaluate their performance in a large-scale empirical study. We report that our tuned column generation approach, based on multicriteria shortest path computations, is able to solve instances with over 16000 nodes within 13 minutes. Furthermore, now knowing optimal solutions for larger graphs, we are able to investigate the quality of the strongest known heuristic on reasonably sized instances for the first time."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Illusion of Competence: Evaluating the Effect of Explanations on Users' Mental Models of Visual Question Answering Systems", "authors": "Judith Sieker, Simeon Junker, Ronja Utescher, Nazia Attari, Heiko Wersing, Hendrik Buschmeier, Sina Zarrie\u00df", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "We examine how users perceive the limitations of an AI system when it encounters a task that it cannot perform perfectly and whether providing explanations alongside its answers aids users in constructing an appropriate mental model of the system's capabilities and limitations. We employ a visual question answer and explanation task where we control the AI system's limitations by manipulating the visual inputs: during inference, the system either processes full-color or grayscale images. Our goal is to determine whether participants can perceive the limitations of the system. We hypothesize that explanations will make limited AI capabilities more transparent to users. However, our results show that explanations do not have this effect. Instead of allowing users to more accurately assess the limitations of the AI system, explanations generally increase users' perceptions of the system's competence - regardless of its actual performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Crowd-Based Requirements Engineering for Digital Farming (CrowdRE4DF)", "authors": "Eduard C. Groen, Kazi Rezoanur Rahman, Nikita Narsinghani, Joerg Doerr", "subjects": "Subjects:\nSoftware Engineering (cs.SE)", "abstract": "The farming domain has seen a tremendous shift towards digital solutions. However, capturing farmers' requirements regarding Digital Farming (DF) technology remains a difficult task due to domain-specific challenges. Farmers form a diverse and international crowd of practitioners who use a common pool of agricultural products and services, which means we can consider the possibility of applying Crowd-based Requirements Engineering (CrowdRE) for DF: CrowdRE4DF. We found that online user feedback in this domain is limited, necessitating a way of capturing user feedback from farmers in situ. Our solution, the Farmers' Voice application, uses speech-to-text, Machine Learning (ML), and Web 2.0 technology. A preliminary evaluation with five farmers showed good technology acceptance, and accurate transcription and ML analysis even in noisy farm settings. Our findings help to drive the development of DF technology through in-situ requirements elicitation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Annotation Errors and NER: A Study with OntoNotes 5.0", "authors": "Gabriel Bernier-Colborne, Sowmya Vajjala", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Named Entity Recognition (NER) is a well-studied problem in NLP. However, there is much less focus on studying NER datasets, compared to developing new NER models. In this paper, we employed three simple techniques to detect annotation errors in the OntoNotes 5.0 corpus for English NER, which is the largest available NER corpus for English. Our techniques corrected ~10% of the sentences in train/dev/test data. In terms of entity mentions, we corrected the span and/or type of ~8% of mentions in the dataset, while adding/deleting/splitting/merging a few more. These are large numbers of changes, considering the size of OntoNotes. We used three NER libraries to train, evaluate and compare the models trained with the original and the re-annotated datasets, which showed an average improvement of 1.23% in overall F-scores, with large (>10%) improvements for some of the entity types. While our annotation error detection methods are not exhaustive and there is some manual annotation effort involved, they are largely language agnostic and can be employed with other NER datasets, and other sequence labelling tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Reducing Data Acquisition and Labeling for Defect Detection using Simulated Data", "authors": "Lukas Malte Kemeter, Rasmus Hvingelby, Paulina Sierak, Tobias Sch\u00f6n, Bishwajit Gosswam", "subjects": "Subjects:\nMachine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "In many manufacturing settings, annotating data for machine learning and computer vision is costly, but synthetic data can be generated at significantly lower cost. Substituting the real-world data with synthetic data is therefore appealing for many machine learning applications that require large amounts of training data. However, relying solely on synthetic data is frequently inadequate for effectively training models that perform well on real-world data, primarily due to domain shifts between the synthetic and real-world data. We discuss approaches for dealing with such a domain shift when detecting defects in X-ray scans of aluminium wheels. Using both simulated and real-world X-ray images, we train an object detection model with different strategies to identify the training approach that generates the best detection results while minimising the demand for annotated real-world training samples. Our preliminary findings suggest that the sim-2-real domain adaptation approach is more cost-efficient than a fully supervised oracle - if the total number of available annotated samples is fixed. Given a certain number of labeled real-world samples, training on a mix of synthetic and unlabeled real-world data achieved comparable or even better detection results at significantly lower cost. We argue that future research into the cost-efficiency of different training strategies is important for a better understanding of how to allocate budget in applied machine learning projects."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cooperative Target Capture using Voronoi Region Shaping", "authors": "Gautam Kumar, Ashwini Ratnoo", "subjects": "Subjects:\nMultiagent Systems (cs.MA)", "abstract": "This paper discusses a cooperative strategy for capturing a target using multiple pursuers in a planar scenario. Given an initial position distribution of pursuers, the Voronoi Diagram is employed to characterize the target's proximity region. The key idea is to dynamically shape that region using a policy that directs its vertices towards its instantaneous centroid. Analysis of the resulting dynamics deduces the velocity control inputs for the pursuers. As the main result, target's proximity region is shown to shrink exponentially irrespective of its speed and evasion policy. Simulation results demonstrate the characteristics of the proposed method."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion", "authors": "Yannis Flet-Berliac, Nathan Grinsztajn, Florian Strub, Eugene Choi, Chris Cremer, Arash Ahmadian, Yash Chandak, Mohammad Gheshlaghi Azar, Olivier Pietquin, Matthieu Geist", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Reinforcement Learning (RL) has been used to finetune Large Language Models (LLMs) using a reward model trained from preference data, to better align with human judgment. The recently introduced direct alignment methods, which are often simpler, more stable, and computationally lighter, can more directly achieve this. However, these approaches cannot optimize arbitrary rewards, and the preference-based ones are not the only rewards of interest for LLMs (eg., unit tests for code generation or textual entailment for summarization, among others). RL-finetuning is usually done with a variation of policy gradient, which calls for on-policy or near-on-policy samples, requiring costly generations. We introduce Contrastive Policy Gradient, or CoPG, a simple and mathematically principled new RL algorithm that can estimate the optimal policy even from off-policy data. It can be seen as an off-policy policy gradient approach that does not rely on important sampling techniques and highlights the importance of using (the right) state baseline. We show this approach to generalize the direct alignment method IPO (identity preference optimization) and classic policy gradient. We experiment with the proposed CoPG on a toy bandit problem to illustrate its properties, as well as for finetuning LLMs on a summarization task, using a learned reward function considered as ground truth for the purpose of the experiments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Averaging log-likelihoods in direct alignment", "authors": "Nathan Grinsztajn, Yannis Flet-Berliac, Mohammad Gheshlaghi Azar, Florian Strub, Bill Wu, Eugene Choi, Chris Cremer, Arash Ahmadian, Yash Chandak, Olivier Pietquin, Matthieu Geist", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "To better align Large Language Models (LLMs) with human judgment, Reinforcement Learning from Human Feedback (RLHF) learns a reward model and then optimizes it using regularized RL. Recently, direct alignment methods were introduced to learn such a fine-tuned model directly from a preference dataset without computing a proxy reward function. These methods are built upon contrastive losses involving the log-likelihood of (dis)preferred completions according to the trained model. However, completions have various lengths, and the log-likelihood is not length-invariant. On the other side, the cross-entropy loss used in supervised training is length-invariant, as batches are typically averaged token-wise. To reconcile these approaches, we introduce a principled approach for making direct alignment length-invariant. Formally, we introduce a new averaging operator, to be composed with the optimality operator giving the best policy for the underlying RL problem. It translates into averaging the log-likelihood within the loss. We empirically study the effect of such averaging, observing a trade-off between the length of generations and their scores."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          BISeizuRe: BERT-Inspired Seizure Data Representation to Improve Epilepsy Monitoring", "authors": "Luca Benfenati, Thorir Mar Ingolfsson, Andrea Cossettini, Daniele Jahier Pagliari, Alessio Burrello, Luca Benini", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "This study presents a novel approach for EEG-based seizure detection leveraging a BERT-based model. The model, BENDR, undergoes a two-phase training process. Initially, it is pre-trained on the extensive Temple University Hospital EEG Corpus (TUEG), a 1.5 TB dataset comprising over 10,000 subjects, to extract common EEG data patterns. Subsequently, the model is fine-tuned on the CHB-MIT Scalp EEG Database, consisting of 664 EEG recordings from 24 pediatric patients, of which 198 contain seizure events. Key contributions include optimizing fine-tuning on the CHB-MIT dataset, where the impact of model architecture, pre-processing, and post-processing techniques are thoroughly examined to enhance sensitivity and reduce false positives per hour (FP/h). We also explored custom training strategies to ascertain the most effective setup. The model undergoes a novel second pre-training phase before subject-specific fine-tuning, enhancing its generalization capabilities. The optimized model demonstrates substantial performance enhancements, achieving as low as 0.23 FP/h, 2.5$\\times$ lower than the baseline model, with a lower but still acceptable sensitivity rate, showcasing the effectiveness of applying a BERT-based approach on EEG-based seizure detection."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Estimating Long-term Heterogeneous Dose-response Curve: Generalization Bound Leveraging Optimal Transport Weights", "authors": "Zeqin Yang, Weilin Chen, Ruichu Cai, Yuguang Yan, Zhifeng Hao, Zhipeng Yu, Zhichao Zou, Zhen Peng, Jiecheng Guo", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Long-term causal effect estimation is a significant but challenging problem in many applications. Existing methods rely on ideal assumptions to estimate long-term average effects, e.g., no unobserved confounders or a binary treatment,while in numerous real-world applications, these assumptions could be violated and average effects are unable to provide individual-level this http URL this paper,we address a more general problem of estimating the long-term heterogeneous dose-response curve (HDRC) while accounting for unobserved confounders. Specifically, to remove unobserved confounding in observational data, we introduce an optimal transport weighting framework to align the observational data to the experimental data with theoretical guarantees. Furthermore,to accurately predict the heterogeneous effects of continuous treatment, we establish a generalization bound on counterfactual prediction error by leveraging the reweighted distribution induced by optimal transport. Finally, we develop an HDRC estimator building upon the above theoretical foundations. Extensive experimental studies conducted on multiple synthetic and semi-synthetic datasets demonstrate the effectiveness of our proposed method."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CoDiNG -- Naming Game with Continuous Latent State of Agents", "authors": "Mateusz Nurek, Joanna Ko\u0142aczek, Rados\u0142aw Michalski, Boles\u0142aw K. Szyma\u0144ski, Omar Lizardo", "subjects": "Subjects:\nSocial and Information Networks (cs.SI); Physics and Society (physics.soc-ph)", "abstract": "Understanding the mechanisms behind opinion formation is crucial for gaining insight into the processes that shape political beliefs, cultural attitudes, consumer choices, and social movements. This work aims to explore a nuanced model that captures the intricacies of real-world opinion dynamics by synthesizing principles from cognitive science and employing social network analysis. The proposed model is a hybrid continuous-discrete extension of the well-known Naming Game opinion model. The added latent continuous layer of opinion strength follows cognitive processes in the human brain, akin to memory imprints. The discrete layer allows for the conversion of intrinsic continuous opinion into discrete form, which often occurs when we publicly verbalize our opinions. We evaluated our model using real data as ground truth and demonstrated that the proposed mechanism outperforms the classic Naming Game model in many cases, reflecting that our model is closer to the real process of opinion formation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation", "authors": "Zijun Yao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Weichuan Liu, Lei Hou, Juanzi Li", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "This paper introduces Self-aware Knowledge Retrieval (SeaKR), a novel adaptive RAG model that extracts self-aware uncertainty of LLMs from their internal states. SeaKR activates retrieval when the LLMs present high self-aware uncertainty for generation. To effectively integrate retrieved knowledge snippets, SeaKR re-ranks them based on LLM's self-aware uncertainty to preserve the snippet that reduces their uncertainty to the utmost. To facilitate solving complex tasks that require multiple retrievals, SeaKR utilizes their self-aware uncertainty to choose among different reasoning strategies. Our experiments on both complex and simple Question Answering datasets show that SeaKR outperforms existing adaptive RAG methods. We release our code at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Think Step by Step: Chain-of-Gesture Prompting for Error Detection in Robotic Surgical Videos", "authors": "Zhimin Shao, Jialang Xu, Danail Stoyanov, Evangelos B. Mazomenos, Yueming Jin", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "abstract": "Despite significant advancements in robotic systems and surgical data science, ensuring safe and optimal execution in robot-assisted minimally invasive surgery (RMIS) remains a complex challenge. Current surgical error detection methods involve two parts: identifying surgical gestures and then detecting errors within each gesture clip. These methods seldom consider the rich contextual and semantic information inherent in surgical videos, limiting their performance due to reliance on accurate gesture identification. Motivated by the chain-of-thought prompting in natural language processing, this letter presents a novel and real-time end-to-end error detection framework, Chain-of-Thought (COG) prompting, leveraging contextual information from surgical videos. This encompasses two reasoning modules designed to mimic the decision-making processes of expert surgeons. Concretely, we first design a Gestural-Visual Reasoning module, which utilizes transformer and attention architectures for gesture prompting, while the second, a Multi-Scale Temporal Reasoning module, employs a multi-stage temporal convolutional network with both slow and fast paths for temporal information extraction. We extensively validate our method on the public benchmark RMIS dataset JIGSAWS. Our method encapsulates the reasoning processes inherent to surgical activities enabling it to outperform the state-of-the-art by 4.6% in F1 score, 4.6% in Accuracy, and 5.9% in Jaccard index while processing each frame in 6.69 milliseconds on average, demonstrating the great potential of our approach in enhancing the safety and efficacy of RMIS procedures and surgical education. The code will be available."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Metrics to Detect Small-Scale and Large-Scale Citation Orchestration", "authors": "Iakovos Evdaimon, John P. A. Ioannidis, Giannis Nikolentzos, Michail Chatzianastasis, George Panagopoulos, Michalis Vazirgiannis", "subjects": "Subjects:\nDigital Libraries (cs.DL)", "abstract": "Citation counts and related metrics have pervasive uses and misuses in academia and research appraisal, serving as scholarly influence and recognition measures. Hence, comprehending the citation patterns exhibited by authors is essential for assessing their research impact and contributions within their respective fields. Although the h-index, introduced by Hirsch in 2005, has emerged as a popular bibliometric indicator, it fails to account for the intricate relationships between authors and their citation patterns. This limitation becomes particularly relevant in cases where citations are strategically employed to boost the perceived influence of certain individuals or groups, a phenomenon that we term \"orchestration\". Orchestrated citations can introduce biases in citation rankings and therefore necessitate the identification of such patterns. Here, we use Scopus data to investigate orchestration of citations across all scientific disciplines. Orchestration could be small-scale, when the author him/herself and/or a small number of other authors use citations strategically to boost citation metrics like h-index; or large-scale, where extensive collaborations among many co-authors lead to high h-index for many/all of them. We propose three orchestration indicators: extremely low values in the ratio of citations over the square of the h-index (indicative of small-scale orchestration); extremely small number of authors who can explain at least 50% of an author's total citations (indicative of either small-scale or large-scale orchestration); and extremely large number of co-authors with more than 50 co-authored papers (indicative of large-scale orchestration). The distributions, potential thresholds based on 1% (and 5%) percentiles, and insights from these indicators are explored and put into perspective across science."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Hack Me If You Can: Aggregating AutoEncoders for Countering Persistent Access Threats Within Highly Imbalanced Data", "authors": "Sidahmed Benabderrahmane, Ngoc Hoang, Petko Valtchev, James Cheney, Talal Rahwan", "subjects": "Subjects:\nCryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "abstract": "Advanced Persistent Threats (APTs) are sophisticated, targeted cyberattacks designed to gain unauthorized access to systems and remain undetected for extended periods. To evade detection, APT cyberattacks deceive defense layers with breaches and exploits, thereby complicating exposure by traditional anomaly detection-based security methods. The challenge of detecting APTs with machine learning is compounded by the rarity of relevant datasets and the significant imbalance in the data, which makes the detection process highly burdensome. We present AE-APT, a deep learning-based tool for APT detection that features a family of AutoEncoder methods ranging from a basic one to a Transformer-based one. We evaluated our tool on a suite of provenance trace databases produced by the DARPA Transparent Computing program, where APT-like attacks constitute as little as 0.004% of the data. The datasets span multiple operating systems, including Android, Linux, BSD, and Windows, and cover two attack scenarios. The outcomes showed that AE-APT has significantly higher detection rates compared to its competitors, indicating superior performance in detecting and ranking anomalies."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings", "authors": "Bj\u00f6rn Deiseroth, Manuel Brack, Patrick Schramowski, Kristian Kersting, Samuel Weinbach", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Tokenizers are crucial for encoding information in Large Language Models, but their development has recently stagnated, and they contain inherent weaknesses. Major limitations include computational overhead, ineffective vocabulary use, and unnecessarily large embedding and head layers. Additionally, their performance is biased towards a reference corpus, leading to reduced effectiveness for underrepresented languages. To remedy these issues, we propose T-FREE, which directly embeds words through sparse activation patterns over character triplets, and does not require a reference corpus. T-FREE inherently exploits morphological similarities and allows for strong compression of embedding layers. In our exhaustive experimental evaluation, we achieve competitive downstream performance with a parameter reduction of more than 85% on these layers. Further, T-FREE shows significant improvements in cross-lingual transfer learning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ProtoGMM: Multi-prototype Gaussian-Mixture-based Domain Adaptation Model for Semantic Segmentation", "authors": "Nazanin Moradinasab, Laura S. Shankman, Rebecca A. Deaton, Gary K. Owens, Donald E. Brown", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Domain adaptive semantic segmentation aims to generate accurate and dense predictions for an unlabeled target domain by leveraging a supervised model trained on a labeled source domain. The prevalent self-training approach involves retraining the dense discriminative classifier of $p(class|pixel feature)$ using the pseudo-labels from the target domain. While many methods focus on mitigating the issue of noisy pseudo-labels, they often overlook the underlying data distribution p(pixel feature|class) in both the source and target domains. To address this limitation, we propose the multi-prototype Gaussian-Mixture-based (ProtoGMM) model, which incorporates the GMM into contrastive losses to perform guided contrastive learning. Contrastive losses are commonly executed in the literature using memory banks, which can lead to class biases due to underrepresented classes. Furthermore, memory banks often have fixed capacities, potentially restricting the model's ability to capture diverse representations of the target/source domains. An alternative approach is to use global class prototypes (i.e. averaged features per category). However, the global prototypes are based on the unimodal distribution assumption per class, disregarding within-class variation. To address these challenges, we propose the ProtoGMM model. This novel approach involves estimating the underlying multi-prototype source distribution by utilizing the GMM on the feature space of the source samples. The components of the GMM model act as representative prototypes. To achieve increased intra-class semantic similarity, decreased inter-class similarity, and domain alignment between the source and target domains, we employ multi-prototype contrastive learning between source distribution and target samples. The experiments show the effectiveness of our method on UDA benchmarks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Simulating Classroom Education with LLM-Empowered Agents", "authors": "Zheyuan Zhang, Daniel Zhang-Li, Jifan Yu, Linlu Gong, Jinchang Zhou, Zhiyuan Liu, Lei Hou, Juanzi Li", "subjects": "Subjects:\nComputation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "abstract": "Large language models (LLMs) have been employed in various intelligent educational tasks to assist teaching. While preliminary explorations have focused on independent LLM-empowered agents for specific educational tasks, the potential for LLMs within a multi-agent collaborative framework to simulate a classroom with real user participation remains unexplored. In this work, we propose SimClass, a multi-agent classroom simulation framework involving user participation. We recognize representative class roles and introduce a novel class control mechanism for automatic classroom teaching, and conduct user experiments in two real-world courses. Utilizing the Flanders Interactive Analysis System and Community of Inquiry theoretical frame works from educational analysis, we demonstrate that LLMs can simulate traditional classroom interaction patterns effectively while enhancing user's experience. We also observe emergent group behaviors among agents in SimClass, where agents collaborate to create enlivening interactions in classrooms to improve user learning process. We hope this work pioneers the application of LLM-empowered multi-agent systems in virtual classroom teaching."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Aligning Teacher with Student Preferences for Tailored Training Data Generation", "authors": "Yantao Liu, Zhao Zhang, Zijun Yao, Shulin Cao, Lei Hou, Juanzi Li", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in various tasks. Local deployment of LLMs on edge devices is necessary when handling privacy-sensitive data or latency-sensitive tasks. The computational constraints of such devices make direct deployment of powerful large-scale LLMs impractical, necessitating the Knowledge Distillation from large-scale models to lightweight models. Lots of work has been done to elicit diversity and quality training examples from LLMs, but little attention has been paid to aligning teacher instructional content based on student preferences, akin to \"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning TeacheR with StudenT PreferencEs, a framework that aligns the teacher model with student preferences to generate tailored training examples for Knowledge Distillation. Specifically, we elicit draft questions and rationales from the teacher model, then collect student preferences on these questions and rationales using students' performance with in-context learning as a proxy, and finally align the teacher model with student preferences. In the end, we repeat the first step with the aligned teacher model to elicit tailored training examples for the student model on the target task. Extensive experiments on academic benchmarks demonstrate the superiority of ARTE over existing instruction-tuning datasets distilled from powerful LLMs. Moreover, we thoroughly investigate the generalization of ARTE, including the generalization of fine-tuned student models in reasoning ability and the generalization of aligned teacher models to generate tailored training data across tasks and students. In summary, our contributions lie in proposing a novel framework for tailored training example generation, demonstrating its efficacy in experiments, and investigating the generalization of both student & aligned teacher models in ARTE."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Tools Fail: Detecting Silent Errors in Faulty Tools", "authors": "Jimin Sun, So Yeon Min, Yingshan Chang, Yonatan Bisk", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not in their weights, to perform tasks on the web, and even to control robots. However, most ontologies and surveys of tool-use have assumed the core challenge for LLMs is choosing the tool. Instead, we introduce a framework for tools more broadly which guides us to explore a model's ability to detect \"silent\" tool errors, and reflect on how to plan. This more directly aligns with the increasingly popular use of models as tools. We provide an initial approach to failure recovery with promising results both on a controlled calculator setting and embodied agent planning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Spiking Convolutional Neural Networks for Text Classification", "authors": "Changze Lv, Jianhan Xu, Xiaoqing Zheng", "subjects": "Subjects:\nNeural and Evolutionary Computing (cs.NE); Computation and Language (cs.CL)", "abstract": "Spiking neural networks (SNNs) offer a promising pathway to implement deep neural networks (DNNs) in a more energy-efficient manner since their neurons are sparsely activated and inferences are event-driven. However, there have been very few works that have demonstrated the efficacy of SNNs in language tasks partially because it is non-trivial to represent words in the forms of spikes and to deal with variable-length texts by SNNs. This work presents a \"conversion + fine-tuning\" two-step method for training SNNs for text classification and proposes a simple but effective way to encode pre-trained word embeddings as spike trains. We show empirically that after fine-tuning with surrogate gradients, the converted SNNs achieve comparable results to their DNN counterparts with much less energy consumption across multiple datasets for both English and Chinese. We also show that such SNNs are more robust to adversarial attacks than DNNs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs", "authors": "Ekaterina Taktasheva, Maxim Bazhukov, Kirill Koncha, Alena Fenogenova, Ekaterina Artemova", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Minimal pairs are a well-established approach to evaluating the grammatical knowledge of language models. However, existing resources for minimal pairs address a limited number of languages and lack diversity of language-specific grammatical phenomena. This paper introduces the Russian Benchmark of Linguistic Minimal Pairs (RuBLiMP), which includes 45k pairs of sentences that differ in grammaticality and isolate a morphological, syntactic, or semantic phenomenon. In contrast to existing benchmarks of linguistic minimal pairs, RuBLiMP is created by applying linguistic perturbations to automatically annotated sentences from open text corpora and carefully curating test data. We describe the data collection protocol and present the results of evaluating 25 language models in various scenarios. We find that the widely used language models for Russian are sensitive to morphological and agreement-oriented contrasts but fall behind humans on phenomena requiring understanding of structural relations, negation, transitivity, and tense. RuBLiMP, the codebase, and other materials are publicly available."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation", "authors": "Yuying Li, Gaoyang Liu, Yang Yang, Chen Wang", "subjects": "Subjects:\nCryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "abstract": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that enhances Large Language Models (LLMs) by retrieving relevant knowledge from an external, non-parametric database. This approach aims to mitigate common LLM issues such as hallucinations and outdated knowledge. Although existing research has demonstrated security and privacy vulnerabilities within RAG systems, making them susceptible to attacks like jailbreaks and prompt injections, the security of the RAG system's external databases remains largely underexplored. In this paper, we employ Membership Inference Attacks (MIA) to determine whether a sample is part of the knowledge database of a RAG system, using only black-box API access. Our core hypothesis posits that if a sample is a member, it will exhibit significant similarity to the text generated by the RAG system. To test this, we compute the cosine similarity and the model's perplexity to establish a membership score, thereby building robust features. We then introduce two novel attack strategies: a Threshold-based Attack and a Machine Learning-based Attack, designed to accurately identify membership. Experimental validation of our methods has achieved a ROC AUC of 82%."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Human-Aware Vision-and-Language Navigation: Bridging Simulation to Reality with Dynamic Human Interactions", "authors": "Minghan Li, Heng Li, Zhi-Qi Cheng, Yifei Dong, Yuxuan Zhou, Jun-Yan He, Qi Dai, Teruko Mitamura, Alexander G. Hauptmann", "subjects": "Subjects:\nArtificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "abstract": "Vision-and-Language Navigation (VLN) aims to develop embodied agents that navigate based on human instructions. However, current VLN frameworks often rely on static environments and optimal expert supervision, limiting their real-world applicability. To address this, we introduce Human-Aware Vision-and-Language Navigation (HA-VLN), extending traditional VLN by incorporating dynamic human activities and relaxing key assumptions. We propose the Human-Aware 3D (HA3D) simulator, which combines dynamic human activities with the Matterport3D dataset, and the Human-Aware Room-to-Room (HA-R2R) dataset, extending R2R with human activity descriptions. To tackle HA-VLN challenges, we present the Expert-Supervised Cross-Modal (VLN-CM) and Non-Expert-Supervised Decision Transformer (VLN-DT) agents, utilizing cross-modal fusion and diverse training strategies for effective navigation in dynamic human environments. A comprehensive evaluation, including metrics considering human activities, and systematic analysis of HA-VLN's unique challenges, underscores the need for further research to enhance HA-VLN agents' real-world robustness and adaptability. Ultimately, this work provides benchmarks and insights for future research on embodied AI and Sim2Real transfer, paving the way for more realistic and applicable VLN systems in human-populated environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts", "authors": "Shubhankar Singh, Purvi Chaurasia, Yerram Varun, Pranshu Pandya, Vatsal Gupta, Vivek Gupta, Dan Roth", "subjects": "Subjects:\nComputation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "abstract": "Existing benchmarks for visual question answering lack in visual grounding and complexity, particularly in evaluating spatial reasoning skills. We introduce FlowVQA, a novel benchmark aimed at assessing the capabilities of visual question-answering multimodal language models in reasoning with flowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and human-verified flowchart images from three distinct content sources, along with 22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks, including information localization, decision-making, and logical progression. We conduct a thorough baseline evaluation on a suite of both open-source and proprietary multimodal language models using various strategies, followed by an analysis of directional bias. The results underscore the benchmark's potential as a vital tool for advancing the field of multimodal modeling, providing a focused and challenging environment for enhancing model performance in visual and logical reasoning tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Revealing Fine-Grained Values and Opinions in Large Language Models", "authors": "Dustin Wright, Arnav Arora, Nadav Borenstein, Srishti Yadav, Serge Belongie, Isabelle Augenstein", "subjects": "Subjects:\nComputation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (cs.LG)", "abstract": "Uncovering latent values and opinions in large language models (LLMs) can help identify biases and mitigate potential harm. Recently, this has been approached by presenting LLMs with survey questions and quantifying their stances towards morally and politically charged statements. However, the stances generated by LLMs can vary greatly depending on how they are prompted, and there are many ways to argue for or against a given position. In this work, we propose to address this by analysing a large and robust dataset of 156k LLM responses to the 62 propositions of the Political Compass Test (PCT) generated by 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of their generated stances and fine-grained analysis of the plain text justifications for those stances. For fine-grained analysis, we propose to identify tropes in the responses: semantically similar phrases that are recurrent and consistent across different prompts, revealing patterns in the text that a given LLM is prone to produce. We find that demographic features added to prompts significantly affect outcomes on the PCT, reflecting bias, as well as disparities between the results of tests when eliciting closed-form vs. open domain responses. Additionally, patterns in the plain text rationales via tropes show that similar justifications are repeatedly generated across models and prompts even with disparate stances."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Data Preparation for Deep Learning based Code Smell Detection: A Systematic Literature Review", "authors": "Fengji Zhang, Zexian Zhang, Jacky Wai Keung, Xiangru Tang, Zhen Yang, Xiao Yu, Wenhua Hu", "subjects": "Subjects:\nSoftware Engineering (cs.SE)", "abstract": "Code Smell Detection (CSD) plays a crucial role in improving software quality and maintainability. And Deep Learning (DL) techniques have emerged as a promising approach for CSD due to their superior performance. However, the effectiveness of DL-based CSD methods heavily relies on the quality of the training data. Despite its importance, little attention has been paid to analyzing the data preparation process. This systematic literature review analyzes the data preparation techniques used in DL-based CSD methods. We identify 36 relevant papers published by December 2023 and provide a thorough analysis of the critical considerations in constructing CSD datasets, including data requirements, collection, labeling, and cleaning. We also summarize seven primary challenges and corresponding solutions in the literature. Finally, we offer actionable recommendations for preparing and accessing high-quality CSD data, emphasizing the importance of data diversity, standardization, and accessibility. This survey provides valuable insights for researchers and practitioners to harness the full potential of DL techniques in CSD."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Application of ASV for Voice Identification after VC and Duration Predictor Improvement in TTS Models", "authors": "Borodin Kirill Nikolayevich, Kudryavtsev Vasiliy Dmitrievich, Mkrtchian Grach Maratovich, Gorodnichev Mikhail Genadievich, Korzh Dmitrii Sergeevich", "subjects": "Subjects:\nSound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)", "abstract": "One of the most crucial components in the field of biometric security is the automatic speaker verification system, which is based on the speaker's voice. It is possible to utilise ASVs in isolation or in conjunction with other AI models. In the contemporary era, the quality and quantity of neural networks are increasing exponentially. Concurrently, there is a growing number of systems that aim to manipulate data through the use of voice conversion and text-to-speech models. The field of voice biometrics forgery is aided by a number of challenges, including SSTC, ASVSpoof, and SingFake. This paper presents a system for automatic speaker verification. The primary objective of our model is the extraction of embeddings from the target speaker's audio in order to obtain information about important characteristics of his voice, such as pitch, energy, and the duration of phonemes. This information is used in our multivoice TTS pipeline, which is currently under development. However, this model was employed within the SSTC challenge to verify users whose voice had undergone voice conversion, where it demonstrated an EER of 20.669."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Improving the Expressiveness of $K$-hop Message-Passing GNNs by Injecting Contextualized Substructure Information", "authors": "Tianjun Yao, Yiongxu Wang, Kun Zhang, Shangsong Liang", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Graph neural networks (GNNs) have become the \\textit{de facto} standard for representational learning in graphs, and have achieved state-of-the-art performance in many graph-related tasks; however, it has been shown that the expressive power of standard GNNs are equivalent maximally to 1-dimensional Weisfeiler-Lehman (1-WL) Test. Recently, there is a line of works aiming to enhance the expressive power of graph neural networks. One line of such works aim at developing $K$-hop message-passing GNNs where node representation is updated by aggregating information from not only direct neighbors but all neighbors within $K$-hop of the node. Another line of works leverages subgraph information to enhance the expressive power which is proven to be strictly more powerful than 1-WL test. In this work, we discuss the limitation of $K$-hop message-passing GNNs and propose \\textit{substructure encoding function} to uplift the expressive power of any $K$-hop message-passing GNN. We further inject contextualized substructure information to enhance the expressiveness of $K$-hop message-passing GNNs. Our method is provably more powerful than previous works on $K$-hop graph neural networks and 1-WL subgraph GNNs, which is a specific type of subgraph based GNN models, and not less powerful than 3-WL. Empirically, our proposed method set new state-of-the-art performance or achieves comparable performance for a variety of datasets. Our code is available at \\url{this https URL}."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Local Manifold Learning for No-Reference Image Quality Assessment", "authors": "Timin Gao, Wensheng Pan, Yan Zhang, Sicheng Zhao, Shengchuan Zhang, Xiawu Zheng, Ke Li, Liujuan Cao, Rongrong Ji", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Contrastive learning has considerably advanced the field of Image Quality Assessment (IQA), emerging as a widely adopted technique. The core mechanism of contrastive learning involves minimizing the distance between quality-similar (positive) examples while maximizing the distance between quality-dissimilar (negative) examples. Despite its successes, current contrastive learning methods often neglect the importance of preserving the local manifold structure. This oversight can result in a high degree of similarity among hard examples within the feature space, thereby impeding effective differentiation and assessment. To address this issue, we propose an innovative framework that integrates local manifold learning with contrastive learning for No-Reference Image Quality Assessment (NR-IQA). Our method begins by sampling multiple crops from a given image, identifying the most visually salient crop. This crop is then used to cluster other crops from the same image as the positive class, while crops from different images are treated as negative classes to increase inter-class distance. Uniquely, our approach also considers non-saliency crops from the same image as intra-class negative classes to preserve their distinctiveness. Additionally, we employ a mutual learning framework, which further enhances the model's ability to adaptively learn and identify visual saliency regions. Our approach demonstrates a better performance compared to state-of-the-art methods in 7 standard datasets, achieving PLCC values of 0.942 (compared to 0.908 in TID2013) and 0.914 (compared to 0.894 in LIVEC)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Staggered Quantizers for Perfect Perceptual Quality: A Connection between Quantizers with Common Randomness and Without", "authors": "Ruida Zhou, Chao Tian", "subjects": "Subjects:\nInformation Theory (cs.IT)", "abstract": "The rate-distortion-perception (RDP) framework has attracted significant recent attention due to its application in neural compression. It is important to understand the underlying mechanism connecting procedures with common randomness and those without. Different from previous efforts, we study this problem from a quantizer design perspective. By analyzing an idealized setting, we provide an interpretation of the advantage of dithered quantization in the RDP setting, which further allows us to make a conceptual connection between randomized (dithered) quantizers and quantizers without common randomness. This new understanding leads to a new procedure for RDP coding based on staggered quantizers."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          NTFormer: A Composite Node Tokenized Graph Transformer for Node Classification", "authors": "Jinsong Chen, Siyu Jiang, Kun He", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Recently, the emerging graph Transformers have made significant advancements for node classification on graphs. In most graph Transformers, a crucial step involves transforming the input graph into token sequences as the model input, enabling Transformer to effectively learn the node representations. However, we observe that existing methods only express partial graph information of nodes through single-type token generation. Consequently, they require tailored strategies to encode additional graph-specific features into the Transformer to ensure the quality of node representation learning, limiting the model flexibility to handle diverse graphs. To this end, we propose a new graph Transformer called NTFormer to address this issue. NTFormer introduces a novel token generator called Node2Par, which constructs various token sequences using different token elements for each node. This flexibility allows Node2Par to generate valuable token sequences from different perspectives, ensuring comprehensive expression of rich graph features. Benefiting from the merits of Node2Par, NTFormer only leverages a Transformer-based backbone without graph-specific modifications to learn node representations, eliminating the need for graph-specific modifications. Extensive experiments conducted on various benchmark datasets containing homophily and heterophily graphs with different scales demonstrate the superiority of NTFormer over representative graph Transformers and graph neural networks for node classification."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation", "authors": "Jia Fu, Xiaoting Qin, Fangkai Yang, Lu Wang, Jue Zhang, Qingwei Lin, Yubo Chen, Dongmei Zhang, Saravan Rajmohan, Qi Zhang", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Recent advancements in Large Language Models have transformed ML/AI development, necessitating a reevaluation of AutoML principles for the Retrieval-Augmented Generation (RAG) systems. To address the challenges of hyper-parameter optimization and online adaptation in RAG, we propose the AutoRAG-HP framework, which formulates the hyper-parameter tuning as an online multi-armed bandit (MAB) problem and introduces a novel two-level Hierarchical MAB (Hier-MAB) method for efficient exploration of large search spaces. We conduct extensive experiments on tuning hyper-parameters, such as top-k retrieved documents, prompt compression ratio, and embedding methods, using the ALCE-ASQA and Natural Questions datasets. Our evaluation from jointly optimization all three hyper-parameters demonstrate that MAB-based online learning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with prominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls required by the Grid Search approach. Additionally, the proposed Hier-MAB approach outperforms other baselines in more challenging optimization scenarios. The code will be made available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Advection Augmented Convolutional Neural Networks", "authors": "Niloufar Zakariaei, Siddharth Rout, Eldad Haber, Moshe Eliasof", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Many problems in physical sciences are characterized by the prediction of space-time sequences. Such problems range from weather prediction to the analysis of disease propagation and video prediction. Modern techniques for the solution of these problems typically combine Convolution Neural Networks (CNN) architecture with a time prediction mechanism. However, oftentimes, such approaches underperform in the long-range propagation of information and lack explainability. In this work, we introduce a physically inspired architecture for the solution of such problems. Namely, we propose to augment CNNs with advection by designing a novel semi-Lagrangian push operator. We show that the proposed operator allows for the non-local transformation of information compared with standard convolutional kernels. We then complement it with Reaction and Diffusion neural components to form a network that mimics the Reaction-Advection-Diffusion equation, in high dimensions. We demonstrate the effectiveness of our network on a number of spatio-temporal datasets that show their merit."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Empirical Investigation of the Relationship Between Design Smells and Role Stereotypes", "authors": "Daniel Ogenrwot, Joyce Nakatumba-Nabende, John Businge, Michel R. V. Chaudron", "subjects": "Subjects:\nSoftware Engineering (cs.SE)", "abstract": "During software development, poor design and implementation choices can detrimentally impact software maintainability. Design smells, recurring patterns of poorly designed fragments, signify these issues. Role-stereotypes denote the generic responsibilities that classes assume in system design. Although the concepts of role-stereotypes and design smells differ, both significantly contribute to the design and maintenance of software systems. Understanding the relationship between these aspects is crucial for enhancing software maintainability, code quality, efficient code review, guided refactoring, and the design of role-specific metrics. This paper employs an exploratory approach, combining statistical analysis and unsupervised learning methods, to understand how design smells relate to role-stereotypes across desktop and mobile applications. Analyzing 11,350 classes from 30 GitHub repositories, we identified several design smells that frequently co-occur within certain role-stereotypes. Specifically, three (3) out of six (6) role-stereotypes we studied are more prone to design smells. We also examined the variation of design smells across the two ecosystems, driven by notable differences in their underlying architecture. Findings revealed that design smells are more prevalent in desktop than in mobile applications, especially within the Service Provider and Information Holder role-stereotypes. Additionally, the unsupervised learning method showed that certain pairs or groups of role-stereotypes are prone to similar types of design smells. We believe these relationships are associated with the characteristic and collaborative properties between role-stereotypes. The insights from this research provide valuable guidance for software teams on implementing design smell prevention and correction mechanisms, ensuring conceptual integrity during design and maintenance phases."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment", "authors": "Hao Fei, Shengqiong Wu, Meishan Zhang, Min Zhang, Tat-Seng Chua, Shuicheng Yan", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "abstract": "While pre-training large-scale video-language models (VLMs) has shown remarkable potential for various downstream video-language tasks, existing VLMs can still suffer from certain commonly seen limitations, e.g., coarse-grained cross-modal aligning , under-modeling of temporal dynamics, detached video-language view. In this work, we target enhancing VLMs with a fine-grained structural spatio-temporal alignment learning method (namely Finsta). First of all, we represent the input texts and videos with fine-grained scene graph (SG) structures, both of which are further unified into a holistic SG (HSG) for bridging two modalities. Then, an SG-based framework is built, where the textual SG (TSG) is encoded with a graph Transformer, while the video dynamic SG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for spatial and temporal feature propagation. A spatial-temporal Gaussian differential graph Transformer is further devised to strengthen the sense of the changes in objects across spatial and temporal dimensions. Next, based on the fine-grained structural features of TSG and DSG, we perform object-centered spatial alignment and predicate-centered temporal alignment respectively, enhancing the video-language grounding in both the spatiality and temporality. We design our method as a plug&play system, which can be integrated into existing well-trained VLMs for further representation augmentation, without training from scratch or relying on SG annotations in downstream applications. On 6 representative VL modeling tasks over 12 datasets in both standard and long-form video scenarios, Finsta consistently improves the existing 13 strong-performing VLMs persistently, and refreshes the current state-of-the-art end task performance significantly in both the fine-tuning and zero-shot settings."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data Readiness for AI", "authors": "Kaveen Hiniduma, Suren Byna, Jean Luca Bez, Ravi Madduri", "subjects": "Subjects:\nArtificial Intelligence (cs.AI)", "abstract": "\"Garbage In Garbage Out\" is a universally agreed quote by computer scientists from various domains, including Artificial Intelligence (AI). As data is the fuel for AI, models trained on low-quality, biased data are often ineffective. Computer scientists who use AI invest a considerable amount of time and effort in preparing the data for AI. However, there are no standard methods or frameworks for assessing the \"readiness\" of data for AI. To provide a quantifiable assessment of the readiness of data for AI processes, we define parameters of AI data readiness and introduce AIDRIN (AI Data Readiness Inspector). AIDRIN is a framework covering a broad range of readiness dimensions available in the literature that aid in evaluating the readiness of data quantitatively and qualitatively. AIDRIN uses metrics in traditional data quality assessment such as completeness, outliers, and duplicates for data evaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI, such as feature importance, feature correlations, class imbalance, fairness, privacy, and FAIR (Findability, Accessibility, Interoperability, and Reusability) principle compliance. AIDRIN provides visualizations and reports to assist data scientists in further investigating the readiness of data. The AIDRIN framework enhances the efficiency of the machine learning pipeline to make informed decisions on data readiness for AI applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Online sorting and online TSP: randomized, stochastic, and high-dimensional", "authors": "Mikkel Abrahamsen, Ioana O. Bercea, Lorenzo Beretta, Jonas Klausen, L\u00e1szl\u00f3 Kozma", "subjects": "Subjects:\nData Structures and Algorithms (cs.DS); Computational Geometry (cs.CG)", "abstract": "In the online sorting problem, $n$ items are revealed one by one and have to be placed (immediately and irrevocably) into empty cells of a size-$n$ array. The goal is to minimize the sum of absolute differences between items in consecutive cells. This natural problem was recently introduced by Aamand, Abrahamsen, Beretta, and Kleist (SODA 2023) as a tool in their study of online geometric packing problems. They showed that when the items are reals from the interval $[0,1]$ a competitive ratio of $O(\\sqrt{n})$ is achievable, and no deterministic algorithm can improve this ratio asymptotically. In this paper, we extend and generalize the study of online sorting in three directions: - randomized: we settle the open question of Aamand et al. by showing that the $O(\\sqrt{n})$ competitive ratio for the online sorting of reals cannot be improved even with the use of randomness; - stochastic: we consider inputs consisting of $n$ samples drawn uniformly at random from an interval, and give an algorithm with an improved competitive ratio of $\\widetilde{O}(n^{1/4})$. The result reveals connections between online sorting and the design of efficient hash tables; - high-dimensional: we show that $\\widetilde{O}(\\sqrt{n})$-competitive online sorting is possible even for items from $\\mathbb{R}^d$, for arbitrary fixed $d$, in an adversarial model. This can be viewed as an online variant of the classical TSP problem where tasks (cities to visit) are revealed one by one and the salesperson assigns each task (immediately and irrevocably) to its timeslot. Along the way, we also show a tight $O(\\log{n})$-competitiveness result for uniform metrics, i.e., where items are of different types and the goal is to order them so as to minimize the number of switches between consecutive items of different types."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Leveraging Contrastive Learning for Enhanced Node Representations in Tokenized Graph Transformers", "authors": "Jinsong Chen, Hanpeng Liu, John E. Hopcroft, Kun He", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "While tokenized graph Transformers have demonstrated strong performance in node classification tasks, their reliance on a limited subset of nodes with high similarity scores for constructing token sequences overlooks valuable information from other nodes, hindering their ability to fully harness graph information for learning optimal node representations. To address this limitation, we propose a novel graph Transformer called GCFormer. Unlike previous approaches, GCFormer develops a hybrid token generator to create two types of token sequences, positive and negative, to capture diverse graph information. And a tailored Transformer-based backbone is adopted to learn meaningful node representations from these generated token sequences. Additionally, GCFormer introduces contrastive learning to extract valuable information from both positive and negative token sequences, enhancing the quality of learned node representations. Extensive experimental results across various datasets, including homophily and heterophily graphs, demonstrate the superiority of GCFormer in node classification, when compared to representative graph neural networks (GNNs) and graph Transformers."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Commodification of Compute", "authors": "Jesper Kristensen, David Wender, Carl Anthony", "subjects": "Subjects:\nComputational Engineering, Finance, and Science (cs.CE); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Emerging Technologies (cs.ET); General Economics (econ.GN)", "abstract": "The rapid advancements in artificial intelligence, big data analytics, and cloud computing have precipitated an unprecedented demand for computational resources. However, the current landscape of computational resource allocation is characterized by significant inefficiencies, including underutilization and price volatility. This paper addresses these challenges by introducing a novel global platform for the commodification of compute hours, termed the Global Compute Exchange (GCX) (Patent Pending). The GCX leverages blockchain technology and smart contracts to create a secure, transparent, and efficient marketplace for buying and selling computational power. The GCX is built in a layered fashion, comprising Market, App, Clearing, Risk Management, Exchange (Offchain), and Blockchain (Onchain) layers, each ensuring a robust and efficient operation. This platform aims to revolutionize the computational resource market by fostering a decentralized, efficient, and transparent ecosystem that ensures equitable access to computing power, stimulates innovation, and supports diverse user needs on a global scale. By transforming compute hours into a tradable commodity, the GCX seeks to optimize resource utilization, stabilize pricing, and democratize access to computational resources. This paper explores the technological infrastructure, market potential, and societal impact of the GCX, positioning it as a pioneering solution poised to drive the next wave of innovation in commodities and compute."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding", "authors": "Yue Fan, Lei Ding, Ching-Chen Kuo, Shan Jiang, Yang Zhao, Xinze Guan, Jie Yang, Yi Zhang, Xin Eric Wang", "subjects": "Subjects:\nComputation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Graphical User Interfaces (GUIs) are central to our interaction with digital devices. Recently, growing efforts have been made to build models for various GUI understanding tasks. However, these efforts largely overlook an important GUI-referring task: screen reading based on user-indicated points, which we name the Screen Point-and-Read (SPR) task. This task is predominantly handled by rigid accessible screen reading tools, in great need of new models driven by advancements in Multimodal Large Language Models (MLLMs). In this paper, we propose a Tree-of-Lens (ToL) agent, utilizing a novel ToL grounding mechanism, to address the SPR task. Based on the input point coordinate and the corresponding GUI screenshot, our ToL agent constructs a Hierarchical Layout Tree. Based on the tree, our ToL agent not only comprehends the content of the indicated area but also articulates the layout and spatial relationships between elements. Such layout information is crucial for accurately interpreting information on the screen, distinguishing our ToL agent from other screen reading tools. We also thoroughly evaluate the ToL agent against other baselines on a newly proposed SPR benchmark, which includes GUIs from mobile, web, and operating systems. Last but not least, we test the ToL agent on mobile GUI navigation tasks, demonstrating its utility in identifying incorrect actions along the path of agent execution trajectories. Code and data: this http URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          OCC-MP: A Max-Pressure framework to prioritize transit and high occupancy vehicles", "authors": "Tanveer Ahmed, Hao Liu, Vikash V. Gayah", "subjects": "Subjects:\nSystems and Control (eess.SY)", "abstract": "Max-pressure (MP) is a decentralized adaptive traffic signal control approach that has been shown to maximize throughput for private vehicles. However, MP-based signal control algorithms do not differentiate the movement of transit vehicles from private vehicles or between high and single-occupancy private vehicles. Prioritizing the movement of transit or other high occupancy vehicles (HOVs) is vital to reduce congestion and improve the reliability and efficiency of transit operations. This study proposes OCC-MP: a novel MP-based algorithm that considers both vehicle queues and passenger occupancies in computing the weights of movements. By weighing movements with higher passenger occupancies more heavily, transit and other HOVs are implicitly provided with priority, while accounting for any negative impacts of that priority on single occupancy vehicles. And, unlike rule-based transit signal priority (TSP) strategies, OCC-MP more naturally also accommodates conflicting transit routes at a signalized intersection and facilitates their movement, even in mixed traffic without dedicated lanes. Simulations on a grid network under varying demands and transit configurations demonstrate the effectiveness of OCC-MP at providing TSP while simultaneously reducing the negative impact imparted onto lower occupancy private vehicles. Furthermore, OCC-MP is shown to have a larger stable region for demand compared to rule-based TSP strategies integrated into the MP framework. The performance of OCC-MP is also shown to be robust to errors in passenger occupancy information from transit vehicles and can be applied when passenger occupancies of private vehicles are not available. Finally, OCC-MP can be applied in a partially connected vehicle (CV) environment when a subset of vehicles is able to provide information to the signal controller, outperforming baseline methods at low CV penetration rates."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AutoPureData: Automated Filtering of Web Data for LLM Fine-tuning", "authors": "Praneeth Vadlapati", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Up-to-date and reliable Large Language Models (LLMs) are consistently sought after. Typically, LLMs are trained on a fixed dataset and then deployed. However, the training data continually becomes outdated. Enable automatic training of AI using web data involves significant concerns regarding data quality and safety due to bias, spam, and other unsafe or unwanted text. Pure data is essential for producing reliable models. Training a model on impure data may result in undesirable outcomes. This research proposes a system that collects web data and automatically filters out unwanted text with the assistance of existing trusted AI models. In the experiment, a small sample of web data was collected and filtered, demonstrating the system's effectiveness in purifying the data."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Stochastic Concept Bottleneck Models", "authors": "Moritz Vandenhirtz, Sonia Laguna, Ri\u010dards Marcinkevi\u010ds, Julia E. Vogt", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Concept Bottleneck Models (CBMs) have emerged as a promising interpretable method whose final prediction is based on intermediate, human-understandable concepts rather than the raw input. Through time-consuming manual interventions, a user can correct wrongly predicted concept values to enhance the model's downstream performance. We propose Stochastic Concept Bottleneck Models (SCBMs), a novel approach that models concept dependencies. In SCBMs, a single-concept intervention affects all correlated concepts, thereby improving intervention effectiveness. Unlike previous approaches that model the concept relations via an autoregressive structure, we introduce an explicit, distributional parameterization that allows SCBMs to retain the CBMs' efficient training and inference procedure. Additionally, we leverage the parameterization to derive an effective intervention strategy based on the confidence region. We show empirically on synthetic tabular and natural image datasets that our approach improves intervention effectiveness significantly. Notably, we showcase the versatility and usability of SCBMs by examining a setting with CLIP-inferred concepts, alleviating the need for manual concept annotations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Insights into the Structured Coordination Game with Neutral Options through Simulation", "authors": "John S. McAlister, Nina H. Fefferman", "subjects": "Subjects:\nComputer Science and Game Theory (cs.GT); Dynamical Systems (math.DS)", "abstract": "Coordination games have been of interest to game theorists, economists, and ecologists for many years to study such problems as the emergence of local conventions and the evolution of cooperative behavior. Approaches for understanding the coordination game with discrete structure have been limited in scope, often relying on symmetric reduction of the state space, or other constraints which limit the power of the model to give insight into desired applications. In this paper, we introduce a new way of thinking about equilibria of the structured coordination game with neutral strategies by means of graph partitioning. We begin with a few elementary game theoretical results and then catalogue all the Nash equilibria of the coordination game with neutral options for graphs with seven or fewer vertices. We extend our observations through the use of simulation on larger Erd\u0151s-R\u00e9nyi random graphs to form the basis for proposing some conjectures about the general relationships among edge density, cluster number, and consensus stability."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          VERISCORE: Evaluating the factuality of verifiable claims in long-form text generation", "authors": "Yixiao Song, Yekyung Kim, Mohit Iyyer", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Existing metrics for evaluating the factuality of long-form text, such as FACTSCORE (Min et al., 2023) and SAFE (Wei et al., 2024), decompose an input text into \"atomic claims\" and verify each against a knowledge base like Wikipedia. These metrics are not suitable for most generation tasks because they assume that every claim is verifiable (i.e., can plausibly be proven true or false). We address this issue with VERISCORE, a metric for diverse long-form generation tasks that contain both verifiable and unverifiable content. VERISCORE can be effectively implemented with either closed or fine-tuned open-weight language models, and human evaluation confirms that VERISCORE's extracted claims are more sensible than those from competing methods across eight different long-form tasks. We use VERISCORE to evaluate generations from 16 different models across multiple long-form tasks and find that while GPT-4o is the best-performing model overall, open-weight models such as Mixtral-8x22 are closing the gap. We show that an LM's VERISCORE on one task (e.g., biography generation) does not necessarily correlate to its VERISCORE on a different task (e.g., long-form QA), highlighting the need for expanding factuality evaluation across tasks with varying fact density."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Emergence of Threads: The Birth of a New Social Network", "authors": "Peixian Zhang, Yupeng He, Ehsan-Ul Haq, Jiahui He, Gareth Tyson", "subjects": "Subjects:\nSocial and Information Networks (cs.SI)", "abstract": "Threads, a new microblogging platform from Meta, was launched in July 2023. In contrast to prior new platforms, Threads was borne out of an existing parent platform, Instagram, for which all users must already possess an account. This offers a unique opportunity to study platform evolution, to understand how one existing platform can support the \"birth\" of another. With this in mind, this paper provides an initial exploration of Threads, contrasting it with its parent, Instagram. We compare user behaviour within and across the two social media platforms, focusing on posting frequency, content preferences, and engagement patterns. Utilising a temporal analysis framework, we identify consistent daily posting trends on the parent platform and uncover contrasting behaviours when comparing intra-platform and cross-platform activities. Our findings reveal that Threads engages more with political and AI-related topics, compared to Instagram which focuses more on lifestyle and fashion topics. Our analysis also shows that user activities align more closely on weekends across both platforms. Engagement analysis suggests that users prefer to post about topics that garner more likes and that topic consistency is maintained when users transition from Instagram to Threads. Our research provides insights into user behaviour and offers a basis for future studies on Threads."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale", "authors": "Junying Chen, Ruyi Ouyang, Anningzhe Gao, Shunian Chen, Guiming Hardy Chen, Xidong Wang, Ruifei Zhang, Zhenyang Cai, Ke Ji, Guangjun Yu, Xiang Wan, Benyou Wang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "The rapid development of multimodal large language models (MLLMs), such as GPT-4V, has led to significant advancements. However, these models still face challenges in medical multimodal capabilities due to limitations in the quantity and quality of medical vision-text data, stemming from data privacy concerns and high annotation costs. While pioneering approaches utilize PubMed's large-scale, de-identified medical image-text pairs to address these limitations, they still fall short due to inherent data noise. To tackle this, we refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in an 'unblinded' capacity to denoise and reformat the data, resulting in the creation of the PubMedVision dataset with 1.3 million medical VQA samples. Our validation demonstrates that: (1) PubMedVision can significantly enhance the medical multimodal capabilities of current MLLMs, showing significant improvement in benchmarks including the MMMU Health & Medicine track; (2) manual checks by medical experts and empirical results validate the superior data quality of our dataset compared to other data construction methods. Using PubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows superior performance in medical multimodal scenarios among open-source MLLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Grounded and Transparent Response Generation for Conversational Information-Seeking Systems", "authors": "Weronika \u0141ajewska", "subjects": "Subjects:\nInformation Retrieval (cs.IR)", "abstract": "While previous conversational information-seeking (CIS) research has focused on passage retrieval, reranking, and query rewriting, the challenge of synthesizing retrieved information into coherent responses remains. The proposed research delves into the intricacies of response generation in CIS systems. Open-ended information-seeking dialogues introduce multiple challenges that may lead to potential pitfalls in system responses. The study focuses on generating responses grounded in the retrieved passages and being transparent about the system's limitations. Specific research questions revolve around obtaining confidence-enriched information nuggets, automatic detection of incomplete or incorrect responses, generating responses communicating the system's limitations, and evaluating enhanced responses. By addressing these research tasks the study aspires to contribute to the advancement of conversational response generation, fostering more trustworthy interactions in CIS dialogues, and paving the way for grounded and transparent systems to meet users' needs in an information-driven world."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          PhysioLLM: Supporting Personalized Health Insights with Wearables and Large Language Models", "authors": "Cathy Mengying Fang, Valdemar Danry, Nathan Whitmore, Andria Bao, Andrew Hutchison, Cayden Pierce, Pattie Maes", "subjects": "Subjects:\nHuman-Computer Interaction (cs.HC)", "abstract": "We present PhysioLLM, an interactive system that leverages large language models (LLMs) to provide personalized health understanding and exploration by integrating physiological data from wearables with contextual information. Unlike commercial health apps for wearables, our system offers a comprehensive statistical analysis component that discovers correlations and trends in user data, allowing users to ask questions in natural language and receive generated personalized insights, and guides them to develop actionable goals. As a case study, we focus on improving sleep quality, given its measurability through physiological data and its importance to general well-being. Through a user study with 24 Fitbit watch users, we demonstrate that PhysioLLM outperforms both the Fitbit App alone and a generic LLM chatbot in facilitating a deeper, personalized understanding of health data and supporting actionable steps toward personal health goals."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Human Modelling and Pose Estimation Overview", "authors": "Pawel Knap", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Human modelling and pose estimation stands at the crossroads of Computer Vision, Computer Graphics, and Machine Learning. This paper presents a thorough investigation of this interdisciplinary field, examining various algorithms, methodologies, and practical applications. It explores the diverse range of sensor technologies relevant to this domain and delves into a wide array of application areas. Additionally, we discuss the challenges and advancements in 2D and 3D human modelling methodologies, along with popular datasets, metrics, and future research directions. The main contribution of this paper lies in its up-to-date comparison of state-of-the-art (SOTA) human pose estimation algorithms in both 2D and 3D domains. By providing this comprehensive overview, the paper aims to enhance understanding of 3D human modelling and pose estimation, offering insights into current SOTA achievements, challenges, and future prospects within the field."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Wikipedia Citations: Reproducible Citation Extraction from Multilingual Wikipedia", "authors": "Natallia Kokash, Giovanni Colavizza", "subjects": "Subjects:\nDigital Libraries (cs.DL)", "abstract": "Wikipedia is an essential component of the open science ecosystem, yet it is poorly integrated with academic open science initiatives. Wikipedia Citations is a project that focuses on extracting and releasing comprehensive datasets of citations from Wikipedia. A total of 29.3 million citations were extracted from English Wikipedia in May 2020. Following this one-off research project, we designed a reproducible pipeline that can process any given Wikipedia dump in the cloud-based settings. To demonstrate its usability, we extracted 40.6 million citations in February 2023 and 44.7 million citations in February 2024. Furthermore, we equipped the pipeline with an adapted Wikipedia citation template translation module to process multilingual Wikipedia articles in 15 European languages so that they are parsed and mapped into a generic structured citation template. This paper presents our open-source software pipeline to retrieve, classify, and disambiguate citations on demand from a given Wikipedia dump."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data", "authors": "Zheyang Xiong, Vasilis Papageorgiou, Kangwook Lee, Dimitris Papailiopoulos", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Recent studies have shown that Large Language Models (LLMs) struggle to accurately retrieve information and maintain reasoning capabilities when processing long-context inputs. To address these limitations, we propose a finetuning approach utilizing a carefully designed synthetic dataset comprising numerical key-value retrieval tasks. Our experiments on models like GPT-3.5 Turbo and Mistral 7B demonstrate that finetuning LLMs on this dataset significantly improves LLMs' information retrieval and reasoning capabilities in longer-context settings. We present an analysis of the finetuned models, illustrating the transfer of skills from synthetic to real task evaluations (e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5 Turbo). We also find that finetuned LLMs' performance on general benchmarks remains almost constant while LLMs finetuned on other baseline long-context augmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B finetuned on our synthetic data cause no performance drop while other baseline data can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study highlights the potential of finetuning on synthetic data for improving the performance of LLMs on longer-context tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Vehicle-to-Grid Technology meets Packetized Energy Management: A Co-Simulation Study", "authors": "Freddy Tuxworth, Adnan Aijaz", "subjects": "Subjects:\nNetworking and Internet Architecture (cs.NI)", "abstract": "The global energy landscape is experiencing a significant transformation driven by increased awareness of climate change and rapid technological advancements in renewable energy and electric vehicles (EVs). Packetized energy management (PEM) schemes are gaining attention as a potential solution for power management for effective load control. This study presents the development of a co-simulation platform to investigate integration of vehicle-to-grid (V2G) with packetized energy trading (PET) in microgrid scenarios. The platform facilitates the interaction between EVs and prosumers, with a focus on responsive loads, and solar photovoltaic (PV) as intermittently available resources. Using the developed co-simulation, this study evaluates how V2G-capable EVs can enhance the stability and efficiency of PET-based microgrids. The results demonstrate the capability of V2G EVs to act as an energy reservoir, effectively managing demand-side load, thus mitigating its fluctuation from available supply while maintaining quality-of-service."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enhancing Continual Learning in Visual Question Answering with Modality-Aware Feature Distillation", "authors": "Malvina Nikandrou, Georgios Pantazopoulos, Ioannis Konstas, Alessandro Suglia", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Continual learning focuses on incrementally training a model on a sequence of tasks with the aim of learning new tasks while minimizing performance drop on previous tasks. Existing approaches at the intersection of Continual Learning and Visual Question Answering (VQA) do not study how the multimodal nature of the input affects the learning dynamics of a model. In this paper, we demonstrate that each modality evolves at different rates across a continuum of tasks and that this behavior occurs in established encoder-only models as well as modern recipes for developing Vision & Language (VL) models. Motivated by this observation, we propose a modality-aware feature distillation (MAFED) approach which outperforms existing baselines across models of varying scale in three multimodal continual learning settings. Furthermore, we provide ablations showcasing that modality-aware distillation complements experience replay. Overall, our results emphasize the importance of addressing modality-specific dynamics to prevent forgetting in multimodal continual learning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Compositional Image Decomposition with Diffusion Models", "authors": "Jocelin Su, Nan Liu, Yanbo Wang, Joshua B. Tenenbaum, Yilun Du", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Given an image of a natural scene, we are able to quickly decompose it into a set of components such as objects, lighting, shadows, and foreground. We can then envision a scene where we combine certain components with those from other images, for instance a set of objects from our bedroom and animals from a zoo under the lighting conditions of a forest, even if we have never encountered such a scene before. In this paper, we present a method to decompose an image into such compositional components. Our approach, Decomp Diffusion, is an unsupervised method which, when given a single image, infers a set of different components in the image, each represented by a diffusion model. We demonstrate how components can capture different factors of the scene, ranging from global scene descriptors like shadows or facial expression to local scene descriptors like constituent objects. We further illustrate how inferred factors can be flexibly composed, even with factors inferred from other models, to generate a variety of scenes sharply different than those seen in training time. Website and code at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          PNeRV: A Polynomial Neural Representation for Videos", "authors": "Sonam Gupta, Snehal Singh Tomar, Grigorios G Chrysos, Sukhendu Das, A. N. Rajagopalan", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Extracting Implicit Neural Representations (INRs) on video data poses unique challenges due to the additional temporal dimension. In the context of videos, INRs have predominantly relied on a frame-only parameterization, which sacrifices the spatiotemporal continuity observed in pixel-level (spatial) representations. To mitigate this, we introduce Polynomial Neural Representation for Videos (PNeRV), a parameter-wise efficient, patch-wise INR for videos that preserves spatiotemporal continuity. PNeRV leverages the modeling capabilities of Polynomial Neural Networks to perform the modulation of a continuous spatial (patch) signal with a continuous time (frame) signal. We further propose a custom Hierarchical Patch-wise Spatial Sampling Scheme that ensures spatial continuity while retaining parameter efficiency. We also employ a carefully designed Positional Embedding methodology to further enhance PNeRV's performance. Our extensive experimentation demonstrates that PNeRV outperforms the baselines in conventional Implicit Neural Representation tasks like compression along with downstream applications that require spatiotemporal continuity in the underlying representation. PNeRV not only addresses the challenges posed by video data in the realm of INRs but also opens new avenues for advanced video processing and analysis."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          scTree: Discovering Cellular Hierarchies in the Presence of Batch Effects in scRNA-seq Data", "authors": "Moritz Vandenhirtz, Florian Barkmann, Laura Manduchi, Julia E. Vogt, Valentina Boeva", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "We propose a novel method, scTree, for single-cell Tree Variational Autoencoders, extending a hierarchical clustering approach to single-cell RNA sequencing data. scTree corrects for batch effects while simultaneously learning a tree-structured data representation. This VAE-based method allows for a more in-depth understanding of complex cellular landscapes independently of the biasing effects of batches. We show empirically on seven datasets that scTree discovers the underlying clusters of the data and the hierarchical relations between them, as well as outperforms established baseline methods across these datasets. Additionally, we analyze the learned hierarchy to understand its biological relevance, thus underpinning the importance of integrating batch correction directly into the clustering procedure."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MCNC: Manifold Constrained Network Compression", "authors": "Chayne Thrash, Ali Abbasi, Parsa Nooralinejad, Soroush Abbasi Koohpayegani, Reed Andreas, Hamed Pirsiavash, Soheil Kolouri", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "The outstanding performance of large foundational models across diverse tasks-from computer vision to speech and natural language processing-has significantly increased their demand. However, storing and transmitting these models pose significant challenges due to their massive size (e.g., 350GB for GPT-3). Recent literature has focused on compressing the original weights or reducing the number of parameters required for fine-tuning these models. These compression methods typically involve constraining the parameter space, for example, through low-rank reparametrization (e.g., LoRA) or quantization (e.g., QLoRA) during model training. In this paper, we present MCNC as a novel model compression method that constrains the parameter space to low-dimensional pre-defined and frozen nonlinear manifolds, which effectively cover this space. Given the prevalence of good solutions in over-parameterized deep neural networks, we show that by constraining the parameter space to our proposed manifold, we can identify high-quality solutions while achieving unprecedented compression rates across a wide variety of tasks. Through extensive experiments in computer vision and natural language processing tasks, we demonstrate that our method, MCNC, significantly outperforms state-of-the-art baselines in terms of compression, accuracy, and/or model reconstruction time."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Mapping Land Naturalness from Sentinel-2 using Deep Contextual and Geographical Priors", "authors": "Burak Ekim, Michael Schmitt", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "In recent decades, the causes and consequences of climate change have accelerated, affecting our planet on an unprecedented scale. This change is closely tied to the ways in which humans alter their surroundings. As our actions continue to impact natural areas, using satellite images to observe and measure these effects has become crucial for understanding and combating climate change. Aiming to map land naturalness on the continuum of modern human pressure, we have developed a multi-modal supervised deep learning framework that addresses the unique challenges of satellite data and the task at hand. We incorporate contextual and geographical priors, represented by corresponding coordinate information and broader contextual information, including and surrounding the immediate patch to be predicted. Our framework improves the model's predictive performance in mapping land naturalness from Sentinel-2 data, a type of multi-spectral optical satellite imagery. Recognizing that our protective measures are only as effective as our understanding of the ecosystem, quantifying naturalness serves as a crucial step toward enhancing our environmental stewardship."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Understanding Routing-Induced Censorship Changes Globally", "authors": "Abhishek Bhaskar, Paul Pearce", "subjects": "Subjects:\nNetworking and Internet Architecture (cs.NI); Cryptography and Security (cs.CR)", "abstract": "Internet censorship is pervasive, with significant effort dedicated to understanding what is censored, and where. Prior censorship work however have identified significant inconsistencies in their results; experiments show unexplained non-determinism thought to be caused by censor load, end-host geographic diversity, or incomplete censorship -- inconsistencies which impede reliable, repeatable and correct understanding of global censorship. In this work we investigate the extent to which Equal-cost Multi-path (ECMP) routing is the cause for these inconsistencies, developing methods to measure and compensate for them. We find ECMP routing significantly changes observed censorship across protocols, censor mechanisms, and in 17 countries. We identify that previously observed non-determinism or regional variations are attributable to measurements between fixed end-hosts taking different routes based on Flow-ID; i.e., choice of intra-subnet source IP or ephemeral source port leads to differences in observed censorship. To achieve this we develop new route-stable censorship measurement methods that allow consistent measurement of DNS, HTTP, and HTTPS censorship. We find ECMP routing yields censorship changes across 42% of IPs and 51% of ASes, but that impact is not uniform. We identify numerous causes of the behavior, ranging from likely failed infrastructure, to routes to the same end-host taking geographically diverse paths which experience differences in censorship en-route. Finally, we explore our results in the context of prior global measurement studies, exploring first the applicability of our findings to prior observed variations, and then demonstrating how specific experiments from two studies could be impacted by, and specific results are explainable by, ECMP routing. Our work points to methods for improving future studies, reducing inconsistencies and increasing repeatability."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Max Pressure Algorithm for Traffic Signals Considering Pedestrian Queues", "authors": "Hao Liu, Vikash V. Gayah, Michael Levin", "subjects": "Subjects:\nSystems and Control (eess.SY)", "abstract": "This paper proposes a novel max-pressure (MP) algorithm that incorporates pedestrian traffic into the MP control architecture. Pedestrians are modeled as being included in one of two groups: those walking on sidewalks and those queued at intersections waiting to cross. Traffic dynamics models for both groups are developed. Under the proposed control policy, the signal timings are determined based on the queue length of both vehicles and pedestrians waiting to cross the intersection. The proposed algorithm maintains the decentralized control structure, and the paper proves that it also exhibits the maximum stability property for both vehicles and pedestrians. Microscopic traffic simulation results demonstrate that the proposed model can improve the overall operational efficiency -- i.e., reduce person travel delays -- under various vehicle demand levels compared to the original queue-based MP (Q-MP) algorithm and a recently developed rule-based MP algorithm considering pedestrians. The Q-MP ignores the yielding behavior of right-turn vehicles to conflicting pedestrian movements, which leads to high delay for vehicles. On the other hand, the delay incurred by pedestrians is high from the rule-based model since it imposes large waiting time tolerance to guarantee the operational efficiency of vehicles. The proposed algorithm outperforms both models since the states of both vehicles and pedestrians are taken into consideration to determine signal timings."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Odyssey of Commonsense Causality: From Foundational Benchmarks to Cutting-Edge Reasoning", "authors": "Shaobo Cui, Zhijing Jin, Bernhard Sch\u00f6lkopf, Boi Faltings", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Understanding commonsense causality is a unique mark of intelligence for humans. It helps people understand the principles of the real world better and benefits the decision-making process related to causation. For instance, commonsense causality is crucial in judging whether a defendant's action causes the plaintiff's loss in determining legal liability. Despite its significance, a systematic exploration of this topic is notably lacking. Our comprehensive survey bridges this gap by focusing on taxonomies, benchmarks, acquisition methods, qualitative reasoning, and quantitative measurements in commonsense causality, synthesizing insights from over 200 representative articles. Our work aims to provide a systematic overview, update scholars on recent advancements, provide a pragmatic guide for beginners, and highlight promising future research directions in this vital field."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Which Neurons Matter in IR? Applying Integrated Gradients-based Methods to Understand Cross-Encoders", "authors": "Mathias Vast, Basile Van Cooten, Laure Soulier, Benjamin Piwowarski", "subjects": "Subjects:\nInformation Retrieval (cs.IR)", "abstract": "With the recent addition of Retrieval-Augmented Generation (RAG), the scope and importance of Information Retrieval (IR) has expanded. As a result, the importance of a deeper understanding of IR models also increases. However, interpretability in IR remains under-explored, especially when it comes to the models' inner mechanisms. In this paper, we explore the possibility of adapting Integrated Gradient-based methods in an IR context to identify the role of individual neurons within the model. In particular, we provide new insights into the role of what we call \"relevance\" neurons, as well as how they deal with unseen data. Finally, we carry out an in-depth pruning study to validate our findings."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Zero-Query Adversarial Attack on Black-box Automatic Speech Recognition Systems", "authors": "Zheng Fang, Tao Wang, Lingchen Zhao, Shenyi Zhang, Bowen Li, Yunjie Ge, Qi Li, Chao Shen, Qian Wang", "subjects": "Subjects:\nCryptography and Security (cs.CR); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "abstract": "In recent years, extensive research has been conducted on the vulnerability of ASR systems, revealing that black-box adversarial example attacks pose significant threats to real-world ASR systems. However, most existing black-box attacks rely on queries to the target ASRs, which is impractical when queries are not permitted. In this paper, we propose ZQ-Attack, a transfer-based adversarial attack on ASR systems in the zero-query black-box setting. Through a comprehensive review and categorization of modern ASR technologies, we first meticulously select surrogate ASRs of diverse types to generate adversarial examples. Following this, ZQ-Attack initializes the adversarial perturbation with a scaled target command audio, rendering it relatively imperceptible while maintaining effectiveness. Subsequently, to achieve high transferability of adversarial perturbations, we propose a sequential ensemble optimization algorithm, which iteratively optimizes the adversarial perturbation on each surrogate model, leveraging collaborative information from other models. We conduct extensive experiments to evaluate ZQ-Attack. In the over-the-line setting, ZQ-Attack achieves a 100% success rate of attack (SRoA) with an average signal-to-noise ratio (SNR) of 21.91dB on 4 online speech recognition services, and attains an average SRoA of 100% and SNR of 19.67dB on 16 open-source ASRs. For commercial intelligent voice control devices, ZQ-Attack also achieves a 100% SRoA with an average SNR of 15.77dB in the over-the-air setting."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On Transition Constructions for Automata -- A Categorical Perspective", "authors": "Mike Cruchten", "subjects": "Subjects:\nFormal Languages and Automata Theory (cs.FL)", "abstract": "We investigate the transition monoid construction for deterministic automata in a categorical setting and establish it as an adjunction. We pair this adjunction with two other adjunctions to obtain two endofunctors on deterministic automata, a comonad and a monad, which are closely related, respectively, to the largest set of equations and the smallest set of coequations satisfied by an automaton. Furthermore, we give similar transition algebra constructions for lasso and {\\Omega}-automata, and show that they form adjunctions. We present some initial results on sets of equations and coequations for lasso automata."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          LiveBench: A Challenging, Contamination-Free LLM Benchmark", "authors": "Colin White, Samuel Dooley, Manley Roberts, Arka Pal, Ben Feuer, Siddhartha Jain, Ravid Shwartz-Ziv, Neel Jain, Khalid Saifullah, Siddartha Naidu, Chinmay Hegde, Yann LeCun, Tom Goldstein, Willie Neiswanger, Micah Goldblum", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer model's training set, is a well-documented obstacle for fair LLM evaluation and can quickly render benchmarks obsolete. To mitigate this, many recent benchmarks crowdsource new prompts and evaluations from human or LLM judges; however, these can introduce significant biases, and break down when scoring hard questions. In this work, we introduce a new benchmark for LLMs designed to be immune to both test set contamination and the pitfalls of LLM judging and human crowdsourcing. We release LiveBench, the first benchmark that (1) contains frequently-updated questions from recent information sources, (2) scores answers automatically according to objective ground-truth values, and (3) contains a wide variety of challenging tasks, spanning math, coding, reasoning, language, instruction following, and data analysis. To achieve this, LiveBench contains questions that are based on recently-released math competitions, arXiv papers, news articles, and datasets, and it contains harder, contamination-free versions of tasks from previous benchmarks such as Big-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source models, as well as dozens of open-source models ranging from 0.5B to 110B in size. LiveBench is difficult, with top models achieving below 65% accuracy. We release all questions, code, and model answers. Questions will be added and updated on a monthly basis, and we will release new tasks and harder versions of tasks over time so that LiveBench can distinguish between the capabilities of LLMs as they improve in the future. We welcome community engagement and collaboration for expanding the benchmark tasks and models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enhanced Data Transfer Cooperating with Artificial Triplets for Scene Graph Generation", "authors": "KuanChao Chu, Satoshi Yamazaki, Hideki Nakayama", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "This work focuses on training dataset enhancement of informative relational triplets for Scene Graph Generation (SGG). Due to the lack of effective supervision, the current SGG model predictions perform poorly for informative relational triplets with inadequate training samples. Therefore, we propose two novel training dataset enhancement modules: Feature Space Triplet Augmentation (FSTA) and Soft Transfer. FSTA leverages a feature generator trained to generate representations of an object in relational triplets. The biased prediction based sampling in FSTA efficiently augments artificial triplets focusing on the challenging ones. In addition, we introduce Soft Transfer, which assigns soft predicate labels to general relational triplets to make more supervisions for informative predicate classes effectively. Experimental results show that integrating FSTA and Soft Transfer achieve high levels of both Recall and mean Recall in Visual Genome dataset. The mean of Recall and mean Recall is the highest among all the existing model-agnostic methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Jump Starting Bandits with LLM-Generated Prior Knowledge", "authors": "Parand A. Alamdari, Yanshuai Cao, Kevin H. Wilson", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "We present substantial evidence demonstrating the benefits of integrating Large Language Models (LLMs) with a Contextual Multi-Armed Bandit framework. Contextual bandits have been widely used in recommendation systems to generate personalized suggestions based on user-specific contexts. We show that LLMs, pre-trained on extensive corpora rich in human knowledge and preferences, can simulate human behaviours well enough to jump-start contextual multi-armed bandits to reduce online learning regret. We propose an initialization algorithm for contextual bandits by prompting LLMs to produce a pre-training dataset of approximate human preferences for the bandit. This significantly reduces online learning regret and data-gathering costs for training such models. Our approach is validated empirically through two sets of experiments with different bandit setups: one which utilizes LLMs to serve as an oracle and a real-world experiment utilizing data from a conjoint survey experiment."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Efficient World Models with Context-Aware Tokenization", "authors": "Vincent Micheli, Eloi Alonso, Fran\u00e7ois Fleuret", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Scaling up deep Reinforcement Learning (RL) methods presents a significant challenge. Following developments in generative modelling, model-based RL positions itself as a strong contender. Recent advances in sequence modelling have led to effective transformer-based world models, albeit at the price of heavy computations due to the long sequences of tokens required to accurately simulate environments. In this work, we propose $\\Delta$-IRIS, a new agent with a world model architecture composed of a discrete autoencoder that encodes stochastic deltas between time steps and an autoregressive transformer that predicts future deltas by summarizing the current state of the world with continuous tokens. In the Crafter benchmark, $\\Delta$-IRIS sets a new state of the art at multiple frame budgets, while being an order of magnitude faster to train than previous attention-based approaches. We release our code and models at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Multimodal Visual-haptic pose estimation in the presence of transient occlusion", "authors": "Michael Zechmair, Yannick Morel", "subjects": "Subjects:\nRobotics (cs.RO)", "abstract": "Human-robot collaboration requires the establishment of methods to guarantee the safety of participating operators. A necessary part of this process is ensuring reliable human pose estimation. Established vision-based modalities encounter problems when under conditions of occlusion. This article describes the combination of two perception modalities for pose estimation in environments containing such transient occlusion. We first introduce a vision-based pose estimation method, based on a deep Predictive Coding (PC) model featuring robustness to partial occlusion. Next, capacitive sensing hardware capable of detecting various objects is introduced. The sensor is compact enough to be mounted on the exterior of any given robotic system. The technology is particularly well-suited to detection of capacitive material, such as living tissue. Pose estimation from the two individual sensing modalities is combined using a modified Luenberger observer model. We demonstrate that the results offer better performance than either sensor alone. The efficacy of the system is demonstrated on an environment containing a robot arm and a human, showing the ability to estimate the pose of a human forearm under varying levels of occlusion."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Subtractive Training for Music Stem Insertion using Latent Diffusion Models", "authors": "Ivan Villa-Renteria, Mason L. Wang, Zachary Shah, Zhe Li, Soohyun Kim, Neelesh Ramachandran, Mert Pilanci", "subjects": "Subjects:\nSound (cs.SD); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)", "abstract": "We present Subtractive Training, a simple and novel method for synthesizing individual musical instrument stems given other instruments as context. This method pairs a dataset of complete music mixes with 1) a variant of the dataset lacking a specific stem, and 2) LLM-generated instructions describing how the missing stem should be reintroduced. We then fine-tune a pretrained text-to-audio diffusion model to generate the missing instrument stem, guided by both the existing stems and the text instruction. Our results demonstrate Subtractive Training's efficacy in creating authentic drum stems that seamlessly blend with the existing tracks. We also show that we can use the text instruction to control the generation of the inserted stem in terms of rhythm, dynamics, and genre, allowing us to modify the style of a single instrument in a full song while keeping the remaining instruments the same. Lastly, we extend this technique to MIDI formats, successfully generating compatible bass, drum, and guitar parts for incomplete arrangements."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Multi-RIS-Empowered Multiple Access: A Distributed Sum-Rate Maximization Approach", "authors": "Konstantinos D. Katsanos, Paolo Di Lorenzo, George C. Alexandropoulos", "subjects": "Subjects:\nInformation Theory (cs.IT); Signal Processing (eess.SP)", "abstract": "The plethora of wirelessly connected devices, whose deployment density is expected to largely increase in the upcoming sixth Generation (6G) of wireless networks, will naturally necessitate substantial advances in multiple access schemes. Reconfigurable Intelligent Surfaces (RISs) constitute a candidate 6G technology capable to offer dynamic over-the-air signal propagation programmability, which can be optimized for efficient non-orthogonal access of a multitude of devices. In this paper, we study the downlink of a wideband communication system comprising multiple multi-antenna Base Stations (BSs), each wishing to serve an associated single-antenna user via the assistance of a Beyond Diagonal (BD) and frequency-selective RIS. Under the assumption that each BS performs Orthogonal Frequency Division Multiplexing (OFDM) transmissions and exclusively controls a distinct RIS, we focus on the sum-rate maximization problem and present a distributed joint design of the linear precoders at the BSs as well as the tunable capacitances and the switch selection matrices at the multiple BD RISs. The formulated non-convex design optimization problem is solved via successive concave approximation necessitating minimal cooperation among the BSs. Our extensive simulation results showcase the performance superiority of the proposed cooperative scheme over non-cooperation benchmarks, indicating the performance gains with BD RISs via the presented optimized frequency selective operation for various scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Synthetic Embedding of Hidden Information in Industrial Control System Network Protocols for Evaluation of Steganographic Malware", "authors": "Tom Neubert, Bjarne Peuker, Laura Buxhoidt, Eric Schueler, Claus Vielhauer", "subjects": "Subjects:\nCryptography and Security (cs.CR)", "abstract": "For the last several years, the embedding of hidden information by steganographic techniques in network communications is increasingly used by attackers in order to obscure data infiltration, exfiltration or command and control in IT (information technology) and OT (operational technology) systems. Especially industrial control systems (ICS) and critical infrastructures have increased protection requirements. Currently, network defense mechanisms are unfortunately quite ineffective against novel attacks based on network steganography. Thus, on the one hand huge amounts of network data with steganographic embedding is required to train, evaluate and improve defense mechanisms. On the other hand, the real-time embedding of hidden information in productive ICS networks is crucial due to safety violations. Additionally it is time consuming because it needs special laboratory setup. To address this challenge, this work introduces an embedding concept to gene ate synthetic steganographic network data to automatically produce significant amounts of data for training and evaluation of defense mechanisms. The concept enables the possibility to manipulate a network packet wherever required and outperforms the state-of-the-art in terms of embedding pace significantly."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Rational Empirical Interpolation Methods with Applications", "authors": "Aidi Li, Yuwen Li", "subjects": "Subjects:\nNumerical Analysis (math.NA)", "abstract": "We present a rational empirical interpolation method for interpolating a family of parametrized functions to rational polynomials with invariant poles, leading to efficient numerical algorithms for space-fractional differential equations, parameter-robust preconditioning, and evaluation of matrix functions. Compared to classical rational approximation algorithms, the proposed method is more efficient for approximating a large number of target functions. In addition, we derive a convergence estimate of our rational approximation algorithm using the metric entropy numbers. Numerical experiments are included to demonstrate the effectiveness of the proposed method."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Learning Visual Conditioning Tokens to Correct Domain Shift for Fully Test-time Adaptation", "authors": "Yushun Tang, Shuoshuo Chen, Zhehan Kan, Yi Zhang, Qinghai Guo, Zhihai He", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Fully test-time adaptation aims to adapt the network model based on sequential analysis of input samples during the inference stage to address the cross-domain performance degradation problem of deep neural networks. This work is based on the following interesting finding: in transformer-based image classification, the class token at the first transformer encoder layer can be learned to capture the domain-specific characteristics of target samples during test-time adaptation. This learned token, when combined with input image patch embeddings, is able to gradually remove the domain-specific information from the feature representations of input samples during the transformer encoding process, thereby significantly improving the test-time adaptation performance of the source model across different domains. We refer to this class token as visual conditioning token (VCT). To successfully learn the VCT, we propose a bi-level learning approach to capture the long-term variations of domain-specific characteristics while accommodating local variations of instance-specific characteristics. Experimental results on the benchmark datasets demonstrate that our proposed bi-level visual conditioning token learning method is able to achieve significantly improved test-time adaptation performance by up to 1.9%."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Unconditional Stability Analysis of N-Port Networks Based on Structured Singular Value Computation", "authors": "Aimar Mateo, Ibone Lizarraga, Jorge Terrer, Aitziber Anakabe, J.M Collantes", "subjects": "Subjects:\nSystems and Control (eess.SY)", "abstract": "In this paper, a novel approach based on robust stability concepts and tools is introduced to evaluate the unconditional stability of microwave active $\\textit{n}$-port devices. An efficient calculation of the Structured Singular Value of the $\\textit{n}$x$\\textit{n}$ scattering matrix is proposed to obtain the stability characteristics of the device. The presented method is validated in two ways. First, it is applied to a referential 4x4 scattering parameter set for independent verification. Second, the method is applied to a 4-port GaAs FET amplifier fabricated in hybrid technology. The results confirm the validity and computational efficiency of the proposed approach."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language", "authors": "Lucky Susanto, Musa Izzanardi Wijanarko, Prasetia Anugrah Pratama, Traci Hong, Ika Idris, Alham Fikri Aji, Derry Wijaya", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Hate speech poses a significant threat to social harmony. Over the past two years, Indonesia has seen a ten-fold increase in the online hate speech ratio, underscoring the urgent need for effective detection mechanisms. However, progress is hindered by the limited availability of labeled data for Indonesian texts. The condition is even worse for marginalized minorities, such as Shia, LGBTQ, and other ethnic minorities because hate speech is underreported and less understood by detection tools. Furthermore, the lack of accommodation for subjectivity in current datasets compounds this issue. To address this, we introduce IndoToxic2024, a comprehensive Indonesian hate speech and toxicity classification dataset. Comprising 43,692 entries annotated by 19 diverse individuals, the dataset focuses on texts targeting vulnerable groups in Indonesia, specifically during the hottest political event in the country: the presidential election. We establish baselines for seven binary classification tasks, achieving a macro-F1 score of 0.78 with a BERT model (IndoBERTweet) fine-tuned for hate speech classification. Furthermore, we demonstrate how incorporating demographic information can enhance the zero-shot performance of the large language model, gpt-3.5-turbo. However, we also caution that an overemphasis on demographic information can negatively impact the fine-tuned model performance due to data fragmentation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Dynamical Analysis of Autobidding Systems", "authors": "Renato Paes Leme, Georgios Piliouras, Jon Schneider, Kelly Spendlove, Song Zuo", "subjects": "Subjects:\nComputer Science and Game Theory (cs.GT)", "abstract": "It has become the default in markets such as ad auctions for participants to bid in an auction through automated bidding agents (autobidders) which adjust bids over time to satisfy return-over-spend constraints. Despite the prominence of such systems for the internet economy, their resulting dynamical behavior is still not well understood. Although one might hope that such relatively simple systems would typically converge to the equilibria of their underlying auctions, we provide a plethora of results that show the emergence of complex behavior, such as bi-stability, periodic orbits and quasi periodicity. We empirically observe how the market structure (expressed as motifs) qualitatively affects the behavior of the dynamics. We complement it with theoretical results showing that autobidding systems can simulate both linear dynamical systems as well logical boolean gates."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CORE4D: A 4D Human-Object-Human Interaction Dataset for Collaborative Object REarrangement", "authors": "Chengwen Zhang, Yun Liu, Ruofan Xing, Bingda Tang, Li Yi", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Understanding how humans cooperatively rearrange household objects is critical for VR/AR and human-robot interaction. However, in-depth studies on modeling these behaviors are under-researched due to the lack of relevant datasets. We fill this gap by presenting CORE4D, a novel large-scale 4D human-object-human interaction dataset focusing on collaborative object rearrangement, which encompasses diverse compositions of various object geometries, collaboration modes, and 3D scenes. With 1K human-object-human motion sequences captured in the real world, we enrich CORE4D by contributing an iterative collaboration retargeting strategy to augment motions to a variety of novel objects. Leveraging this approach, CORE4D comprises a total of 11K collaboration sequences spanning 3K real and virtual object shapes. Benefiting from extensive motion patterns provided by CORE4D, we benchmark two tasks aiming at generating human-object interaction: human-object motion forecasting and interaction synthesis. Extensive experiments demonstrate the effectiveness of our collaboration retargeting strategy and indicate that CORE4D has posed new challenges to existing human-object interaction generation methodologies. Our dataset and code are available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?", "authors": "Peter Hase, Thomas Hofweber, Xiang Zhou, Elias Stengel-Eskin, Mohit Bansal", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "The model editing problem concerns how language models should learn new facts about the world over time. While empirical research on model editing has drawn widespread attention, the conceptual foundations of model editing remain shaky -- perhaps unsurprisingly, since model editing is essentially belief revision, a storied problem in philosophy that has eluded succinct solutions for decades. Model editing nonetheless demands a solution, since we need to be able to control the knowledge within language models. With this goal in mind, this paper critiques the standard formulation of the model editing problem and proposes a formal testbed for model editing research. We first describe 12 open problems with model editing, based on challenges with (1) defining the problem, (2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the first place. Many of these challenges are extremely difficult to address, e.g. determining far-reaching consequences of edits, labeling probabilistic entailments between facts, and updating beliefs of agent simulators. Next, we introduce a semi-synthetic dataset for model editing based on Wikidata, where we can evaluate edits against labels given by an idealized Bayesian agent. This enables us to say exactly how belief revision in language models falls short of a desirable epistemic standard. We encourage further research exploring settings where such a gold standard can be compared against. Our code is publicly available at: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions", "authors": "Nigel Fernandez, Alexander Scarlatos, Simon Woodhead, Andrew Lan", "subjects": "Subjects:\nComputation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (cs.LG)", "abstract": "High-quality distractors are crucial to both the assessment and pedagogical value of multiple-choice questions (MCQs), where manually crafting ones that anticipate knowledge deficiencies or misconceptions among real students is difficult. Meanwhile, automated distractor generation, even with the help of large language models (LLMs), remains challenging for subjects like math. It is crucial to not only identify plausible distractors but also understand the error behind them. In this paper, we introduce DiVERT (Distractor Generation with Variational Errors Represented as Text), a novel variational approach that learns an interpretable representation of errors behind distractors in math MCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions used by hundreds of thousands of students, we show that DiVERT, despite using a base open-source LLM with 7B parameters, outperforms state-of-the-art approaches using GPT-4o on downstream distractor generation. We also conduct a human evaluation with math educators and find that DiVERT leads to error labels that are of comparable quality to human-authored ones."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models", "authors": "Xiliang Zhu, Shayna Gardiner, Tere Rold\u00e1n, David Rossouw", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Sentiment analysis serves as a pivotal component in Natural Language Processing (NLP). Advancements in multilingual pre-trained models such as XLM-R and mT5 have contributed to the increasing interest in cross-lingual sentiment analysis. The recent emergence in Large Language Models (LLM) has significantly advanced general NLP tasks, however, the capability of such LLMs in cross-lingual sentiment analysis has not been fully studied. This work undertakes an empirical analysis to compare the cross-lingual transfer capability of public Small Multilingual Language Models (SMLM) like XLM-R, against English-centric LLMs such as Llama-3, in the context of sentiment analysis across English, Spanish, French and Chinese. Our findings reveal that among public models, SMLMs exhibit superior zero-shot cross-lingual performance relative to LLMs. However, in few-shot cross-lingual settings, public LLMs demonstrate an enhanced adaptive potential. In addition, we observe that proprietary GPT-3.5 and GPT-4 lead in zero-shot cross-lingual capability, but are outpaced by public models in few-shot scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          STAL3D: Unsupervised Domain Adaptation for 3D Object Detection via Collaborating Self-Training and Adversarial Learning", "authors": "Yanan Zhang, Chao Zhou, Di Huang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Existing 3D object detection suffers from expensive annotation costs and poor transferability to unknown data due to the domain gap, Unsupervised Domain Adaptation (UDA) aims to generalize detection models trained in labeled source domains to perform robustly on unexplored target domains, providing a promising solution for cross-domain 3D object detection. Although Self-Training (ST) based cross-domain 3D detection methods with the assistance of pseudo-labeling techniques have achieved remarkable progress, they still face the issue of low-quality pseudo-labels when there are significant domain disparities due to the absence of a process for feature distribution alignment. While Adversarial Learning (AL) based methods can effectively align the feature distributions of the source and target domains, the inability to obtain labels in the target domain forces the adoption of asymmetric optimization losses, resulting in a challenging issue of source domain bias. To overcome these limitations, we propose a novel unsupervised domain adaptation framework for 3D object detection via collaborating ST and AL, dubbed as STAL3D, unleashing the complementary advantages of pseudo labels and feature distribution alignment. Additionally, a Background Suppression Adversarial Learning (BS-AL) module and a Scale Filtering Module (SFM) are designed tailored for 3D cross-domain scenes, effectively alleviating the issues of the large proportion of background interference and source domain size bias. Our STAL3D achieves state-of-the-art performance on multiple cross-domain tasks and even surpasses the Oracle results on Waymo $\\rightarrow$ KITTI and Waymo $\\rightarrow$ KITTI-rain."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SimTxtSeg: Weakly-Supervised Medical Image Segmentation with Simple Text Cues", "authors": "Yuxin Xie, Tao Zhou, Yi Zhou, Geng Chen", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Weakly-supervised medical image segmentation is a challenging task that aims to reduce the annotation cost while keep the segmentation performance. In this paper, we present a novel framework, SimTxtSeg, that leverages simple text cues to generate high-quality pseudo-labels and study the cross-modal fusion in training segmentation models, simultaneously. Our contribution consists of two key components: an effective Textual-to-Visual Cue Converter that produces visual prompts from text prompts on medical images, and a text-guided segmentation model with Text-Vision Hybrid Attention that fuses text and image features. We evaluate our framework on two medical image segmentation tasks: colonic polyp segmentation and MRI brain tumor segmentation, and achieve consistent state-of-the-art performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Mamba or RWKV: Exploring High-Quality and High-Efficiency Segment Anything Model", "authors": "Haobo Yuan, Xiangtai Li, Lu Qi, Tao Zhang, Ming-Hsuan Yang, Shuicheng Yan, Chen Change Loy", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Transformer-based segmentation methods face the challenge of efficient inference when dealing with high-resolution images. Recently, several linear attention architectures, such as Mamba and RWKV, have attracted much attention as they can process long sequences efficiently. In this work, we focus on designing an efficient segment-anything model by exploring these different architectures. Specifically, we design a mixed backbone that contains convolution and RWKV operation, which achieves the best for both accuracy and efficiency. In addition, we design an efficient decoder to utilize the multiscale tokens to obtain high-quality masks. We denote our method as RWKV-SAM, a simple, effective, fast baseline for SAM-like models. Moreover, we build a benchmark containing various high-quality segmentation datasets and jointly train one efficient yet high-quality segmentation model using this benchmark. Based on the benchmark results, our RWKV-SAM achieves outstanding performance in efficiency and segmentation quality compared to transformers and other linear attention models. For example, compared with the same-scale transformer model, RWKV-SAM achieves more than 2x speedup and can achieve better segmentation performance on various datasets. In addition, RWKV-SAM outperforms recent vision Mamba models with better classification and semantic segmentation results. Code and models will be publicly available."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space", "authors": "Core Francisco Park, Maya Okawa, Andrew Lee, Ekdeep Singh Lubana, Hidenori Tanaka", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Modern generative models demonstrate impressive capabilities, likely stemming from an ability to identify and manipulate abstract concepts underlying their training data. However, fundamental questions remain: what determines the concepts a model learns, the order in which it learns them, and its ability to manipulate those concepts? To address these questions, we propose analyzing a model's learning dynamics via a framework we call the concept space, where each axis represents an independent concept underlying the data generating process. By characterizing learning dynamics in this space, we identify how the speed at which a concept is learned, and hence the order of concept learning, is controlled by properties of the data we term concept signal. Further, we observe moments of sudden turns in the direction of a model's learning dynamics in concept space. Surprisingly, these points precisely correspond to the emergence of hidden capabilities, i.e., where latent interventions show the model possesses the capability to manipulate a concept, but these capabilities cannot yet be elicited via naive input prompting. While our results focus on synthetically defined toy datasets, we hypothesize a general claim on emergence of hidden capabilities may hold: generative models possess latent capabilities that emerge suddenly and consistently during training, though a model might not exhibit these capabilities under naive input prompting."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Suri: Multi-constraint Instruction Following for Long-form Text Generation", "authors": "Chau Minh Pham, Simeng Sun, Mohit Iyyer", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Existing research on instruction following largely focuses on tasks with simple instructions and short responses. In this work, we explore multi-constraint instruction following for generating long-form text. We create Suri, a dataset with 20K human-written long-form texts paired with LLM-generated backtranslated instructions that contain multiple complex constraints. Because of prohibitive challenges associated with collecting human preference judgments on long-form texts, preference-tuning algorithms such as DPO are infeasible in our setting; thus, we propose Instructional ORPO (I-ORPO), an alignment method based on the ORPO algorithm. Instead of receiving negative feedback from dispreferred responses, I-ORPO obtains negative feedback from synthetically corrupted instructions generated by an LLM. Using Suri, we perform supervised and I-ORPO fine-tuning on Mistral-7b-Instruct-v0.2. The resulting models, Suri-SFT and Suri-I-ORPO, generate significantly longer texts (~5K tokens) than base models without significant quality deterioration. Our human evaluation shows that while both SFT and I-ORPO models satisfy most constraints, Suri-I-ORPO generations are generally preferred for their coherent and informative incorporation of the constraints. We release our code at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          TTP-Based Cyber Resilience Index: A Probabilistic Quantitative Approach to Measure Defence Effectiveness Against Cyber Attacks", "authors": "Lampis Alevizos, Vinh-Thong Ta", "subjects": "Subjects:\nCryptography and Security (cs.CR)", "abstract": "In the dynamic cyber threat landscape, effective decision-making under uncertainty is crucial for maintaining robust information security. This paper introduces the Cyber Resilience Index (CRI), a TTP-based probabilistic approach to quantifying an organisation's defence effectiveness against cyber-attacks (campaigns). Building upon the Threat-Intelligence Based Security Assessment (TIBSA) methodology, we present a mathematical model that translates complex threat intelligence into an actionable, unified metric similar to a stock market index, that executives can understand and interact with while teams can act upon. Our method leverages Partially Observable Markov Decision Processes (POMDPs) to simulate attacker behaviour considering real-world uncertainties and the latest threat actor tactics, techniques, and procedures (TTPs). This allows for dynamic, context-aware evaluation of an organization's security posture, moving beyond static compliance-based assessments. As a result, decision-makers are equipped with a single metric of cyber resilience that bridges the gap between quantitative and qualitative assessments, enabling data-driven resource allocation and strategic planning. This can ultimately lead to more informed decision-making, mitigate under or overspending, and assist in resource allocation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Higher-Order Constrained Dependency Pairs for (Universal) Computability", "authors": "Liye Guo, Kasper Hagens, Cynthia Kop, Deivid Vale", "subjects": "Subjects:\nLogic in Computer Science (cs.LO)", "abstract": "Dependency pairs constitute a series of very effective techniques for the termination analysis of term rewriting systems. In this paper, we adapt the static dependency pair framework to logically constrained simply-typed term rewriting systems (LCSTRSs), a higher-order formalism with logical constraints built in. We also propose the concept of universal computability, which enables a form of open-world termination analysis through the use of static dependency pairs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          TabReD: A Benchmark of Tabular Machine Learning in-the-Wild", "authors": "Ivan Rubachev, Nikolay Kartashev, Yury Gorishniy, Artem Babenko", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Benchmarks that closely reflect downstream application scenarios are essential for the streamlined adoption of new research in tabular machine learning (ML). In this work, we examine existing tabular benchmarks and find two common characteristics of industry-grade tabular data that are underrepresented in the datasets available to the academic community. First, tabular data often changes over time in real-world deployment scenarios. This impacts model performance and requires time-based train and test splits for correct model evaluation. Yet, existing academic tabular datasets often lack timestamp metadata to enable such evaluation. Second, a considerable portion of datasets in production settings stem from extensive data acquisition and feature engineering pipelines. For each specific dataset, this can have a different impact on the absolute and relative number of predictive, uninformative, and correlated features, which in turn can affect model selection. To fill the aforementioned gaps in academic benchmarks, we introduce TabReD -- a collection of eight industry-grade tabular datasets covering a wide range of domains from finance to food delivery services. We assess a large number of tabular ML models in the feature-rich, temporally-evolving data setting facilitated by TabReD. We demonstrate that evaluation on time-based data splits leads to different methods ranking, compared to evaluation on random splits more common in academic benchmarks. Furthermore, on the TabReD datasets, MLP-like architectures and GBDT show the best results, while more sophisticated DL models are yet to prove their effectiveness."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Remarkable Robustness of LLMs: Stages of Inference?", "authors": "Vedang Lad, Wes Gurnee, Max Tegmark", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "We demonstrate and investigate the remarkable robustness of Large Language Models by deleting and swapping adjacent layers. We find that deleting and swapping interventions retain 72-95\\% of the original model's prediction accuracy without fine-tuning, whereas models with more layers exhibit more robustness. Based on the results of the layer-wise intervention and further experiments, we hypothesize the existence of four universal stages of inference across eight different models: detokenization, feature engineering, prediction ensembling, and residual sharpening. The first stage integrates local information, lifting raw token representations into higher-level contextual representations. Next is the iterative refinement of task and entity-specific features. Then, the second half of the model begins with a phase transition, where hidden representations align more with the vocabulary space due to specialized model components. Finally, the last layer sharpens the following token distribution by eliminating obsolete features that add noise to the prediction."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Taming Data and Transformers for Audio Generation", "authors": "Moayed Haji-Ali, Willi Menapace, Aliaksandr Siarohin, Guha Balakrishnan, Sergey Tulyakov, Vicente Ordonez", "subjects": "Subjects:\nSound (cs.SD); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)", "abstract": "Generating ambient sounds and effects is a challenging problem due to data scarcity and often insufficient caption quality, making it difficult to employ large-scale generative models for the task. In this work, we tackle the problem by introducing two new models. First, we propose AutoCap, a high-quality and efficient automatic audio captioning model. We show that by leveraging metadata available with the audio modality, we can substantially improve the quality of captions. AutoCap reaches CIDEr score of 83.2, marking a 3.2% improvement from the best available captioning model at four times faster inference speed. We then use AutoCap to caption clips from existing datasets, obtaining 761,000 audio clips with high-quality captions, forming the largest available audio-text dataset. Second, we propose GenAu, a scalable transformer-based audio generation architecture that we scale up to 1.25B parameters and train with our new dataset. When compared to state-of-the-art audio generators, GenAu obtains significant improvements of 15.7% in FAD score, 22.7% in IS, and 13.5% in CLAP score, indicating significantly improved quality of generated audio compared to previous works. This shows that the quality of data is often as important as its quantity. Besides, since AutoCap is fully automatic, new audio samples can be added to the training dataset, unlocking the training of even larger generative models for audio synthesis."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding", "authors": "Tao Zhang, Xiangtai Li, Hao Fei, Haobo Yuan, Shengqiong Wu, Shunping Ji, Chen Change Loy, Shuicheng Yan", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Current universal segmentation methods demonstrate strong capabilities in pixel-level image and video understanding. However, they lack reasoning abilities and cannot be controlled via text instructions. In contrast, large vision-language multimodal models exhibit powerful vision-based conversation and reasoning capabilities but lack pixel-level understanding and have difficulty accepting visual prompts for flexible user interaction. This paper proposes OMG-LLaVA, a new and elegant framework combining powerful pixel-level vision understanding with reasoning abilities. It can accept various visual and text prompts for flexible user interaction. Specifically, we use a universal segmentation method as the visual encoder, integrating image information, perception priors, and visual prompts into visual tokens provided to the LLM. The LLM is responsible for understanding the user's text instructions and providing text responses and pixel-level segmentation results based on the visual information. We propose perception prior embedding to better integrate perception priors with image features. OMG-LLaVA achieves image-level, object-level, and pixel-level reasoning and understanding in a single model, matching or surpassing the performance of specialized methods on multiple benchmarks. Rather than using LLM to connect each specialist, our work aims at end-to-end training on one encoder, one decoder, and one LLM. The code and model have been released for further research."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SALVe: Semantic Alignment Verification for Floorplan Reconstruction from Sparse Panoramas", "authors": "John Lambert, Yuguang Li, Ivaylo Boyadzhiev, Lambert Wixson, Manjunath Narayana, Will Hutchcroft, James Hays, Frank Dellaert, Sing Bing Kang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "We propose a new system for automatic 2D floorplan reconstruction that is enabled by SALVe, our novel pairwise learned alignment verifier. The inputs to our system are sparsely located 360$^\\circ$ panoramas, whose semantic features (windows, doors, and openings) are inferred and used to hypothesize pairwise room adjacency or overlap. SALVe initializes a pose graph, which is subsequently optimized using GTSAM. Once the room poses are computed, room layouts are inferred using HorizonNet, and the floorplan is constructed by stitching the most confident layout boundaries. We validate our system qualitatively and quantitatively as well as through ablation studies, showing that it outperforms state-of-the-art SfM systems in completeness by over 200%, without sacrificing accuracy. Our results point to the significance of our work: poses of 81% of panoramas are localized in the first 2 connected components (CCs), and 89% in the first 3 CCs. Code and models are publicly available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads", "authors": "Ali Khaleghi Rahimian, Manish Kumar Govind, Subhajit Maity, Dominick Reilly, Christian K\u00fcmmerle, Srijan Das, Aritra Dutta", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Visual perception tasks are predominantly solved by Vision Transformer (ViT) architectures, which, despite their effectiveness, encounter a computational bottleneck due to the quadratic complexity of computing self-attention. This inefficiency is largely due to the self-attention heads capturing redundant token interactions, reflecting inherent redundancy within visual data. Many works have aimed to reduce the computational complexity of self-attention in ViTs, leading to the development of efficient and sparse transformer architectures. In this paper, viewing through the efficiency lens, we realized that introducing any sparse self-attention strategy in ViTs can keep the computational overhead low. However, these strategies are sub-optimal as they often fail to capture fine-grained visual details. This observation leads us to propose a general, efficient, sparse architecture, named Fibottention, for approximating self-attention with superlinear complexity that is built upon Fibonacci sequences. The key strategies in Fibottention include: it excludes proximate tokens to reduce redundancy, employs structured sparsity by design to decrease computational demands, and incorporates inception-like diversity across attention heads. This diversity ensures the capture of complementary information through non-overlapping token interactions, optimizing both performance and resource utilization in ViTs for visual representation learning. We embed our Fibottention mechanism into multiple state-of-the-art transformer architectures dedicated to visual tasks. Leveraging only 2-6% of the elements in the self-attention heads, Fibottention in conjunction with ViT and its variants, consistently achieves significant performance boosts compared to standard ViTs in nine datasets across three domains $\\unicode{x2013}$ image classification, video understanding, and robot learning tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos", "authors": "Jr-Jen Chen, Yu-Chien Liao, Hsi-Che Lin, Yu-Chu Yu, Yen-Chun Chen, Yu-Chiang Frank Wang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "We introduce ReXTime, a benchmark designed to rigorously test AI models' ability to perform temporal reasoning within video events. Specifically, ReXTime focuses on reasoning across time, i.e. human-like understanding when the question and its corresponding answer occur in different video segments. This form of reasoning, requiring advanced understanding of cause-and-effect relationships across video segments, poses significant challenges to even the frontier multimodal large language models. To facilitate this evaluation, we develop an automated pipeline for generating temporal reasoning question-answer pairs, significantly reducing the need for labor-intensive manual annotations. Our benchmark includes 921 carefully vetted validation samples and 2,143 test samples, each manually curated for accuracy and relevance. Evaluation results show that while frontier large language models outperform academic models, they still lag behind human performance by a significant 14.3% accuracy gap. Additionally, our pipeline creates a training dataset of 9,695 machine generated samples without manual effort, which empirical studies suggest can enhance the across-time reasoning via fine-tuning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Looking 3D: Anomaly Detection with 2D-3D Alignment", "authors": "Ankan Bhunia, Changjian Li, Hakan Bilen", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Automatic anomaly detection based on visual cues holds practical significance in various domains, such as manufacturing and product quality assessment. This paper introduces a new conditional anomaly detection problem, which involves identifying anomalies in a query image by comparing it to a reference shape. To address this challenge, we have created a large dataset, BrokenChairs-180K, consisting of around 180K images, with diverse anomalies, geometries, and textures paired with 8,143 reference 3D shapes. To tackle this task, we have proposed a novel transformer-based approach that explicitly learns the correspondence between the query image and reference 3D shape via feature alignment and leverages a customized attention mechanism for anomaly detection. Our approach has been rigorously evaluated through comprehensive experiments, serving as a benchmark for future research in this domain."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          HUWSOD: Holistic Self-training for Unified Weakly Supervised Object Detection", "authors": "Liujuan Cao, Jianghang Lin, Zebo Hong, Yunhang Shen, Shaohui Lin, Chao Chen, Rongrong Ji", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Most WSOD methods rely on traditional object proposals to generate candidate regions and are confronted with unstable training, which easily gets stuck in a poor local optimum. In this paper, we introduce a unified, high-capacity weakly supervised object detection (WSOD) network called HUWSOD, which utilizes a comprehensive self-training framework without needing external modules or additional supervision. HUWSOD innovatively incorporates a self-supervised proposal generator and an autoencoder proposal generator with a multi-rate resampling pyramid to replace traditional object proposals, enabling end-to-end WSOD training and inference. Additionally, we implement a holistic self-training scheme that refines detection scores and coordinates through step-wise entropy minimization and consistency-constraint regularization, ensuring consistent predictions across stochastic augmentations of the same image. Extensive experiments on PASCAL VOC and MS COCO demonstrate that HUWSOD competes with state-of-the-art WSOD methods, eliminating the need for offline proposals and additional data. The peak performance of HUWSOD approaches that of fully-supervised Faster R-CNN. Our findings also indicate that randomly initialized boxes, although significantly different from well-designed offline object proposals, are effective for WSOD training."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Dataset Size Recovery from LoRA Weights", "authors": "Mohammad Salama, Jonathan Kahana, Eliahu Horwitz, Yedid Hoshen", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Model inversion and membership inference attacks aim to reconstruct and verify the data which a model was trained on. However, they are not guaranteed to find all training samples as they do not know the size of the training set. In this paper, we introduce a new task: dataset size recovery, that aims to determine the number of samples used to train a model, directly from its weights. We then propose DSiRe, a method for recovering the number of images used to fine-tune a model, in the common case where fine-tuning uses LoRA. We discover that both the norm and the spectrum of the LoRA matrices are closely linked to the fine-tuning dataset size; we leverage this finding to propose a simple yet effective prediction algorithm. To evaluate dataset size recovery of LoRA weights, we develop and release a new benchmark, LoRA-WiSE, consisting of over 25000 weight snapshots from more than 2000 diverse LoRA fine-tuned models. Our best classifier can predict the number of fine-tuning images with a mean absolute error of 0.36 images, establishing the feasibility of this attack."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SimLOB: Learning Representations of Limited Order Book for Financial Market Simulation", "authors": "Yuanzhe Li, Yue Wu, Peng Yang", "subjects": "Subjects:\nComputational Engineering, Finance, and Science (cs.CE)", "abstract": "Financial market simulation (FMS) serves as a promising tool for understanding market anomalies and the underlying trading behaviors. To ensure high-fidelity simulations, it is crucial to calibrate the FMS model for generating data closely resembling the observed market data. Previous efforts primarily focused on calibrating the mid-price data, leading to essential information loss of the market activities and thus biasing the calibrated model. The Limit Order Book (LOB) data is the fundamental data fully capturing the market micro-structure and is adopted by worldwide exchanges. However, LOB is not applicable to existing calibration objective functions due to its tabular structure not suitable for the vectorized input requirement. This paper proposes to explicitly learn the vectorized representations of LOB with a Transformer-based autoencoder. Then the latent vector, which captures the major information of LOB, can be applied for calibration. Extensive experiments show that the learned latent representation not only preserves the non-linear auto-correlation in the temporal axis, but the precedence between successive price levels of LOB. Besides, it is verified that the performance of the representation learning stage is consistent with the downstream calibration tasks. Thus, this work also progresses the FMS on LOB data, for the first time."}
